{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NTU ADL 2023 Fall HW2 - MT5 Fine-tuning for Title Generation\n",
        "- written by Chih-Han Yang\n",
        "- inspired by [Link](https://github.com/KrishnanJothi/MT5_Language_identification_NLP/blob/main/MT5_fine-tuning.ipynb)\n",
        "- executed on google - colab\n",
        "### Check the system resource"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rz3EIp51ZATF",
        "outputId": "3e36a0a5-e47c-4fd4-fc29-330ce7a34872"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Nov  6 10:03:42 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Required Library and Set Arguments\n",
        "1. Checks if a CUDA device (GPU) is available and prints the result.\n",
        "2. Imports the torch library for PyTorch, json for handling JSON data, and math for mathematical operations.\n",
        "3. Imports components from the accelerate library for hardware acceleration during training.\n",
        "4. Imports necessary components from the transformers library for working with pre-trained language models.\n",
        "5. Imports a function (get_rouge) for computing ROUGE scores, which are used for evaluating text generation tasks.\n",
        "6. Imports the tqdm library for creating progress bars, matplotlib for plotting, pandas for data manipulation, and argparse for handling command-line arguments.\n",
        "7. Defines a function named parse_args() which sets up command-line arguments for customizing the fine-tuning process. These arguments include file paths, hyperparameters, and settings related to the training process.\n",
        "    - (ps, Note that argparse are meant to be run from the command line, since it's a integrated kernel in the ipynb file, use ```args = parser.parse_known_args()[0]``` to resolve it.)\n",
        "    - (ps, Change the path arguments if you're using this code on a different platform.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oHnigbx1ueE",
        "outputId": "1176612f-66b5-4ed0-de0c-a0350e001a7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ckiptagger/model_ws.py:106: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# check if there's any cuda device available\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "import json\n",
        "import math\n",
        "\n",
        "from accelerate import Accelerator\n",
        "from accelerate.utils import set_seed\n",
        "\n",
        "import transformers\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    MT5ForConditionalGeneration,\n",
        "    GenerationConfig,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "from tw_rouge import get_rouge\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import argparse\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description = \"Finetune a mT5 model on Title Generation\")\n",
        "    parser.add_argument(\"--train_file\", type=str, default=\"/content/data/train.jsonl\")\n",
        "    parser.add_argument(\"--validation_file\", type=str, default=\"/content/data/public.jsonl\")\n",
        "    parser.add_argument(\"--result_file\", type=str, default=\"/content/result.jsonl\")\n",
        "    parser.add_argument(\"--max_output_length\", type=int, default=64)\n",
        "    parser.add_argument(\"--max_input_length\", type=int, default=256)\n",
        "    parser.add_argument(\"--model_name_or_path\", type=str, default=\"google/mt5-small\")\n",
        "    parser.add_argument(\"--learning_rate\", type=float, default=1e-3)\n",
        "    parser.add_argument(\"--num_train_epochs\", type=int, default=6)\n",
        "    parser.add_argument(\"--output_dir\", type=str, default=\"/content/model/\")\n",
        "    parser.add_argument(\"--per_device_train_batch_size\", type=int, default=1)\n",
        "    parser.add_argument(\"--per_device_eval_batch_size\", type=int, default=1)\n",
        "    parser.add_argument(\"--gradient_accumulation_steps\", type=int, default=16)\n",
        "    parser.add_argument(\"--seed\", type=int, default=20231104)\n",
        "    parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
        "\n",
        "\n",
        "    args = parser.parse_known_args()[0]\n",
        "    if args.train_file is None or args.validation_file is None or args.result_file is None:\n",
        "        raise ValueError(\"Need train file, validation file, and the result file specification\")\n",
        "    else:\n",
        "        # neither do train_file nor validation file is None, so\n",
        "        extension = args.train_file.split(\".\")[-1] # to see what extension the file is\n",
        "        print(extension)\n",
        "        assert extension == \"jsonl\", \"train_file should be a jsonl file\"\n",
        "        extension = args.validation_file.split(\".\")[-1] # to see what extension the file is\n",
        "        assert extension == \"jsonl\", \"validation_file should be a jsonl file\"\n",
        "        extension = args.result_file.split(\".\")[-1] # to see what extension the file is\n",
        "        assert extension == \"jsonl\", \"result_file should be a jsonl file\"\n",
        "    return args"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup and Configuration\n",
        "The following code is responsible for initializing the training process with the specified configuration, setting up hardware acceleration, adjusting logging levels, and potentially setting a random seed for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "args = parse_args()\n",
        "\n",
        "# acclerator setup\n",
        "accelerator_log_kwargs = {}\n",
        "accelerator = Accelerator(gradient_accumulation_steps=args.gradient_accumulation_steps, **accelerator_log_kwargs)\n",
        "\n",
        "if accelerator.is_local_main_process:\n",
        "    transformers.utils.logging.set_verbosity_info()\n",
        "else:\n",
        "    transformers.utils.logging.set_verbosity_error()\n",
        "\n",
        "# If passed along, set the training seed now.\n",
        "if args.seed is not None:\n",
        "    set_seed(args.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Preprocessing\n",
        "This code segment performs the following operations:\n",
        "\n",
        "1. Loads training and validation data from JSON files.\n",
        "2. Cleans the data by removing duplicate entries.\n",
        "3. Removes specific characters from the text. (Spaces and newlines)\n",
        "4. Calculates maximum text length in the training data.\n",
        "5. Determines batch sizes for training and evaluation.\n",
        "6. Adds a prefix to the text in order to specify the starting point.\n",
        "7. Prints information about the cleaned datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HuRP3U1QpwK",
        "outputId": "e0c2a791-4068-4e92-9ade-99558741ab43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "jsonl\n",
            "=====DATA CLEANING=====\n",
            "24549\n",
            "=====CLEANED TRAIN DATA===== | Shape:(21632, 6)\n",
            "          date_publish                                  title source_domain  \\\n",
            "0  2015-03-02 00:00:00  榜首進台大醫科卻休學 、27歲拿到法國天文博士 李悅寧跌破眾人眼鏡返台任教       udn.com   \n",
            "1  2015-10-20 00:00:00           「猩人」真有其事？人猿混種曾成功受孕 揭秘前蘇聯可怕實驗       udn.com   \n",
            "2  2015-12-10 00:00:00                跑步小品／謝謝三浦春馬 再次喚醒我對跑步的熱情       udn.com   \n",
            "3  2016-04-22 00:00:00       【身體不適特輯（下）】「拉肚子」、「想吐」、「嘔吐」英文怎麼說？       udn.com   \n",
            "4  2016-04-29 00:00:00                  中職／球彈、好球帶小 投手被打趴百害無一利       udn.com   \n",
            "\n",
            "                                            maintext  split  id  \n",
            "0  <idf.lang>從小就很會念書的李悅寧，在眾人殷殷期盼下，以榜首之姿進入臺大醫學院，但始...  train   0  \n",
            "1  <idf.lang>人類與猩猩混種誕下後代，不一定僅限於科幻電影情節。前蘇聯科學家早在192...  train   1  \n",
            "2  <idf.lang>從得知三浦春馬離世的消息那刻開始，心中頓時感到很鬱悶，那種很驚訝、很可惜...  train   2  \n",
            "3  <idf.lang>嗨，歡迎回到【身體不適特輯】的下集，在這集裡，小編會繼續講自己食物中毒的...  train   3  \n",
            "4  <idf.lang>今年中華職棒官辦熱身賽眾家打者真的打瘋了！數據顯示，官辦熱身賽打了20場...  train   4  \n",
            "=====CLEANED VALID DATA===== | Shape:(5467, 6)\n",
            "          date_publish                                   title source_domain  \\\n",
            "0  2021-01-14 00:00:00  Anker新款真無線藍牙耳機Liberty Air 2 Pro 引進台灣市場       udn.com   \n",
            "1  2021-01-14 00:00:00           藍染、客家美食、舊山線自行車 「苗栗一日遊」超人氣美食美景       udn.com   \n",
            "2  2021-01-14 00:00:00     華碩打造對應軍規防護與2 in 1設計的15.6吋Chromebook       udn.com   \n",
            "3  2021-01-14 00:00:00                         產業發展變革 台灣的優勢與機會       udn.com   \n",
            "4  2021-01-14 00:00:00     全球Windows 7裝置粗估至少還有1億台以上 市佔率穩穩卡在20％       udn.com   \n",
            "\n",
            "                                            maintext split     id  \n",
            "0  <idf.lang>Anker在此次CES2021中，宣布以旗下Soundcore品牌推出新...   dev  21710  \n",
            "1  <idf.lang>來到了苗栗旅遊，除了有超人氣的舊山線鐵道自行車外，還有絕不能錯過的客家美...   dev  21711  \n",
            "2  <idf.lang>如同其他品牌選擇在CES2021公布新款Chromebook產品，華碩也...   dev  21712  \n",
            "3  <idf.lang>文．洪寶山疫情改變全球的生活型態，也改變產業的發展，有些產業受到嚴重波及...   dev  21713  \n",
            "4  <idf.lang>在2020年1月14日，Windows7已經正式退出消費市場，不再得到微...   dev  21714  \n"
          ]
        }
      ],
      "source": [
        "# parsing data\n",
        "train_df = pd.read_json(args.train_file, lines=True)\n",
        "eval_df = pd.read_json(args.validation_file, lines=True)\n",
        "\n",
        "print(\"=====DATA CLEANING=====\")\n",
        "train_df = train_df.drop_duplicates(subset='title', keep=False).drop_duplicates(subset='maintext', keep=False)\n",
        "eval_df = eval_df.drop_duplicates(subset='title', keep=False).drop_duplicates(subset='maintext', keep=False)\n",
        "\n",
        "dropout_symbol = [\" \", \"\\n\"]\n",
        "for s in dropout_symbol:\n",
        "    train_df[\"maintext\"] = train_df[\"maintext\"].str.replace(s, \"\")\n",
        "    eval_df[\"maintext\"] = eval_df[\"maintext\"].str.replace(s, \"\")\n",
        "\n",
        "print(max([len(s) for s in train_df[\"maintext\"]]))\n",
        "\n",
        "train_batch_size = args.per_device_train_batch_size * args.gradient_accumulation_steps\n",
        "eval_batch_size = args.per_device_eval_batch_size * args.gradient_accumulation_steps\n",
        "\n",
        "# Adding prefix text to the input, which helps the model to understand the fine-tuning task objective\n",
        "train_df[\"maintext\"] = '<idf.lang>' + train_df[\"maintext\"]\n",
        "eval_df[\"maintext\"] = '<idf.lang>' + eval_df[\"maintext\"]\n",
        "print(f\"=====CLEANED TRAIN DATA===== | Shape:{train_df.shape}\")\n",
        "print(train_df.head())\n",
        "print(f\"=====CLEANED VALID DATA===== | Shape:{eval_df.shape}\")\n",
        "print(eval_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenizer and Model Initialization for Fine-tuning\n",
        "The code begins by initializing a tokenizer and a language generation model, loading pre-trained parameters. It configures the hardware accelerator for efficient training. Language identification tokens are defined and added to the tokenizer. The code then provides insights into tokenization and adjusts the model's token embeddings to match the updated vocabulary. This section ensures that both the tokenizer and model are set up optimally for fine-tuning, incorporating a special token for language identification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW7LrTLTQ5Hn",
        "outputId": "c9b7296d-0bba-4adb-a4c3-138160340343"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /content/model/models--google--mt5-small/snapshots/73fb5dbe4756edadc8fbe8c769b0a109493acf7a/config.json\n",
            "Model config MT5Config {\n",
            "  \"_name_or_path\": \"google/mt5-small\",\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 1024,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"num_decoder_layers\": 8,\n",
            "  \"num_heads\": 6,\n",
            "  \"num_layers\": 8,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.35.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "loading file spiece.model from cache at /content/model/models--google--mt5-small/snapshots/73fb5dbe4756edadc8fbe8c769b0a109493acf7a/spiece.model\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /content/model/models--google--mt5-small/snapshots/73fb5dbe4756edadc8fbe8c769b0a109493acf7a/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /content/model/models--google--mt5-small/snapshots/73fb5dbe4756edadc8fbe8c769b0a109493acf7a/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /content/model/models--google--mt5-small/snapshots/73fb5dbe4756edadc8fbe8c769b0a109493acf7a/config.json\n",
            "Model config MT5Config {\n",
            "  \"_name_or_path\": \"google/mt5-small\",\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 1024,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"num_decoder_layers\": 8,\n",
            "  \"num_heads\": 6,\n",
            "  \"num_layers\": 8,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.35.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "loading configuration file config.json from cache at /content/model/models--google--mt5-small/snapshots/73fb5dbe4756edadc8fbe8c769b0a109493acf7a/config.json\n",
            "Model config MT5Config {\n",
            "  \"_name_or_path\": \"google/mt5-small\",\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 1024,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"num_decoder_layers\": 8,\n",
            "  \"num_heads\": 6,\n",
            "  \"num_layers\": 8,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.35.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "loading configuration file config.json from cache at /content/model/models--google--mt5-small/snapshots/73fb5dbe4756edadc8fbe8c769b0a109493acf7a/config.json\n",
            "Model config MT5Config {\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 1024,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"num_decoder_layers\": 8,\n",
            "  \"num_heads\": 6,\n",
            "  \"num_layers\": 8,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.35.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /content/model/models--google--mt5-small/snapshots/73fb5dbe4756edadc8fbe8c769b0a109493acf7a/pytorch_model.bin\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing MT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of MT5ForConditionalGeneration were initialized from the model checkpoint at google/mt5-small.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use MT5ForConditionalGeneration for predictions without further training.\n",
            "loading configuration file generation_config.json from cache at /content/model/models--google--mt5-small/snapshots/73fb5dbe4756edadc8fbe8c769b0a109493acf7a/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The device is using: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 250101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "250100\n",
            "['</s>', '<unk>', '<pad>', '<idf.lang>']\n",
            "250101 250112\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Embedding(250101, 512)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tokenizer and Model\n",
        "tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path,\n",
        "              use_fast=True,\n",
        "              trust_remote_code=True,\n",
        "              cache_dir=args.output_dir\n",
        "          )\n",
        "model = MT5ForConditionalGeneration.from_pretrained(\n",
        "          args.model_name_or_path,\n",
        "          from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "          trust_remote_code=True,\n",
        "          cache_dir=args.output_dir,\n",
        "      )\n",
        "\n",
        "device = accelerator.device\n",
        "print(f\"The device is using: {device}\")\n",
        "model.to(device)\n",
        "\n",
        "LANG_TOKEN_MAPPING = {'identify language': '<idf.lang>'}\n",
        "special_tokens_dict = {'additional_special_tokens': list(LANG_TOKEN_MAPPING.values())}\n",
        "print(len(tokenizer))\n",
        "tokenizer.add_special_tokens(special_tokens_dict)\n",
        "print(tokenizer.all_special_tokens)\n",
        "print(len(tokenizer), model.config.vocab_size)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Text Encoding for Language Models\n",
        "1. ```encode_main_text``` : is a lambda function that tokenizes and encodes a given text with specified length constraints. It uses the tokenizer to prepare the text for training.\n",
        "2. ```encode_feature```: encodes an entire feature, consisting of 'maintext' and 'title'.\n",
        "3. ```encode_batch```: processes a batch of features, encoding each one using encode_feature. It organizes the resulting tensors into batches for efficient processing.\n",
        "4. ```encode_dataset```: encodes an entire dataset by iterating through it in batches. It shuffles the dataset, ensuring diversity in training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rPHcAmOgYlrW"
      },
      "outputs": [],
      "source": [
        "encode_main_text = lambda text, length: tokenizer.encode(text=text,\n",
        "                                                  return_tensors = 'pt',\n",
        "                                                  padding = 'max_length',\n",
        "                                                  truncation = True,\n",
        "                                                  max_length = length,\n",
        "                                              )[0]\n",
        "def encode_feature(feature):\n",
        "    # encode an entire feature\n",
        "    input_text = feature[\"maintext\"]\n",
        "    output_text = feature[\"title\"]\n",
        "\n",
        "    if input_text == None or output_text == None: return None\n",
        "\n",
        "    # note that the input and output should have different length constraint\n",
        "    # or both inputs and outputs would have encoding too long, causing out of memory\n",
        "    input_tokens = encode_main_text(input_text, args.max_input_length)\n",
        "    output_tokens = encode_main_text(output_text, args.max_output_length)\n",
        "\n",
        "    return input_tokens, output_tokens\n",
        "\n",
        "def encode_batch(batch):\n",
        "    # encode an entire batch\n",
        "    inputs = []\n",
        "    outputs = []\n",
        "\n",
        "    for index, feature in batch.iterrows():\n",
        "        formatted_data = encode_feature(feature)\n",
        "        if formatted_data is None: continue\n",
        "\n",
        "        input_tokens, output_tokens = formatted_data\n",
        "        inputs.append(input_tokens.unsqueeze(0))\n",
        "        outputs.append(output_tokens.unsqueeze(0))\n",
        "\n",
        "    batch_input_tokens = torch.cat(inputs).cuda()\n",
        "    batch_output_ids = torch.cat(outputs).cuda()\n",
        "\n",
        "    return batch_input_tokens, batch_output_ids\n",
        "\n",
        "def encode_dataset(dataset, batch_size):\n",
        "    dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    for i in range(0, len(dataset), batch_size):\n",
        "        raw_batch = dataset[i:i+batch_size]\n",
        "        yield encode_batch(raw_batch) # use yield to save memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training Configuration\n",
        "It sets up the optimizer, grouping parameters for efficient weight decay. It initializes an AdamW optimizer, calculates total training steps, and establishes a linear learning rate scheduler with warmup. The accelerator.prepare() function ensures hardware compatibility. Note that the lr_scheduler has argument ```num_training_steps=total_training_steps/2```. This can make the learning rate decay more rapidly which could give better result based on countless experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "# Split weights in two groups, one with weight decay and the other not.\n",
        "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "optimizer_grouped_parameters = [\n",
        "  {\n",
        "      \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "      \"weight_decay\": args.weight_decay,\n",
        "  },\n",
        "  {\n",
        "      \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "      \"weight_decay\": 0.0,\n",
        "  },\n",
        "]\n",
        "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=args.learning_rate)\n",
        "\n",
        "total_train_steps = math.ceil(train_df.shape[0] / (args.per_device_train_batch_size*args.gradient_accumulation_steps)) * args.num_train_epochs\n",
        "lr_scheduler = get_linear_schedule_with_warmup(\n",
        "                  optimizer=optimizer,\n",
        "                  num_warmup_steps=0,\n",
        "                  num_training_steps=total_train_steps/2)\n",
        "tokenizer, model, optimizer, lr_scheduler = accelerator.prepare(tokenizer, model, optimizer, lr_scheduler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training Loop\n",
        "This is the training process of fine-tuning a mT5 model. A generator configuration (train_gen_config) is established for text generation during training for evaluation. Training data is encoded in batches and fed into the model. Loss is computed, gradients are backpropagated, and optimizer steps are taken. Rouge scores are calculated periodically for evaluation. Additionally, training progress and metrics are logged. If the loss reaches a new minimum, the model is saved, ensuring the model learns from the data effectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "404b323293d94968bebd6e0eccec98cc",
            "275bba471d824aa29776cfabb2a76919",
            "246c552040d8445fa8ae23767d9e4a69",
            "492d5cb8d8054676a085a1ed087ab969",
            "d47b0dd51dc3438d89864314f0d3e9c6",
            "05530eb983ae4d7a85626ece9e22ec97",
            "c76c77a9d820458d880a0e6c76848157",
            "8149004acb904688ba4343d494ee58ac",
            "c93f4fa85c7e4e4eae1d0ecbc51976c8",
            "80a0fbd4c1f6471e886a7ed79a34bf26",
            "cc3e1b376e664f0b9a1575bbb91081da"
          ]
        },
        "id": "H7o-s0WqQ825",
        "outputId": "463ad259-4663-4330-dd37-20458723946f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "404b323293d94968bebd6e0eccec98cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/8112 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 21632\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 1\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 16\n",
            "Rouge-1:0.008928571275510205 | Rouge-2:0.0044642855947066365 | Rouge-l:0.008928571275510205\n",
            "Epoch: 0 | Step: 0 | Train loss: 48.03231430053711 | lr: 0.001 | Min loss:100\n",
            "Rouge-1:0.02629620849030326 | Rouge-2:0.0 | Rouge-l:0.02629620849030326\n",
            "Epoch: 0 | Step: 10 | Train loss: 48.763771057128906 | lr: 0.001 | Min loss:100\n",
            "Rouge-1:0.08496906158674944 | Rouge-2:0.021859388319451094 | Rouge-l:0.07287698699467486\n",
            "Epoch: 0 | Step: 20 | Train loss: 46.5804328918457 | lr: 0.0009997534516765286 | Min loss:100\n",
            "Rouge-1:0.0978197916132306 | Rouge-2:0.03888533076845712 | Rouge-l:0.08348386856476595\n",
            "Epoch: 0 | Step: 30 | Train loss: 48.8234748840332 | lr: 0.0009997534516765286 | Min loss:100\n",
            "Rouge-1:0.008333333022222235 | Rouge-2:0.0 | Rouge-l:0.008333333022222235\n",
            "Epoch: 0 | Step: 40 | Train loss: 37.304080963134766 | lr: 0.0009995069033530573 | Min loss:100\n",
            "Rouge-1:0.0 | Rouge-2:0.0 | Rouge-l:0.0\n",
            "Epoch: 0 | Step: 50 | Train loss: 27.660449981689453 | lr: 0.0009992603550295859 | Min loss:100\n",
            "Rouge-1:0.0 | Rouge-2:0.0 | Rouge-l:0.0\n",
            "Epoch: 0 | Step: 60 | Train loss: 28.454116821289062 | lr: 0.0009992603550295859 | Min loss:100\n",
            "Rouge-1:0.0032894733933518266 | Rouge-2:0.0 | Rouge-l:0.0032894733933518266\n",
            "Epoch: 0 | Step: 70 | Train loss: 18.604509353637695 | lr: 0.0009990138067061144 | Min loss:100\n",
            "Rouge-1:0.004676572897996906 | Rouge-2:0.0 | Rouge-l:0.004676572897996906\n",
            "Epoch: 0 | Step: 80 | Train loss: 15.028542518615723 | lr: 0.000998767258382643 | Min loss:100\n",
            "Rouge-1:0.020615548267990537 | Rouge-2:0.0 | Rouge-l:0.020615548267990537\n",
            "Epoch: 0 | Step: 90 | Train loss: 14.451085090637207 | lr: 0.000998767258382643 | Min loss:100\n",
            "Rouge-1:0.03881049552338322 | Rouge-2:0.0 | Rouge-l:0.03381049552338323\n",
            "Epoch: 0 | Step: 100 | Train loss: 13.316770553588867 | lr: 0.0009985207100591718 | Min loss:100\n",
            "Rouge-1:0.053557563945054135 | Rouge-2:0.0 | Rouge-l:0.044631878879040104\n",
            "Epoch: 0 | Step: 110 | Train loss: 12.960431098937988 | lr: 0.0009985207100591718 | Min loss:100\n",
            "Rouge-1:0.03448264889556347 | Rouge-2:0.0016447366161703911 | Rouge-l:0.029738646031259863\n",
            "Epoch: 0 | Step: 120 | Train loss: 11.951745986938477 | lr: 0.0009982741617357 | Min loss:100\n",
            "Rouge-1:0.04532655269617518 | Rouge-2:0.0 | Rouge-l:0.0407390106086331\n",
            "Epoch: 0 | Step: 130 | Train loss: 11.033668518066406 | lr: 0.0009980276134122289 | Min loss:100\n",
            "Rouge-1:0.02476075043867386 | Rouge-2:0.0 | Rouge-l:0.02476075043867386\n",
            "Epoch: 0 | Step: 140 | Train loss: 11.202096939086914 | lr: 0.0009980276134122289 | Min loss:100\n",
            "Rouge-1:0.06107374708003626 | Rouge-2:0.0 | Rouge-l:0.04629587498043243\n",
            "Epoch: 0 | Step: 150 | Train loss: 10.0504150390625 | lr: 0.0009977810650887574 | Min loss:100\n",
            "Rouge-1:0.02294258268096444 | Rouge-2:0.0 | Rouge-l:0.02294258268096444\n",
            "Epoch: 0 | Step: 160 | Train loss: 9.679491996765137 | lr: 0.000997534516765286 | Min loss:100\n",
            "Rouge-1:0.04088271319322461 | Rouge-2:0.0 | Rouge-l:0.03607502088553231\n",
            "Epoch: 0 | Step: 170 | Train loss: 9.490347862243652 | lr: 0.000997534516765286 | Min loss:100\n",
            "Rouge-1:0.0269010035297257 | Rouge-2:0.0 | Rouge-l:0.0269010035297257\n",
            "Epoch: 0 | Step: 180 | Train loss: 9.080023765563965 | lr: 0.0009972879684418145 | Min loss:100\n",
            "Rouge-1:0.006578947160664827 | Rouge-2:0.0 | Rouge-l:0.006578947160664827\n",
            "Epoch: 0 | Step: 190 | Train loss: 8.843955039978027 | lr: 0.0009972879684418145 | Min loss:100\n",
            "Rouge-1:0.0233265571630543 | Rouge-2:0.0 | Rouge-l:0.0233265571630543\n",
            "Epoch: 0 | Step: 200 | Train loss: 8.470818519592285 | lr: 0.0009970414201183433 | Min loss:100\n",
            "Rouge-1:0.03296454354559266 | Rouge-2:0.006249999800000006 | Rouge-l:0.03296454354559266\n",
            "Epoch: 0 | Step: 210 | Train loss: 7.850563049316406 | lr: 0.0009967948717948718 | Min loss:100\n",
            "Rouge-1:0.020847258713049883 | Rouge-2:0.0 | Rouge-l:0.020847258713049883\n",
            "Epoch: 0 | Step: 220 | Train loss: 8.010111808776855 | lr: 0.0009967948717948718 | Min loss:100\n",
            "Rouge-1:0.03275416017073936 | Rouge-2:0.0 | Rouge-l:0.03275416017073936\n",
            "Epoch: 0 | Step: 230 | Train loss: 7.552225112915039 | lr: 0.0009965483234714004 | Min loss:100\n",
            "Rouge-1:0.05845735118807353 | Rouge-2:0.0 | Rouge-l:0.05845735118807353\n",
            "Epoch: 0 | Step: 240 | Train loss: 6.933851718902588 | lr: 0.000996301775147929 | Min loss:100\n",
            "Rouge-1:0.047735537918099306 | Rouge-2:0.0 | Rouge-l:0.04205371973628113\n",
            "Epoch: 0 | Step: 250 | Train loss: 6.964150428771973 | lr: 0.000996301775147929 | Min loss:100\n",
            "Rouge-1:0.04334327787170784 | Rouge-2:0.0 | Rouge-l:0.038713648242078215\n",
            "Epoch: 0 | Step: 260 | Train loss: 6.485817909240723 | lr: 0.0009960552268244577 | Min loss:100\n",
            "Rouge-1:0.05730263636541731 | Rouge-2:0.0 | Rouge-l:0.051620818183599135\n",
            "Epoch: 0 | Step: 270 | Train loss: 6.495734214782715 | lr: 0.0009960552268244577 | Min loss:100\n",
            "Rouge-1:0.07749402425077492 | Rouge-2:0.011363636115702484 | Rouge-l:0.06539725005722655\n",
            "Epoch: 0 | Step: 280 | Train loss: 6.135533332824707 | lr: 0.0009958086785009862 | Min loss:100\n",
            "Rouge-1:0.0702788890110401 | Rouge-2:0.0 | Rouge-l:0.06547119670334779\n",
            "Epoch: 0 | Step: 290 | Train loss: 5.869630336761475 | lr: 0.0009955621301775148 | Min loss:100\n",
            "Rouge-1:0.09458167536302008 | Rouge-2:0.014154704426161662 | Rouge-l:0.08651715923398783\n",
            "Epoch: 0 | Step: 300 | Train loss: 5.836146831512451 | lr: 0.0009955621301775148 | Min loss:100\n",
            "Rouge-1:0.04861358863034639 | Rouge-2:0.0 | Rouge-l:0.03999289897517398\n",
            "Epoch: 0 | Step: 310 | Train loss: 5.63169527053833 | lr: 0.0009953155818540433 | Min loss:100\n",
            "Rouge-1:0.06317910346135838 | Rouge-2:0.0 | Rouge-l:0.05837141115366608\n",
            "Epoch: 0 | Step: 320 | Train loss: 5.361425876617432 | lr: 0.0009950690335305719 | Min loss:100\n",
            "Rouge-1:0.05230593601103649 | Rouge-2:0.010416666356336816 | Rouge-l:0.047841650296750776\n",
            "Epoch: 0 | Step: 330 | Train loss: 5.4044060707092285 | lr: 0.0009950690335305719 | Min loss:100\n",
            "Rouge-1:0.10325246340179357 | Rouge-2:0.023437499267035616 | Rouge-l:0.09323643776076795\n",
            "Epoch: 0 | Step: 340 | Train loss: 5.221578598022461 | lr: 0.0009948224852071007 | Min loss:100\n",
            "Rouge-1:0.07729665175951579 | Rouge-2:0.010416666104513922 | Rouge-l:0.07729665175951579\n",
            "Epoch: 0 | Step: 350 | Train loss: 5.251295566558838 | lr: 0.0009948224852071007 | Min loss:100\n",
            "Rouge-1:0.08023047169873476 | Rouge-2:0.011578946826337975 | Rouge-l:0.06947039843866151\n",
            "Epoch: 0 | Step: 360 | Train loss: 5.00535774230957 | lr: 0.0009945759368836292 | Min loss:100\n",
            "Rouge-1:0.05688133865797882 | Rouge-2:0.01343167633823858 | Rouge-l:0.05012458190122208\n",
            "Epoch: 0 | Step: 370 | Train loss: 4.818892955780029 | lr: 0.000994329388560158 | Min loss:100\n",
            "Rouge-1:0.05188806523526218 | Rouge-2:0.0 | Rouge-l:0.04667973190192885\n",
            "Epoch: 0 | Step: 380 | Train loss: 4.878388404846191 | lr: 0.000994329388560158 | Min loss:100\n",
            "Rouge-1:0.09578280842791953 | Rouge-2:0.01562499954861113 | Rouge-l:0.08953280842791954\n",
            "Epoch: 0 | Step: 390 | Train loss: 4.535741806030273 | lr: 0.0009940828402366863 | Min loss:100\n",
            "Rouge-1:0.06827977873653143 | Rouge-2:0.02246776714549829 | Rouge-l:0.06827977873653143\n",
            "Epoch: 0 | Step: 400 | Train loss: 4.54312801361084 | lr: 0.000993836291913215 | Min loss:100\n",
            "Rouge-1:0.028365383949741144 | Rouge-2:0.005681818078512398 | Rouge-l:0.028365383949741144\n",
            "Epoch: 0 | Step: 410 | Train loss: 4.627044677734375 | lr: 0.000993836291913215 | Min loss:100\n",
            "Rouge-1:0.07208503885895359 | Rouge-2:0.004999999692000019 | Rouge-l:0.06613265790657265\n",
            "Epoch: 0 | Step: 420 | Train loss: 4.492173194885254 | lr: 0.0009935897435897436 | Min loss:100\n",
            "Rouge-1:0.028159562257602126 | Rouge-2:0.0 | Rouge-l:0.028159562257602126\n",
            "Epoch: 0 | Step: 430 | Train loss: 4.691898345947266 | lr: 0.0009935897435897436 | Min loss:100\n",
            "Rouge-1:0.0824878313734802 | Rouge-2:0.020138888266242317 | Rouge-l:0.07513489019700961\n",
            "Epoch: 0 | Step: 440 | Train loss: 4.254300117492676 | lr: 0.0009933431952662722 | Min loss:100\n",
            "Rouge-1:0.11932126819910839 | Rouge-2:0.021558301790157993 | Rouge-l:0.09585582104463686\n",
            "Epoch: 0 | Step: 450 | Train loss: 4.198127746582031 | lr: 0.0009930966469428007 | Min loss:100\n",
            "Rouge-1:0.06129960117618229 | Rouge-2:0.0078124998095703176 | Rouge-l:0.06129960117618229\n",
            "Epoch: 0 | Step: 460 | Train loss: 4.37532377243042 | lr: 0.0009930966469428007 | Min loss:100\n",
            "Rouge-1:0.09660422054753023 | Rouge-2:0.021638485462949223 | Rouge-l:0.08336530429137261\n",
            "Epoch: 0 | Step: 470 | Train loss: 4.08327579498291 | lr: 0.0009928500986193295 | Min loss:100\n",
            "Rouge-1:0.06926602789580596 | Rouge-2:0.0 | Rouge-l:0.057902391532169604\n",
            "Epoch: 0 | Step: 480 | Train loss: 4.140628337860107 | lr: 0.000992603550295858 | Min loss:100\n",
            "Rouge-1:0.13926334856323336 | Rouge-2:0.050528576422054154 | Rouge-l:0.12787618500215675\n",
            "Epoch: 0 | Step: 490 | Train loss: 3.971538543701172 | lr: 0.000992603550295858 | Min loss:100\n",
            "Rouge-1:0.13226336833165342 | Rouge-2:0.04043236741868522 | Rouge-l:0.12491042715518283\n",
            "Epoch: 0 | Step: 500 | Train loss: 4.006561756134033 | lr: 0.0009923570019723866 | Min loss:100\n",
            "Rouge-1:0.07731284084747186 | Rouge-2:0.014430292998375022 | Rouge-l:0.06391998370461474\n",
            "Epoch: 0 | Step: 510 | Train loss: 4.007686614990234 | lr: 0.0009923570019723866 | Min loss:100\n",
            "Rouge-1:0.13074557689994765 | Rouge-2:0.0060975607450922155 | Rouge-l:0.11120648423585501\n",
            "Epoch: 0 | Step: 520 | Train loss: 4.028160095214844 | lr: 0.0009921104536489151 | Min loss:100\n",
            "Rouge-1:0.09137814393873561 | Rouge-2:0.02172618988691187 | Rouge-l:0.09137814393873561\n",
            "Epoch: 0 | Step: 530 | Train loss: 3.809260129928589 | lr: 0.000991863905325444 | Min loss:100\n",
            "Rouge-1:0.1322887611019822 | Rouge-2:0.02113229019690028 | Rouge-l:0.10627033702956094\n",
            "Epoch: 0 | Step: 540 | Train loss: 3.747637987136841 | lr: 0.000991863905325444 | Min loss:100\n",
            "Rouge-1:0.11982733746737563 | Rouge-2:0.04991421475900251 | Rouge-l:0.11021195285199104\n",
            "Epoch: 0 | Step: 550 | Train loss: 3.6152524948120117 | lr: 0.0009916173570019724 | Min loss:100\n",
            "Rouge-1:0.1531174783176928 | Rouge-2:0.033665458075423677 | Rouge-l:0.14790914498435948\n",
            "Epoch: 0 | Step: 560 | Train loss: 3.3974742889404297 | lr: 0.000991370808678501 | Min loss:100\n",
            "Rouge-1:0.1631858984017571 | Rouge-2:0.07746429773239835 | Rouge-l:0.15297756506842378\n",
            "Epoch: 0 | Step: 570 | Train loss: 3.390775203704834 | lr: 0.000991370808678501 | Min loss:100\n",
            "Rouge-1:0.25484870193752823 | Rouge-2:0.11590328327848307 | Rouge-l:0.19868324300033016\n",
            "Epoch: 0 | Step: 580 | Train loss: 3.24869966506958 | lr: 0.0009911242603550295 | Min loss:100\n",
            "Rouge-1:0.15496394358061333 | Rouge-2:0.04261363574610183 | Rouge-l:0.13966674078341057\n",
            "Epoch: 0 | Step: 590 | Train loss: 3.3898401260375977 | lr: 0.0009911242603550295 | Min loss:100\n",
            "Rouge-1:0.14201160546516295 | Rouge-2:0.0370943196445558 | Rouge-l:0.1222283393361307\n",
            "Epoch: 0 | Step: 600 | Train loss: 3.254100799560547 | lr: 0.000990877712031558 | Min loss:100\n",
            "Rouge-1:0.14505910488085844 | Rouge-2:0.026871154263603952 | Rouge-l:0.12133751397176758\n",
            "Epoch: 0 | Step: 610 | Train loss: 3.1608619689941406 | lr: 0.0009906311637080869 | Min loss:100\n",
            "Rouge-1:0.15716409825575323 | Rouge-2:0.06884222386880612 | Rouge-l:0.14934396140335832\n",
            "Epoch: 0 | Step: 620 | Train loss: 3.1238832473754883 | lr: 0.0009906311637080869 | Min loss:100\n",
            "Rouge-1:0.1290831650911214 | Rouge-2:0.04798255701999152 | Rouge-l:0.1290831650911214\n",
            "Epoch: 0 | Step: 630 | Train loss: 2.97786283493042 | lr: 0.0009903846153846154 | Min loss:100\n",
            "Rouge-1:0.15468836815913992 | Rouge-2:0.03752281380177094 | Rouge-l:0.14332473179550353\n",
            "Epoch: 0 | Step: 640 | Train loss: 2.807248830795288 | lr: 0.000990138067061144 | Min loss:100\n",
            "Rouge-1:0.06293733339210843 | Rouge-2:0.0 | Rouge-l:0.058770666725441754\n",
            "Epoch: 0 | Step: 650 | Train loss: 3.1307976245880127 | lr: 0.000990138067061144 | Min loss:100\n",
            "Rouge-1:0.1941823123760704 | Rouge-2:0.05926120332248404 | Rouge-l:0.1779879803922647\n",
            "Epoch: 0 | Step: 660 | Train loss: 2.6560916900634766 | lr: 0.0009898915187376725 | Min loss:100\n",
            "Rouge-1:0.16951659830704863 | Rouge-2:0.03413865496802398 | Rouge-l:0.14522931760529423\n",
            "Epoch: 0 | Step: 670 | Train loss: 2.5671443939208984 | lr: 0.0009898915187376725 | Min loss:100\n",
            "Rouge-1:0.22888329644117505 | Rouge-2:0.10937524362840532 | Rouge-l:0.2202252877831664\n",
            "Epoch: 0 | Step: 680 | Train loss: 2.379751682281494 | lr: 0.0009896449704142013 | Min loss:100\n",
            "Rouge-1:0.14591605375892858 | Rouge-2:0.04244652327757265 | Rouge-l:0.14128642412929893\n",
            "Epoch: 0 | Step: 690 | Train loss: 2.42069149017334 | lr: 0.0009893984220907298 | Min loss:100\n",
            "Rouge-1:0.19443750768029816 | Rouge-2:0.09427074519780476 | Rouge-l:0.18444534467089374\n",
            "Epoch: 0 | Step: 700 | Train loss: 2.5021026134490967 | lr: 0.0009893984220907298 | Min loss:100\n",
            "Rouge-1:0.12496386119536271 | Rouge-2:0.020130742020935444 | Rouge-l:0.11423153796303948\n",
            "Epoch: 0 | Step: 710 | Train loss: 2.2945239543914795 | lr: 0.0009891518737672584 | Min loss:100\n",
            "Rouge-1:0.11512140732437687 | Rouge-2:0.039434677397478315 | Rouge-l:0.11012140732437686\n",
            "Epoch: 0 | Step: 720 | Train loss: 1.9347814321517944 | lr: 0.000988905325443787 | Min loss:100\n",
            "Rouge-1:0.1685348429039959 | Rouge-2:0.06700977066745309 | Rouge-l:0.15950258483947977\n",
            "Epoch: 0 | Step: 730 | Train loss: 2.0818610191345215 | lr: 0.000988905325443787 | Min loss:100\n",
            "Rouge-1:0.12865068829505388 | Rouge-2:0.019657257498394434 | Rouge-l:0.1030408633374029\n",
            "Epoch: 0 | Step: 740 | Train loss: 2.0886785984039307 | lr: 0.0009886587771203157 | Min loss:100\n",
            "Rouge-1:0.1910281877182752 | Rouge-2:0.10611294972619893 | Rouge-l:0.1910281877182752\n",
            "Epoch: 0 | Step: 750 | Train loss: 2.026758909225464 | lr: 0.0009886587771203157 | Min loss:100\n",
            "Rouge-1:0.12769041557555905 | Rouge-2:0.05575836478307662 | Rouge-l:0.11630521633457236\n",
            "Epoch: 0 | Step: 760 | Train loss: 1.9382081031799316 | lr: 0.0009884122287968442 | Min loss:100\n",
            "Rouge-1:0.18061737222374658 | Rouge-2:0.03974536859973329 | Rouge-l:0.12244955008692093\n",
            "Epoch: 0 | Step: 770 | Train loss: 1.865069031715393 | lr: 0.0009881656804733728 | Min loss:100\n",
            "Rouge-1:0.1066039831743964 | Rouge-2:0.021205231128859865 | Rouge-l:0.10035398317439641\n",
            "Epoch: 0 | Step: 780 | Train loss: 1.8684325218200684 | lr: 0.0009881656804733728 | Min loss:100\n",
            "Rouge-1:0.0753688903202193 | Rouge-2:0.01319444384737657 | Rouge-l:0.07146264032021932\n",
            "Epoch: 0 | Step: 790 | Train loss: 2.0128579139709473 | lr: 0.0009879191321499013 | Min loss:100\n",
            "Rouge-1:0.13551309357438385 | Rouge-2:0.028291400380346044 | Rouge-l:0.11372250599432258\n",
            "Epoch: 0 | Step: 800 | Train loss: 1.7010118961334229 | lr: 0.00098767258382643 | Min loss:100\n",
            "Rouge-1:0.1979301695857853 | Rouge-2:0.06684807451615797 | Rouge-l:0.1647057687143256\n",
            "Epoch: 0 | Step: 810 | Train loss: 1.8944350481033325 | lr: 0.00098767258382643 | Min loss:100\n",
            "Rouge-1:0.09505783657462809 | Rouge-2:0.042022791403499175 | Rouge-l:0.09505783657462809\n",
            "Epoch: 0 | Step: 820 | Train loss: 1.7595107555389404 | lr: 0.0009874260355029587 | Min loss:100\n",
            "Rouge-1:0.19746845723620068 | Rouge-2:0.055702927560229265 | Rouge-l:0.1749839972517407\n",
            "Epoch: 0 | Step: 830 | Train loss: 1.6906545162200928 | lr: 0.0009874260355029587 | Min loss:100\n",
            "Rouge-1:0.11752695956481499 | Rouge-2:0.031897023758944994 | Rouge-l:0.10614176032382829\n",
            "Epoch: 0 | Step: 840 | Train loss: 1.7778677940368652 | lr: 0.0009871794871794872 | Min loss:100\n",
            "Rouge-1:0.14720912225429683 | Rouge-2:0.041803727227718225 | Rouge-l:0.1306455358689787\n",
            "Epoch: 0 | Step: 850 | Train loss: 1.9338464736938477 | lr: 0.0009869329388560158 | Min loss:100\n",
            "Rouge-1:0.11090817916705834 | Rouge-2:0.007812499687500012 | Rouge-l:0.0984584126850338\n",
            "Epoch: 0 | Step: 860 | Train loss: 1.8345240354537964 | lr: 0.0009869329388560158 | Min loss:100\n",
            "Rouge-1:0.1659789785399313 | Rouge-2:0.05095909757281282 | Rouge-l:0.1496974659348893\n",
            "Epoch: 0 | Step: 870 | Train loss: 1.7541760206222534 | lr: 0.0009866863905325443 | Min loss:100\n",
            "Rouge-1:0.19248749614052763 | Rouge-2:0.06097892750177652 | Rouge-l:0.16531203661419325\n",
            "Epoch: 0 | Step: 880 | Train loss: 1.6451470851898193 | lr: 0.000986439842209073 | Min loss:100\n",
            "Rouge-1:0.2252534126713618 | Rouge-2:0.07117106231247566 | Rouge-l:0.18190753579752444\n",
            "Epoch: 0 | Step: 890 | Train loss: 1.468672752380371 | lr: 0.000986439842209073 | Min loss:100\n",
            "Rouge-1:0.15884729205588063 | Rouge-2:0.07181712823162084 | Rouge-l:0.14923190744049603\n",
            "Epoch: 0 | Step: 900 | Train loss: 1.6842223405838013 | lr: 0.0009861932938856016 | Min loss:100\n",
            "Rouge-1:0.18232570514296176 | Rouge-2:0.041550194322831115 | Rouge-l:0.1651348010035282\n",
            "Epoch: 0 | Step: 910 | Train loss: 1.528342843055725 | lr: 0.0009861932938856016 | Min loss:100\n",
            "Rouge-1:0.16325958642580995 | Rouge-2:0.05144664934637086 | Rouge-l:0.12597384227865277\n",
            "Epoch: 0 | Step: 920 | Train loss: 1.7273136377334595 | lr: 0.0009859467455621302 | Min loss:100\n",
            "Rouge-1:0.14894831405454292 | Rouge-2:0.03914967964425145 | Rouge-l:0.1385316473878763\n",
            "Epoch: 0 | Step: 930 | Train loss: 1.572007179260254 | lr: 0.0009857001972386587 | Min loss:100\n",
            "Rouge-1:0.17864145890707997 | Rouge-2:0.05130083025435887 | Rouge-l:0.157998342965051\n",
            "Epoch: 0 | Step: 940 | Train loss: 1.4606177806854248 | lr: 0.0009857001972386587 | Min loss:100\n",
            "Rouge-1:0.23336036060528523 | Rouge-2:0.1083473505282323 | Rouge-l:0.1959867952144785\n",
            "Epoch: 0 | Step: 950 | Train loss: 1.7710211277008057 | lr: 0.0009854536489151875 | Min loss:100\n",
            "Rouge-1:0.1777481781147183 | Rouge-2:0.03366545819815344 | Rouge-l:0.14473001572155592\n",
            "Epoch: 0 | Step: 960 | Train loss: 1.586194396018982 | lr: 0.000985207100591716 | Min loss:100\n",
            "Rouge-1:0.19819831627698473 | Rouge-2:0.055309827589246165 | Rouge-l:0.17212459832826682\n",
            "Epoch: 0 | Step: 970 | Train loss: 1.6089601516723633 | lr: 0.000985207100591716 | Min loss:100\n",
            "Rouge-1:0.1269562367690577 | Rouge-2:0.021230388664884147 | Rouge-l:0.104703694903029\n",
            "Epoch: 0 | Step: 980 | Train loss: 1.6364095211029053 | lr: 0.0009849605522682446 | Min loss:100\n",
            "Rouge-1:0.13217541011795794 | Rouge-2:0.006944444131944459 | Rouge-l:0.12191999216130162\n",
            "Epoch: 0 | Step: 990 | Train loss: 1.5707367658615112 | lr: 0.0009849605522682446 | Min loss:100\n",
            "Rouge-1:0.22988239560358262 | Rouge-2:0.0861977678361173 | Rouge-l:0.1850724388031367\n",
            "Epoch: 0 | Step: 1000 | Train loss: 1.6719787120819092 | lr: 0.0009847140039447731 | Min loss:100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Step: 1001 | Train loss: 1.7152594327926636 | lr: 0.0009847140039447731 | Min loss:1.7152594327926636\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n",
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Step: 1003 | Train loss: 1.5802503824234009 | lr: 0.0009847140039447731 | Min loss:1.5802503824234009\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n",
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Step: 1005 | Train loss: 1.5187166929244995 | lr: 0.0009847140039447731 | Min loss:1.5187166929244995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n",
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.165671886523686 | Rouge-2:0.03613471535666258 | Rouge-l:0.15565586088266034\n",
            "Epoch: 0 | Step: 1010 | Train loss: 1.5087201595306396 | lr: 0.0009844674556213017 | Min loss:1.5187166929244995\n",
            "Epoch: 0 | Step: 1010 | Train loss: 1.5087201595306396 | lr: 0.0009844674556213017 | Min loss:1.5087201595306396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n",
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Step: 1016 | Train loss: 1.4882259368896484 | lr: 0.0009844674556213017 | Min loss:1.4882259368896484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n",
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.12335354152862654 | Rouge-2:0.01874999922267577 | Rouge-l:0.10147854152862656\n",
            "Epoch: 0 | Step: 1020 | Train loss: 1.4512516260147095 | lr: 0.0009844674556213017 | Min loss:1.4882259368896484\n",
            "Epoch: 0 | Step: 1020 | Train loss: 1.4512516260147095 | lr: 0.0009844674556213017 | Min loss:1.4512516260147095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.19666250782478673 | Rouge-2:0.04567098135194224 | Rouge-l:0.1835046130879446\n",
            "Epoch: 0 | Step: 1030 | Train loss: 1.66416597366333 | lr: 0.0009842209072978305 | Min loss:1.4512516260147095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Step: 1033 | Train loss: 1.1780685186386108 | lr: 0.0009842209072978305 | Min loss:1.1780685186386108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.2519732972422299 | Rouge-2:0.12835662251488744 | Rouge-l:0.2118239007866115\n",
            "Epoch: 0 | Step: 1040 | Train loss: 1.6597920656204224 | lr: 0.000983974358974359 | Min loss:1.1780685186386108\n",
            "Rouge-1:0.18126531209326233 | Rouge-2:0.07134966624893546 | Rouge-l:0.17077580160375183\n",
            "Epoch: 0 | Step: 1050 | Train loss: 1.2887362241744995 | lr: 0.000983974358974359 | Min loss:1.1780685186386108\n",
            "Rouge-1:0.20414548950210928 | Rouge-2:0.12921156674510365 | Rouge-l:0.19720104505766484\n",
            "Epoch: 0 | Step: 1060 | Train loss: 1.2876179218292236 | lr: 0.0009837278106508876 | Min loss:1.1780685186386108\n",
            "Rouge-1:0.17298958795871236 | Rouge-2:0.02971230086869511 | Rouge-l:0.13587556117077257\n",
            "Epoch: 0 | Step: 1070 | Train loss: 1.7127612829208374 | lr: 0.0009837278106508876 | Min loss:1.1780685186386108\n",
            "Rouge-1:0.11268678651413955 | Rouge-2:0.010952380352589603 | Rouge-l:0.08712317942879334\n",
            "Epoch: 0 | Step: 1080 | Train loss: 1.70663321018219 | lr: 0.000983481262327416 | Min loss:1.1780685186386108\n",
            "Rouge-1:0.16908167039463484 | Rouge-2:0.045065788212839575 | Rouge-l:0.1559187916067561\n",
            "Epoch: 0 | Step: 1090 | Train loss: 1.5407274961471558 | lr: 0.0009832347140039449 | Min loss:1.1780685186386108\n",
            "Rouge-1:0.13243648076102152 | Rouge-2:0.04442072424031789 | Rouge-l:0.12585753339260047\n",
            "Epoch: 0 | Step: 1100 | Train loss: 1.731116533279419 | lr: 0.0009832347140039449 | Min loss:1.1780685186386108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Step: 1103 | Train loss: 1.1290531158447266 | lr: 0.0009829881656804734 | Min loss:1.1290531158447266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.1275383570829913 | Rouge-2:0.03624458764866841 | Rouge-l:0.11327909782373208\n",
            "Epoch: 0 | Step: 1110 | Train loss: 1.2612802982330322 | lr: 0.0009829881656804734 | Min loss:1.1290531158447266\n",
            "Rouge-1:0.15672288816240917 | Rouge-2:0.07030075030100928 | Rouge-l:0.1468849251994462\n",
            "Epoch: 0 | Step: 1120 | Train loss: 1.5234336853027344 | lr: 0.000982741617357002 | Min loss:1.1290531158447266\n",
            "Rouge-1:0.18531359440971965 | Rouge-2:0.06009541424773615 | Rouge-l:0.15261995740156653\n",
            "Epoch: 0 | Step: 1130 | Train loss: 1.61453378200531 | lr: 0.000982741617357002 | Min loss:1.1290531158447266\n",
            "Rouge-1:0.13329868845477041 | Rouge-2:0.04564276110814755 | Rouge-l:0.12939243845477041\n",
            "Epoch: 0 | Step: 1140 | Train loss: 1.3979190587997437 | lr: 0.0009824950690335305 | Min loss:1.1290531158447266\n",
            "Rouge-1:0.18938216282570658 | Rouge-2:0.06870039605446607 | Rouge-l:0.17909990476119048\n",
            "Epoch: 0 | Step: 1150 | Train loss: 1.1632018089294434 | lr: 0.0009824950690335305 | Min loss:1.1290531158447266\n",
            "Rouge-1:0.1304292755465529 | Rouge-2:0.04464285685586735 | Rouge-l:0.11665189004575492\n",
            "Epoch: 0 | Step: 1160 | Train loss: 1.655673861503601 | lr: 0.0009822485207100593 | Min loss:1.1290531158447266\n",
            "Rouge-1:0.2164793145625866 | Rouge-2:0.09006466351388676 | Rouge-l:0.20351635159962364\n",
            "Epoch: 0 | Step: 1170 | Train loss: 1.6231322288513184 | lr: 0.0009820019723865878 | Min loss:1.1290531158447266\n",
            "Rouge-1:0.12639604824677914 | Rouge-2:0.030686089211593187 | Rouge-l:0.12639604824677914\n",
            "Epoch: 0 | Step: 1180 | Train loss: 1.5128306150436401 | lr: 0.0009820019723865878 | Min loss:1.1290531158447266\n",
            "Rouge-1:0.15183957170270188 | Rouge-2:0.04427364776055749 | Rouge-l:0.1112611109330867\n",
            "Epoch: 0 | Step: 1190 | Train loss: 1.4399919509887695 | lr: 0.0009817554240631164 | Min loss:1.1290531158447266\n",
            "Rouge-1:0.1595831423403893 | Rouge-2:0.061325356108105494 | Rouge-l:0.13302730261319407\n",
            "Epoch: 0 | Step: 1200 | Train loss: 1.3683663606643677 | lr: 0.000981508875739645 | Min loss:1.1290531158447266\n",
            "Rouge-1:0.15590728461886294 | Rouge-2:0.06059962325104988 | Rouge-l:0.14995490366648198\n",
            "Epoch: 0 | Step: 1210 | Train loss: 1.389665961265564 | lr: 0.000981508875739645 | Min loss:1.1290531158447266\n",
            "Rouge-1:0.12165193191193553 | Rouge-2:0.040740739737414294 | Rouge-l:0.10915193191193553\n",
            "Epoch: 0 | Step: 1220 | Train loss: 1.5876495838165283 | lr: 0.0009812623274161737 | Min loss:1.1290531158447266\n",
            "Rouge-1:0.16150485317884722 | Rouge-2:0.048733024163784444 | Rouge-l:0.14674790873440277\n",
            "Epoch: 0 | Step: 1230 | Train loss: 1.159727692604065 | lr: 0.0009812623274161737 | Min loss:1.1290531158447266\n",
            "Rouge-1:0.15015082895216014 | Rouge-2:0.0607473530775501 | Rouge-l:0.14153013929698774\n",
            "Epoch: 0 | Step: 1240 | Train loss: 1.384023904800415 | lr: 0.0009810157790927023 | Min loss:1.1290531158447266\n",
            "Rouge-1:0.17731890945686163 | Rouge-2:0.07734279420957381 | Rouge-l:0.17731890945686163\n",
            "Epoch: 0 | Step: 1250 | Train loss: 1.4808344841003418 | lr: 0.0009807692307692308 | Min loss:1.1290531158447266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Step: 1255 | Train loss: 1.0719903707504272 | lr: 0.0009807692307692308 | Min loss:1.0719903707504272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.2023438941327173 | Rouge-2:0.07574630095836699 | Rouge-l:0.1920210713098945\n",
            "Epoch: 0 | Step: 1260 | Train loss: 1.2908973693847656 | lr: 0.0009807692307692308 | Min loss:1.0719903707504272\n",
            "Rouge-1:0.1879827255769129 | Rouge-2:0.037677014719583096 | Rouge-l:0.1331700902955276\n",
            "Epoch: 0 | Step: 1270 | Train loss: 1.5332740545272827 | lr: 0.0009805226824457594 | Min loss:1.0719903707504272\n",
            "Rouge-1:0.2398806588138662 | Rouge-2:0.0893693861076659 | Rouge-l:0.21644992288313025\n",
            "Epoch: 0 | Step: 1280 | Train loss: 1.4091038703918457 | lr: 0.000980276134122288 | Min loss:1.0719903707504272\n",
            "Rouge-1:0.2564933577404849 | Rouge-2:0.11084741583208894 | Rouge-l:0.24823624391934668\n",
            "Epoch: 0 | Step: 1290 | Train loss: 1.1548829078674316 | lr: 0.000980276134122288 | Min loss:1.0719903707504272\n",
            "Rouge-1:0.21533937677234452 | Rouge-2:0.13767945344440644 | Rouge-l:0.20513104343901117\n",
            "Epoch: 0 | Step: 1300 | Train loss: 1.3943226337432861 | lr: 0.0009800295857988167 | Min loss:1.0719903707504272\n",
            "Rouge-1:0.1866130850671925 | Rouge-2:0.05693164280615195 | Rouge-l:0.18036308506719254\n",
            "Epoch: 0 | Step: 1310 | Train loss: 1.4279851913452148 | lr: 0.0009800295857988167 | Min loss:1.0719903707504272\n",
            "Rouge-1:0.16124834158475143 | Rouge-2:0.08274456393344408 | Rouge-l:0.15075883109524096\n",
            "Epoch: 0 | Step: 1320 | Train loss: 1.5883615016937256 | lr: 0.0009797830374753452 | Min loss:1.0719903707504272\n",
            "Rouge-1:0.20216070419012835 | Rouge-2:0.07440476073524661 | Rouge-l:0.163056426115262\n",
            "Epoch: 0 | Step: 1330 | Train loss: 1.2549173831939697 | lr: 0.0009795364891518738 | Min loss:1.0719903707504272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Step: 1337 | Train loss: 1.066332221031189 | lr: 0.0009795364891518738 | Min loss:1.066332221031189\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.22183525196523382 | Rouge-2:0.047579964913360716 | Rouge-l:0.20551031784138665\n",
            "Epoch: 0 | Step: 1340 | Train loss: 1.3797869682312012 | lr: 0.0009795364891518738 | Min loss:1.066332221031189\n",
            "Rouge-1:0.15776512314762176 | Rouge-2:0.07543062063260322 | Rouge-l:0.13916694500996993\n",
            "Epoch: 0 | Step: 1350 | Train loss: 1.4276782274246216 | lr: 0.0009792899408284023 | Min loss:1.066332221031189\n",
            "Rouge-1:0.17624934926784644 | Rouge-2:0.06751889533133584 | Rouge-l:0.17193900444026022\n",
            "Epoch: 1 | Step: 0 | Train loss: 1.226524829864502 | lr: 0.0009792899408284023 | Min loss:1.066332221031189\n",
            "Rouge-1:0.19019413404648133 | Rouge-2:0.050974167987042775 | Rouge-l:0.16379931119691712\n",
            "Epoch: 1 | Step: 10 | Train loss: 1.2785831689834595 | lr: 0.000979043392504931 | Min loss:1.066332221031189\n",
            "Rouge-1:0.13374227698398622 | Rouge-2:0.0698265533623394 | Rouge-l:0.12679783253954177\n",
            "Epoch: 1 | Step: 20 | Train loss: 1.3824729919433594 | lr: 0.000979043392504931 | Min loss:1.066332221031189\n",
            "Rouge-1:0.16789465319008598 | Rouge-2:0.028409090087809945 | Rouge-l:0.14954529421572704\n",
            "Epoch: 1 | Step: 30 | Train loss: 1.1948585510253906 | lr: 0.0009787968441814596 | Min loss:1.066332221031189\n",
            "Rouge-1:0.19068835335068152 | Rouge-2:0.09829861932610419 | Rouge-l:0.17082904599137416\n",
            "Epoch: 1 | Step: 40 | Train loss: 1.537501335144043 | lr: 0.0009785502958579882 | Min loss:1.066332221031189\n",
            "Rouge-1:0.1813899243696183 | Rouge-2:0.08235230420287105 | Rouge-l:0.1813899243696183\n",
            "Epoch: 1 | Step: 50 | Train loss: 1.4658734798431396 | lr: 0.0009785502958579882 | Min loss:1.066332221031189\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Step: 54 | Train loss: 1.033966064453125 | lr: 0.0009785502958579882 | Min loss:1.033966064453125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.140502996388696 | Rouge-2:0.01971726135859554 | Rouge-l:0.135502996388696\n",
            "Epoch: 1 | Step: 60 | Train loss: 1.3237383365631104 | lr: 0.0009783037475345167 | Min loss:1.033966064453125\n",
            "Rouge-1:0.2214914013941429 | Rouge-2:0.09821749796922104 | Rouge-l:0.2214914013941429\n",
            "Epoch: 1 | Step: 70 | Train loss: 1.3332929611206055 | lr: 0.0009783037475345167 | Min loss:1.033966064453125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.2446586922613733 | Rouge-2:0.1297720380899417 | Rouge-l:0.20571664016142652\n",
            "Epoch: 1 | Step: 80 | Train loss: 1.024495005607605 | lr: 0.0009780571992110455 | Min loss:1.033966064453125\n",
            "Epoch: 1 | Step: 80 | Train loss: 1.024495005607605 | lr: 0.0009780571992110455 | Min loss:1.024495005607605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.1814477495324041 | Rouge-2:0.07204483669339129 | Rouge-l:0.1708365440994669\n",
            "Epoch: 1 | Step: 90 | Train loss: 1.259053349494934 | lr: 0.000977810650887574 | Min loss:1.024495005607605\n",
            "Rouge-1:0.1704410873867203 | Rouge-2:0.07000383239274019 | Rouge-l:0.15230171957062835\n",
            "Epoch: 1 | Step: 100 | Train loss: 1.1938989162445068 | lr: 0.000977810650887574 | Min loss:1.024495005607605\n",
            "Rouge-1:0.27406284776783696 | Rouge-2:0.14252639052092206 | Rouge-l:0.2620491177907203\n",
            "Epoch: 1 | Step: 110 | Train loss: 1.30508553981781 | lr: 0.0009775641025641026 | Min loss:1.024495005607605\n",
            "Rouge-1:0.13405170726006566 | Rouge-2:0.037881728152829294 | Rouge-l:0.10780987719470615\n",
            "Epoch: 1 | Step: 120 | Train loss: 1.3919458389282227 | lr: 0.0009773175542406312 | Min loss:1.024495005607605\n",
            "Rouge-1:0.15028480868305857 | Rouge-2:0.037289781451687334 | Rouge-l:0.12777097991922978\n",
            "Epoch: 1 | Step: 130 | Train loss: 1.2388681173324585 | lr: 0.0009773175542406312 | Min loss:1.024495005607605\n",
            "Rouge-1:0.22208293470058088 | Rouge-2:0.07162039227555601 | Rouge-l:0.18333649964743076\n",
            "Epoch: 1 | Step: 140 | Train loss: 1.2164307832717896 | lr: 0.0009770710059171597 | Min loss:1.024495005607605\n",
            "Rouge-1:0.1757592553647069 | Rouge-2:0.05156132796044345 | Rouge-l:0.17172699730019078\n",
            "Epoch: 1 | Step: 150 | Train loss: 1.448493480682373 | lr: 0.0009770710059171597 | Min loss:1.024495005607605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Step: 159 | Train loss: 1.0146510601043701 | lr: 0.0009768244575936885 | Min loss:1.0146510601043701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.1888193233869635 | Rouge-2:0.08146008261152134 | Rouge-l:0.18224037601854243\n",
            "Epoch: 1 | Step: 160 | Train loss: 1.2283928394317627 | lr: 0.0009768244575936885 | Min loss:1.0146510601043701\n",
            "Rouge-1:0.16772755389548308 | Rouge-2:0.04538690403437679 | Rouge-l:0.1629198615877908\n",
            "Epoch: 1 | Step: 170 | Train loss: 1.3222434520721436 | lr: 0.000976577909270217 | Min loss:1.0146510601043701\n",
            "Rouge-1:0.17596983726802048 | Rouge-2:0.08576839726514193 | Rouge-l:0.1593978675710508\n",
            "Epoch: 1 | Step: 180 | Train loss: 1.2152243852615356 | lr: 0.000976577909270217 | Min loss:1.0146510601043701\n",
            "Rouge-1:0.18014987593094697 | Rouge-2:0.07534536422364793 | Rouge-l:0.17357092856252593\n",
            "Epoch: 1 | Step: 190 | Train loss: 1.2707403898239136 | lr: 0.0009763313609467456 | Min loss:1.0146510601043701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Step: 198 | Train loss: 0.9656074643135071 | lr: 0.0009763313609467456 | Min loss:0.9656074643135071\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.1292219115727402 | Rouge-2:0.038498588839776623 | Rouge-l:0.1152067600575887\n",
            "Epoch: 1 | Step: 200 | Train loss: 1.4834344387054443 | lr: 0.0009760848126232742 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.16399613855312892 | Rouge-2:0.055609323383878174 | Rouge-l:0.1593665089234993\n",
            "Epoch: 1 | Step: 210 | Train loss: 1.4516154527664185 | lr: 0.0009760848126232742 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.2256746547794919 | Rouge-2:0.06854930701432368 | Rouge-l:0.19078160665114968\n",
            "Epoch: 1 | Step: 220 | Train loss: 1.3996200561523438 | lr: 0.0009758382642998028 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.21859181534728397 | Rouge-2:0.06915178455552698 | Rouge-l:0.20062885238432102\n",
            "Epoch: 1 | Step: 230 | Train loss: 1.056496262550354 | lr: 0.0009758382642998028 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.2014599397330396 | Rouge-2:0.08901040336580744 | Rouge-l:0.2014599397330396\n",
            "Epoch: 1 | Step: 240 | Train loss: 1.4567770957946777 | lr: 0.0009755917159763313 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.23698755620775638 | Rouge-2:0.10855688251156345 | Rouge-l:0.21973554670830442\n",
            "Epoch: 1 | Step: 250 | Train loss: 1.194911241531372 | lr: 0.00097534516765286 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.1635507793935885 | Rouge-2:0.010416666460503475 | Rouge-l:0.14255210214491124\n",
            "Epoch: 1 | Step: 260 | Train loss: 1.3728904724121094 | lr: 0.00097534516765286 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.11744303659069955 | Rouge-2:0.0436921284277146 | Rouge-l:0.10695352610118905\n",
            "Epoch: 1 | Step: 270 | Train loss: 1.3912022113800049 | lr: 0.0009750986193293886 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.22542061408567063 | Rouge-2:0.09707723432243387 | Rouge-l:0.20151188392694047\n",
            "Epoch: 1 | Step: 280 | Train loss: 1.3422185182571411 | lr: 0.0009748520710059172 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.24114931786918214 | Rouge-2:0.11042843494005665 | Rouge-l:0.22480093823955255\n",
            "Epoch: 1 | Step: 290 | Train loss: 1.266768217086792 | lr: 0.0009748520710059172 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.23829893062546145 | Rouge-2:0.0811970165513888 | Rouge-l:0.19676961515499158\n",
            "Epoch: 1 | Step: 300 | Train loss: 1.3758045434951782 | lr: 0.0009746055226824457 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.23913147710912094 | Rouge-2:0.12179122707278006 | Rouge-l:0.20880201251241498\n",
            "Epoch: 1 | Step: 310 | Train loss: 1.156105875968933 | lr: 0.0009746055226824457 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.12757328184159203 | Rouge-2:0.022997835042604862 | Rouge-l:0.12757328184159203\n",
            "Epoch: 1 | Step: 320 | Train loss: 1.1447510719299316 | lr: 0.0009743589743589744 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.15351719260344115 | Rouge-2:0.04859510299073718 | Rouge-l:0.15351719260344115\n",
            "Epoch: 1 | Step: 330 | Train loss: 1.3720921277999878 | lr: 0.000974112426035503 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.2760907726642346 | Rouge-2:0.11023510773634612 | Rouge-l:0.24020801020252477\n",
            "Epoch: 1 | Step: 340 | Train loss: 1.1327208280563354 | lr: 0.000974112426035503 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.21699974875768122 | Rouge-2:0.09246223305816555 | Rouge-l:0.21074974875768124\n",
            "Epoch: 1 | Step: 350 | Train loss: 1.068368911743164 | lr: 0.0009738658777120316 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.1230953968007159 | Rouge-2:0.026575275754920333 | Rouge-l:0.10856669884810491\n",
            "Epoch: 1 | Step: 360 | Train loss: 1.2759751081466675 | lr: 0.0009736193293885602 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.19919502880981627 | Rouge-2:0.08195681279506845 | Rouge-l:0.17966032500787113\n",
            "Epoch: 1 | Step: 370 | Train loss: 1.307902455329895 | lr: 0.0009736193293885602 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.17572874603958327 | Rouge-2:0.04994083721735101 | Rouge-l:0.16516840121199705\n",
            "Epoch: 1 | Step: 380 | Train loss: 1.316355586051941 | lr: 0.0009733727810650887 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.21211303248004837 | Rouge-2:0.08501031852357822 | Rouge-l:0.2001304616739482\n",
            "Epoch: 1 | Step: 390 | Train loss: 1.1966215372085571 | lr: 0.0009733727810650887 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.221393521508762 | Rouge-2:0.09955661996269398 | Rouge-l:0.20860579772359575\n",
            "Epoch: 1 | Step: 400 | Train loss: 1.2679271697998047 | lr: 0.0009731262327416174 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.186509240684571 | Rouge-2:0.06095142492584165 | Rouge-l:0.16293467928106223\n",
            "Epoch: 1 | Step: 410 | Train loss: 1.30231511592865 | lr: 0.000972879684418146 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.2321697136722567 | Rouge-2:0.07669101174811051 | Rouge-l:0.2025239741827672\n",
            "Epoch: 1 | Step: 420 | Train loss: 1.4715931415557861 | lr: 0.000972879684418146 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.23180469404621562 | Rouge-2:0.08299783353820583 | Rouge-l:0.22636991143751994\n",
            "Epoch: 1 | Step: 430 | Train loss: 1.2083560228347778 | lr: 0.0009726331360946747 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.1349830901329693 | Rouge-2:0.04673076848650075 | Rouge-l:0.1287330901329693\n",
            "Epoch: 1 | Step: 440 | Train loss: 1.358778715133667 | lr: 0.0009723865877712031 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.17096364185291993 | Rouge-2:0.06977582433698606 | Rouge-l:0.16203507042434853\n",
            "Epoch: 1 | Step: 450 | Train loss: 1.3178218603134155 | lr: 0.0009723865877712031 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.20548847227456257 | Rouge-2:0.08091468988810586 | Rouge-l:0.17614158074017108\n",
            "Epoch: 1 | Step: 460 | Train loss: 1.3165701627731323 | lr: 0.0009721400394477318 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.31155838234205413 | Rouge-2:0.16376691584041925 | Rouge-l:0.29140056592601404\n",
            "Epoch: 1 | Step: 470 | Train loss: 1.2574291229248047 | lr: 0.0009721400394477318 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.1711351152640868 | Rouge-2:0.07132801669748384 | Rouge-l:0.15704197800918485\n",
            "Epoch: 1 | Step: 480 | Train loss: 1.3299107551574707 | lr: 0.0009718934911242604 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.15051856443115802 | Rouge-2:0.053195952970926066 | Rouge-l:0.14571087212346573\n",
            "Epoch: 1 | Step: 490 | Train loss: 1.1570225954055786 | lr: 0.000971646942800789 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.21800612069734795 | Rouge-2:0.09811705302966954 | Rouge-l:0.21175612069734798\n",
            "Epoch: 1 | Step: 500 | Train loss: 1.2736294269561768 | lr: 0.000971646942800789 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.19874506748235785 | Rouge-2:0.07500102457282518 | Rouge-l:0.17830281602036954\n",
            "Epoch: 1 | Step: 510 | Train loss: 1.2378432750701904 | lr: 0.0009714003944773175 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.14539184639481822 | Rouge-2:0.061793476849819055 | Rouge-l:0.14039184639481822\n",
            "Epoch: 1 | Step: 520 | Train loss: 1.353080153465271 | lr: 0.0009711538461538462 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.18700162379807414 | Rouge-2:0.05215617601605796 | Rouge-l:0.1476856182456556\n",
            "Epoch: 1 | Step: 530 | Train loss: 1.326035737991333 | lr: 0.0009711538461538462 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.1873625610155894 | Rouge-2:0.07427805183106562 | Rouge-l:0.16054202724652625\n",
            "Epoch: 1 | Step: 540 | Train loss: 1.3263357877731323 | lr: 0.0009709072978303747 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.23999598428910543 | Rouge-2:0.0933756475206163 | Rouge-l:0.2283112016804098\n",
            "Epoch: 1 | Step: 550 | Train loss: 1.0567710399627686 | lr: 0.0009709072978303747 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.21866257791558824 | Rouge-2:0.08488976268784056 | Rouge-l:0.20284177591057576\n",
            "Epoch: 1 | Step: 560 | Train loss: 1.3141281604766846 | lr: 0.0009706607495069034 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.2644195443019937 | Rouge-2:0.13396021405043895 | Rouge-l:0.23615947104192045\n",
            "Epoch: 1 | Step: 570 | Train loss: 1.320669174194336 | lr: 0.000970414201183432 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.24171679901114407 | Rouge-2:0.10623006196331335 | Rouge-l:0.21796679901114405\n",
            "Epoch: 1 | Step: 580 | Train loss: 1.3672611713409424 | lr: 0.000970414201183432 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.1449584240382102 | Rouge-2:0.016712453542714945 | Rouge-l:0.12238897959376577\n",
            "Epoch: 1 | Step: 590 | Train loss: 1.4331738948822021 | lr: 0.0009701676528599605 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.18895876098545628 | Rouge-2:0.07574057557574106 | Rouge-l:0.15520064246344797\n",
            "Epoch: 1 | Step: 600 | Train loss: 1.4395766258239746 | lr: 0.0009699211045364892 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.23821002514081727 | Rouge-2:0.09899783767297321 | Rouge-l:0.23321002514081726\n",
            "Epoch: 1 | Step: 610 | Train loss: 1.2371729612350464 | lr: 0.0009699211045364892 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.2134808699885055 | Rouge-2:0.07599382920573752 | Rouge-l:0.1763051869966681\n",
            "Epoch: 1 | Step: 620 | Train loss: 1.1658724546432495 | lr: 0.0009696745562130178 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.21226157723588218 | Rouge-2:0.06052941648362747 | Rouge-l:0.1781415306158356\n",
            "Epoch: 1 | Step: 630 | Train loss: 1.244505524635315 | lr: 0.0009696745562130178 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.24197626302584455 | Rouge-2:0.06385136346046477 | Rouge-l:0.22036406259011465\n",
            "Epoch: 1 | Step: 640 | Train loss: 1.457502841949463 | lr: 0.0009694280078895464 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.2987063240068195 | Rouge-2:0.14716788213959328 | Rouge-l:0.27061288966338515\n",
            "Epoch: 1 | Step: 650 | Train loss: 1.2405786514282227 | lr: 0.0009691814595660749 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.2653602085672486 | Rouge-2:0.11976324579810449 | Rouge-l:0.23222979731183743\n",
            "Epoch: 1 | Step: 660 | Train loss: 1.2064024209976196 | lr: 0.0009691814595660749 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.14086815889725815 | Rouge-2:0.023042928162183764 | Rouge-l:0.12487489290399217\n",
            "Epoch: 1 | Step: 670 | Train loss: 1.335766077041626 | lr: 0.0009689349112426036 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.17175501314273778 | Rouge-2:0.0734073780297333 | Rouge-l:0.15134618346666673\n",
            "Epoch: 1 | Step: 680 | Train loss: 1.370636224746704 | lr: 0.0009686883629191322 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.18015526799053014 | Rouge-2:0.04552218526982234 | Rouge-l:0.1502199231629439\n",
            "Epoch: 1 | Step: 690 | Train loss: 1.3507376909255981 | lr: 0.0009686883629191322 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.20706042792419352 | Rouge-2:0.057686672773306996 | Rouge-l:0.18137562422214845\n",
            "Epoch: 1 | Step: 700 | Train loss: 1.3300755023956299 | lr: 0.0009684418145956607 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.15026157779817925 | Rouge-2:0.082488221254672 | Rouge-l:0.14457975961636108\n",
            "Epoch: 1 | Step: 710 | Train loss: 1.179347276687622 | lr: 0.0009684418145956607 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.2015555622257411 | Rouge-2:0.08206097947856154 | Rouge-l:0.19016839866466448\n",
            "Epoch: 1 | Step: 720 | Train loss: 1.5067986249923706 | lr: 0.0009681952662721893 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.2202017324358856 | Rouge-2:0.05055465250701713 | Rouge-l:0.19429580909093785\n",
            "Epoch: 1 | Step: 730 | Train loss: 1.2754969596862793 | lr: 0.000967948717948718 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.23383539057185085 | Rouge-2:0.07285714111411527 | Rouge-l:0.2188353905718509\n",
            "Epoch: 1 | Step: 740 | Train loss: 1.052133321762085 | lr: 0.000967948717948718 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.20644412189450193 | Rouge-2:0.050153876041239255 | Rouge-l:0.19519412189450194\n",
            "Epoch: 1 | Step: 750 | Train loss: 1.2119710445404053 | lr: 0.0009677021696252465 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.2004273116885122 | Rouge-2:0.08456196443281311 | Rouge-l:0.16699937590256425\n",
            "Epoch: 1 | Step: 760 | Train loss: 1.2648818492889404 | lr: 0.0009674556213017751 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.2527354827727005 | Rouge-2:0.16262676650288213 | Rouge-l:0.2408307208679386\n",
            "Epoch: 1 | Step: 770 | Train loss: 1.2477184534072876 | lr: 0.0009674556213017751 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.1628160621185867 | Rouge-2:0.04574817660278245 | Rouge-l:0.13498868116620577\n",
            "Epoch: 1 | Step: 780 | Train loss: 1.1652947664260864 | lr: 0.0009672090729783038 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.23142222526446332 | Rouge-2:0.11016568156190863 | Rouge-l:0.20283726855450662\n",
            "Epoch: 1 | Step: 790 | Train loss: 1.280505657196045 | lr: 0.0009672090729783038 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.22860586414266384 | Rouge-2:0.03727957841972647 | Rouge-l:0.18022682922830288\n",
            "Epoch: 1 | Step: 800 | Train loss: 1.330305576324463 | lr: 0.0009669625246548324 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.11704452718246966 | Rouge-2:0.01666666636666667 | Rouge-l:0.10826989664059775\n",
            "Epoch: 1 | Step: 810 | Train loss: 1.1993695497512817 | lr: 0.000966715976331361 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.15914776807907344 | Rouge-2:0.04010623192914871 | Rouge-l:0.14357260858944024\n",
            "Epoch: 1 | Step: 820 | Train loss: 1.3275701999664307 | lr: 0.000966715976331361 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.27329640370362657 | Rouge-2:0.13305829261609645 | Rouge-l:0.2485595615983634\n",
            "Epoch: 1 | Step: 830 | Train loss: 1.2821584939956665 | lr: 0.0009664694280078896 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.21177377223295976 | Rouge-2:0.07306316062975526 | Rouge-l:0.18547825402567686\n",
            "Epoch: 1 | Step: 840 | Train loss: 1.1825647354125977 | lr: 0.0009662228796844182 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.2023784029188404 | Rouge-2:0.056437188832298854 | Rouge-l:0.1847520809446923\n",
            "Epoch: 1 | Step: 850 | Train loss: 1.2933881282806396 | lr: 0.0009662228796844182 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.22147701120147292 | Rouge-2:0.10380321251265247 | Rouge-l:0.2066063215463005\n",
            "Epoch: 1 | Step: 860 | Train loss: 1.1547410488128662 | lr: 0.0009659763313609467 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.17437035852194024 | Rouge-2:0.03759057909991337 | Rouge-l:0.1579327802011382\n",
            "Epoch: 1 | Step: 870 | Train loss: 1.2866770029067993 | lr: 0.0009659763313609467 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.1681303496403064 | Rouge-2:0.062394779756571705 | Rouge-l:0.1644538790520711\n",
            "Epoch: 1 | Step: 880 | Train loss: 1.3847198486328125 | lr: 0.0009657297830374754 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.28909035139813416 | Rouge-2:0.10837110926570422 | Rouge-l:0.25758350866565427\n",
            "Epoch: 1 | Step: 890 | Train loss: 1.001357078552246 | lr: 0.000965483234714004 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.21562947427241572 | Rouge-2:0.11564499658135587 | Rouge-l:0.20306819976261178\n",
            "Epoch: 1 | Step: 900 | Train loss: 1.0290371179580688 | lr: 0.000965483234714004 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.20172775111201707 | Rouge-2:0.10398000689489745 | Rouge-l:0.195148803743596\n",
            "Epoch: 1 | Step: 910 | Train loss: 1.0875022411346436 | lr: 0.0009652366863905325 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.2806366024082589 | Rouge-2:0.1597682238233477 | Rouge-l:0.2647670371908676\n",
            "Epoch: 1 | Step: 920 | Train loss: 1.112046241760254 | lr: 0.0009649901380670611 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.18920910969637691 | Rouge-2:0.07095576992755669 | Rouge-l:0.16782734331461055\n",
            "Epoch: 1 | Step: 930 | Train loss: 1.3318582773208618 | lr: 0.0009649901380670611 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.2630777268264062 | Rouge-2:0.12922723282652987 | Rouge-l:0.22976770055299317\n",
            "Epoch: 1 | Step: 940 | Train loss: 1.1986982822418213 | lr: 0.0009647435897435898 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.21907372363184538 | Rouge-2:0.0859427013645938 | Rouge-l:0.20210943791755967\n",
            "Epoch: 1 | Step: 950 | Train loss: 1.1790434122085571 | lr: 0.0009647435897435898 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.24534081175901964 | Rouge-2:0.08239106607911612 | Rouge-l:0.20877532349474842\n",
            "Epoch: 1 | Step: 960 | Train loss: 1.1966114044189453 | lr: 0.0009644970414201185 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.1318378801917516 | Rouge-2:0.037287820392880436 | Rouge-l:0.11263821663067503\n",
            "Epoch: 1 | Step: 970 | Train loss: 1.2059563398361206 | lr: 0.0009642504930966469 | Min loss:0.9656074643135071\n",
            "Rouge-1:0.12611831281109345 | Rouge-2:0.05609776371775544 | Rouge-l:0.12611831281109345\n",
            "Epoch: 1 | Step: 980 | Train loss: 1.1640124320983887 | lr: 0.0009642504930966469 | Min loss:0.9656074643135071\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Step: 985 | Train loss: 0.930592954158783 | lr: 0.0009640039447731756 | Min loss:0.930592954158783\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.18044229431740014 | Rouge-2:0.04147727185364155 | Rouge-l:0.1671847185598244\n",
            "Epoch: 1 | Step: 990 | Train loss: 1.2422908544540405 | lr: 0.0009640039447731756 | Min loss:0.930592954158783\n",
            "Rouge-1:0.2822998808262231 | Rouge-2:0.14288712682755458 | Rouge-l:0.25047604017885305\n",
            "Epoch: 1 | Step: 1000 | Train loss: 0.9985265135765076 | lr: 0.0009637573964497042 | Min loss:0.930592954158783\n",
            "Rouge-1:0.19444384216245156 | Rouge-2:0.038350839181650956 | Rouge-l:0.1682136834322929\n",
            "Epoch: 1 | Step: 1010 | Train loss: 1.1508705615997314 | lr: 0.0009637573964497042 | Min loss:0.930592954158783\n",
            "Rouge-1:0.2245634309733916 | Rouge-2:0.09728463678497533 | Rouge-l:0.20373275393654347\n",
            "Epoch: 1 | Step: 1020 | Train loss: 1.350460410118103 | lr: 0.0009635108481262328 | Min loss:0.930592954158783\n",
            "Rouge-1:0.2314112884783336 | Rouge-2:0.10304509216681604 | Rouge-l:0.21004765211469723\n",
            "Epoch: 1 | Step: 1030 | Train loss: 1.1796050071716309 | lr: 0.0009635108481262328 | Min loss:0.930592954158783\n",
            "Rouge-1:0.34697303996711526 | Rouge-2:0.14867385477398837 | Rouge-l:0.28449421670704195\n",
            "Epoch: 1 | Step: 1040 | Train loss: 1.1623663902282715 | lr: 0.0009632642998027613 | Min loss:0.930592954158783\n",
            "Rouge-1:0.17033480843679744 | Rouge-2:0.06892207366492938 | Rouge-l:0.16465299025497926\n",
            "Epoch: 1 | Step: 1050 | Train loss: 1.1728440523147583 | lr: 0.00096301775147929 | Min loss:0.930592954158783\n",
            "Rouge-1:0.24036926715282958 | Rouge-2:0.08461873090185383 | Rouge-l:0.19778170676635615\n",
            "Epoch: 1 | Step: 1060 | Train loss: 1.195015549659729 | lr: 0.00096301775147929 | Min loss:0.930592954158783\n",
            "Rouge-1:0.20767199089814128 | Rouge-2:0.0735446721885521 | Rouge-l:0.1937406645106438\n",
            "Epoch: 1 | Step: 1070 | Train loss: 1.2737199068069458 | lr: 0.0009627712031558185 | Min loss:0.930592954158783\n",
            "Rouge-1:0.24781202937856317 | Rouge-2:0.08048073850132245 | Rouge-l:0.22191691754595133\n",
            "Epoch: 1 | Step: 1080 | Train loss: 1.2553545236587524 | lr: 0.0009625246548323472 | Min loss:0.930592954158783\n",
            "Rouge-1:0.2142653702409791 | Rouge-2:0.0511477788554744 | Rouge-l:0.2056034825468334\n",
            "Epoch: 1 | Step: 1090 | Train loss: 1.1232495307922363 | lr: 0.0009625246548323472 | Min loss:0.930592954158783\n",
            "Rouge-1:0.22836494472129937 | Rouge-2:0.10125067605565333 | Rouge-l:0.2149263000326547\n",
            "Epoch: 1 | Step: 1100 | Train loss: 1.148248553276062 | lr: 0.0009622781065088757 | Min loss:0.930592954158783\n",
            "Rouge-1:0.14648692642362168 | Rouge-2:0.026339284823216097 | Rouge-l:0.13636787880457407\n",
            "Epoch: 1 | Step: 1110 | Train loss: 1.2740901708602905 | lr: 0.0009622781065088757 | Min loss:0.930592954158783\n",
            "Rouge-1:0.2730710775904526 | Rouge-2:0.09277575320464683 | Rouge-l:0.22236297542760913\n",
            "Epoch: 1 | Step: 1120 | Train loss: 1.1457008123397827 | lr: 0.0009620315581854044 | Min loss:0.930592954158783\n",
            "Rouge-1:0.2603082404729336 | Rouge-2:0.13211606648398203 | Rouge-l:0.23106872998342315\n",
            "Epoch: 1 | Step: 1130 | Train loss: 1.0673787593841553 | lr: 0.0009617850098619329 | Min loss:0.930592954158783\n",
            "Rouge-1:0.20270477231462158 | Rouge-2:0.05676555399002232 | Rouge-l:0.18340201858015281\n",
            "Epoch: 1 | Step: 1140 | Train loss: 1.3115320205688477 | lr: 0.0009617850098619329 | Min loss:0.930592954158783\n",
            "Rouge-1:0.1897166115730281 | Rouge-2:0.08683809968130252 | Rouge-l:0.18450827823969473\n",
            "Epoch: 1 | Step: 1150 | Train loss: 1.054735779762268 | lr: 0.0009615384615384616 | Min loss:0.930592954158783\n",
            "Rouge-1:0.24718444694192945 | Rouge-2:0.10217969159736848 | Rouge-l:0.23324525057372703\n",
            "Epoch: 1 | Step: 1160 | Train loss: 1.275220513343811 | lr: 0.0009612919132149903 | Min loss:0.930592954158783\n",
            "Rouge-1:0.2546790983849399 | Rouge-2:0.09277777600213583 | Rouge-l:0.23371950242534398\n",
            "Epoch: 1 | Step: 1170 | Train loss: 1.3235729932785034 | lr: 0.0009612919132149903 | Min loss:0.930592954158783\n",
            "Rouge-1:0.2654582405372152 | Rouge-2:0.0812733074072183 | Rouge-l:0.2357850202389949\n",
            "Epoch: 1 | Step: 1180 | Train loss: 1.2500027418136597 | lr: 0.0009610453648915187 | Min loss:0.930592954158783\n",
            "Rouge-1:0.15824321844809258 | Rouge-2:0.06100692640998927 | Rouge-l:0.13362444645416915\n",
            "Epoch: 1 | Step: 1190 | Train loss: 1.143447995185852 | lr: 0.0009610453648915187 | Min loss:0.930592954158783\n",
            "Rouge-1:0.27918251148589057 | Rouge-2:0.12646416464170324 | Rouge-l:0.2493566026277237\n",
            "Epoch: 1 | Step: 1200 | Train loss: 1.0358525514602661 | lr: 0.0009607988165680473 | Min loss:0.930592954158783\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Step: 1203 | Train loss: 0.9106767177581787 | lr: 0.0009607988165680473 | Min loss:0.9106767177581787\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.25670745791600397 | Rouge-2:0.10184809619681118 | Rouge-l:0.23587412458267057\n",
            "Epoch: 1 | Step: 1210 | Train loss: 1.1991297006607056 | lr: 0.000960552268244576 | Min loss:0.9106767177581787\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Step: 1219 | Train loss: 0.8824707269668579 | lr: 0.000960552268244576 | Min loss:0.8824707269668579\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.217026270656162 | Rouge-2:0.09536030355908703 | Rouge-l:0.19181727266490592\n",
            "Epoch: 1 | Step: 1220 | Train loss: 1.2478420734405518 | lr: 0.000960552268244576 | Min loss:0.8824707269668579\n",
            "Rouge-1:0.1840874937088359 | Rouge-2:0.06162066982477624 | Rouge-l:0.1547182807458729\n",
            "Epoch: 1 | Step: 1230 | Train loss: 1.1137131452560425 | lr: 0.0009603057199211046 | Min loss:0.8824707269668579\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Step: 1238 | Train loss: 0.8718587160110474 | lr: 0.0009603057199211046 | Min loss:0.8718587160110474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.1621656809672089 | Rouge-2:0.0328876996673218 | Rouge-l:0.15142006693212118\n",
            "Epoch: 1 | Step: 1240 | Train loss: 1.507832407951355 | lr: 0.0009600591715976331 | Min loss:0.8718587160110474\n",
            "Rouge-1:0.19424859961711502 | Rouge-2:0.08952738584021308 | Rouge-l:0.18329621866473408\n",
            "Epoch: 1 | Step: 1250 | Train loss: 1.172821044921875 | lr: 0.0009600591715976331 | Min loss:0.8718587160110474\n",
            "Rouge-1:0.25105292525202366 | Rouge-2:0.09254943618553334 | Rouge-l:0.21049977782101578\n",
            "Epoch: 1 | Step: 1260 | Train loss: 1.0490423440933228 | lr: 0.0009598126232741618 | Min loss:0.8718587160110474\n",
            "Rouge-1:0.245450618806545 | Rouge-2:0.0978868250836432 | Rouge-l:0.2207565769385901\n",
            "Epoch: 1 | Step: 1270 | Train loss: 1.1893945932388306 | lr: 0.0009598126232741618 | Min loss:0.8718587160110474\n",
            "Rouge-1:0.17024682273354366 | Rouge-2:0.0388361626274554 | Rouge-l:0.1521857774985854\n",
            "Epoch: 1 | Step: 1280 | Train loss: 1.355125069618225 | lr: 0.0009595660749506904 | Min loss:0.8718587160110474\n",
            "Rouge-1:0.2778891605926071 | Rouge-2:0.11702236643348649 | Rouge-l:0.24150712839442048\n",
            "Epoch: 1 | Step: 1290 | Train loss: 1.1408843994140625 | lr: 0.000959319526627219 | Min loss:0.8718587160110474\n",
            "Rouge-1:0.25670299071452524 | Rouge-2:0.0888157193386417 | Rouge-l:0.2162588427376087\n",
            "Epoch: 1 | Step: 1300 | Train loss: 1.461584210395813 | lr: 0.000959319526627219 | Min loss:0.8718587160110474\n",
            "Rouge-1:0.20658866402273987 | Rouge-2:0.06460976192594124 | Rouge-l:0.17673336577377052\n",
            "Epoch: 1 | Step: 1310 | Train loss: 1.317943811416626 | lr: 0.0009590729783037475 | Min loss:0.8718587160110474\n",
            "Rouge-1:0.2209906317527804 | Rouge-2:0.1019047596488025 | Rouge-l:0.19284013641478506\n",
            "Epoch: 1 | Step: 1320 | Train loss: 1.0977234840393066 | lr: 0.0009588264299802762 | Min loss:0.8718587160110474\n",
            "Rouge-1:0.260096514745376 | Rouge-2:0.15781356460860663 | Rouge-l:0.246190264745376\n",
            "Epoch: 1 | Step: 1330 | Train loss: 1.038275122642517 | lr: 0.0009588264299802762 | Min loss:0.8718587160110474\n",
            "Rouge-1:0.2261939683297562 | Rouge-2:0.0643712569480108 | Rouge-l:0.17801305408762919\n",
            "Epoch: 1 | Step: 1340 | Train loss: 1.3660062551498413 | lr: 0.0009585798816568047 | Min loss:0.8718587160110474\n",
            "Rouge-1:0.17548493797461537 | Rouge-2:0.045368740568023244 | Rouge-l:0.15448502126630287\n",
            "Epoch: 1 | Step: 1350 | Train loss: 1.295512318611145 | lr: 0.0009585798816568047 | Min loss:0.8718587160110474\n",
            "Rouge-1:0.27659758977086285 | Rouge-2:0.13466288554707959 | Rouge-l:0.26556817800615695\n",
            "Epoch: 2 | Step: 0 | Train loss: 0.9065753221511841 | lr: 0.0009583333333333334 | Min loss:0.8718587160110474\n",
            "Rouge-1:0.24023485726426647 | Rouge-2:0.0881130335143807 | Rouge-l:0.20804660882315762\n",
            "Epoch: 2 | Step: 10 | Train loss: 1.1020092964172363 | lr: 0.0009583333333333334 | Min loss:0.8718587160110474\n",
            "Rouge-1:0.1481202625930179 | Rouge-2:0.07196176331041018 | Rouge-l:0.13486994330821586\n",
            "Epoch: 2 | Step: 20 | Train loss: 1.2471762895584106 | lr: 0.0009580867850098619 | Min loss:0.8718587160110474\n",
            "Rouge-1:0.24085326148816197 | Rouge-2:0.06848161320610834 | Rouge-l:0.22404935425275319\n",
            "Epoch: 2 | Step: 30 | Train loss: 1.2308114767074585 | lr: 0.0009580867850098619 | Min loss:0.8718587160110474\n",
            "Rouge-1:0.2567953123293478 | Rouge-2:0.09632902150686642 | Rouge-l:0.22554684454862206\n",
            "Epoch: 2 | Step: 40 | Train loss: 1.0588338375091553 | lr: 0.0009578402366863905 | Min loss:0.8718587160110474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2 | Step: 43 | Train loss: 0.8611001372337341 | lr: 0.0009578402366863905 | Min loss:0.8611001372337341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.2682740603299796 | Rouge-2:0.11818183338737501 | Rouge-l:0.2538649187469249\n",
            "Epoch: 2 | Step: 50 | Train loss: 1.2184985876083374 | lr: 0.0009575936883629191 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.16114170871355402 | Rouge-2:0.022058822629757825 | Rouge-l:0.1285976757061343\n",
            "Epoch: 2 | Step: 60 | Train loss: 1.3735607862472534 | lr: 0.0009575936883629191 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.21677772549059576 | Rouge-2:0.11148177783639625 | Rouge-l:0.20740272549059577\n",
            "Epoch: 2 | Step: 70 | Train loss: 1.0491995811462402 | lr: 0.0009573471400394478 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2224165443887169 | Rouge-2:0.06676210279175675 | Rouge-l:0.18037917705243653\n",
            "Epoch: 2 | Step: 80 | Train loss: 1.3196303844451904 | lr: 0.0009571005917159762 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.18876023301136952 | Rouge-2:0.05195422843662253 | Rouge-l:0.1631097112670978\n",
            "Epoch: 2 | Step: 90 | Train loss: 1.2718982696533203 | lr: 0.0009571005917159762 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.26511970786932476 | Rouge-2:0.08324186015904854 | Rouge-l:0.22124165985524732\n",
            "Epoch: 2 | Step: 100 | Train loss: 1.2590423822402954 | lr: 0.0009568540433925049 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2652276551632468 | Rouge-2:0.13372684281197 | Rouge-l:0.2452098432336702\n",
            "Epoch: 2 | Step: 110 | Train loss: 1.1968493461608887 | lr: 0.0009568540433925049 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.14435738025596806 | Rouge-2:0.03792588029858879 | Rouge-l:0.11809231467638635\n",
            "Epoch: 2 | Step: 120 | Train loss: 1.2791465520858765 | lr: 0.0009566074950690336 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.213363108793794 | Rouge-2:0.11126799583691208 | Rouge-l:0.213363108793794\n",
            "Epoch: 2 | Step: 130 | Train loss: 1.1164424419403076 | lr: 0.0009563609467455622 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.187167361244028 | Rouge-2:0.09792282522752294 | Rouge-l:0.1663412843834684\n",
            "Epoch: 2 | Step: 140 | Train loss: 1.119468092918396 | lr: 0.0009563609467455622 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.24698520619434225 | Rouge-2:0.0878720221198298 | Rouge-l:0.21674956574250936\n",
            "Epoch: 2 | Step: 150 | Train loss: 1.1187374591827393 | lr: 0.0009561143984220908 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2174565004962586 | Rouge-2:0.07092568761714543 | Rouge-l:0.20041104595080406\n",
            "Epoch: 2 | Step: 160 | Train loss: 1.2791922092437744 | lr: 0.0009558678500986193 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.19780458174258814 | Rouge-2:0.056950969084233284 | Rouge-l:0.17189840458641104\n",
            "Epoch: 2 | Step: 170 | Train loss: 1.2744860649108887 | lr: 0.0009558678500986193 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2792832114596343 | Rouge-2:0.13863626299779766 | Rouge-l:0.25146309679169365\n",
            "Epoch: 2 | Step: 180 | Train loss: 1.0214952230453491 | lr: 0.000955621301775148 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2048177166569022 | Rouge-2:0.07775950179154754 | Rouge-l:0.2048177166569022\n",
            "Epoch: 2 | Step: 190 | Train loss: 1.1184089183807373 | lr: 0.000955621301775148 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.17795982383858114 | Rouge-2:0.05496856210526465 | Rouge-l:0.1616751016163589\n",
            "Epoch: 2 | Step: 200 | Train loss: 1.0946385860443115 | lr: 0.0009553747534516765 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.17135404448416428 | Rouge-2:0.039690393915920386 | Rouge-l:0.15451237133577608\n",
            "Epoch: 2 | Step: 210 | Train loss: 1.23345148563385 | lr: 0.0009551282051282052 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.17042733588668596 | Rouge-2:0.06659887363401068 | Rouge-l:0.16209400255335266\n",
            "Epoch: 2 | Step: 220 | Train loss: 1.162604808807373 | lr: 0.0009551282051282052 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2036322917065946 | Rouge-2:0.1114632895668109 | Rouge-l:0.18257373314803604\n",
            "Epoch: 2 | Step: 230 | Train loss: 1.2350021600723267 | lr: 0.0009548816568047337 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.26353564027193893 | Rouge-2:0.10746582528023868 | Rouge-l:0.2253261645624633\n",
            "Epoch: 2 | Step: 240 | Train loss: 1.310097336769104 | lr: 0.0009546351084812623 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.23168518209931932 | Rouge-2:0.07467458422162733 | Rouge-l:0.19693638204879516\n",
            "Epoch: 2 | Step: 250 | Train loss: 1.050598382949829 | lr: 0.0009546351084812623 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.19443264332130372 | Rouge-2:0.08521854451572387 | Rouge-l:0.17968751588502188\n",
            "Epoch: 2 | Step: 260 | Train loss: 1.0805028676986694 | lr: 0.0009543885601577909 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.24273377559041184 | Rouge-2:0.0687085856559868 | Rouge-l:0.2119416510482873\n",
            "Epoch: 2 | Step: 270 | Train loss: 0.9701271057128906 | lr: 0.0009543885601577909 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.22795346014575016 | Rouge-2:0.08975406566108575 | Rouge-l:0.20355382960387822\n",
            "Epoch: 2 | Step: 280 | Train loss: 1.020767092704773 | lr: 0.0009541420118343196 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.23398176311942326 | Rouge-2:0.10050168875326879 | Rouge-l:0.1874601960286371\n",
            "Epoch: 2 | Step: 290 | Train loss: 1.061083197593689 | lr: 0.0009538954635108482 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2151234453144744 | Rouge-2:0.0890839926278843 | Rouge-l:0.19541668468380077\n",
            "Epoch: 2 | Step: 300 | Train loss: 1.3313753604888916 | lr: 0.0009538954635108482 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2311080138377458 | Rouge-2:0.084949941564163 | Rouge-l:0.2005230384682877\n",
            "Epoch: 2 | Step: 310 | Train loss: 1.146643877029419 | lr: 0.0009536489151873767 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.23350633326699555 | Rouge-2:0.12751374378164834 | Rouge-l:0.21157005875719162\n",
            "Epoch: 2 | Step: 320 | Train loss: 0.9975872039794922 | lr: 0.0009534023668639054 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.21969947393978104 | Rouge-2:0.10879201338084851 | Rouge-l:0.21969947393978104\n",
            "Epoch: 2 | Step: 330 | Train loss: 0.9950345158576965 | lr: 0.0009534023668639054 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2823835704755023 | Rouge-2:0.1509255846689407 | Rouge-l:0.26080618952312135\n",
            "Epoch: 2 | Step: 340 | Train loss: 1.05070960521698 | lr: 0.000953155818540434 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.1997598065081547 | Rouge-2:0.08699736297638806 | Rouge-l:0.1997598065081547\n",
            "Epoch: 2 | Step: 350 | Train loss: 1.0275273323059082 | lr: 0.000953155818540434 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.1961036582229677 | Rouge-2:0.05564099466590928 | Rouge-l:0.18712929924860874\n",
            "Epoch: 2 | Step: 360 | Train loss: 0.9287980794906616 | lr: 0.0009529092702169625 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2357222527599092 | Rouge-2:0.06884398377368631 | Rouge-l:0.21323236519649225\n",
            "Epoch: 2 | Step: 370 | Train loss: 1.1462914943695068 | lr: 0.0009526627218934911 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.27015192314306297 | Rouge-2:0.17406885764147895 | Rouge-l:0.26390192314306293\n",
            "Epoch: 2 | Step: 380 | Train loss: 1.0696072578430176 | lr: 0.0009526627218934911 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.25048707267328507 | Rouge-2:0.1283321696614906 | Rouge-l:0.243908125304864\n",
            "Epoch: 2 | Step: 390 | Train loss: 1.276252031326294 | lr: 0.0009524161735700198 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.27200040017269594 | Rouge-2:0.15824847684724774 | Rouge-l:0.2671927078650036\n",
            "Epoch: 2 | Step: 400 | Train loss: 1.0258699655532837 | lr: 0.0009521696252465483 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2075329347620778 | Rouge-2:0.026933383122336705 | Rouge-l:0.16143277586300586\n",
            "Epoch: 2 | Step: 410 | Train loss: 1.2103897333145142 | lr: 0.0009521696252465483 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.22779994800897663 | Rouge-2:0.06151788082330101 | Rouge-l:0.2027024821220371\n",
            "Epoch: 2 | Step: 420 | Train loss: 1.2571512460708618 | lr: 0.0009519230769230769 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.20971852940341787 | Rouge-2:0.07158755448136002 | Rouge-l:0.19578995797484647\n",
            "Epoch: 2 | Step: 430 | Train loss: 1.1344190835952759 | lr: 0.0009519230769230769 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.20691149256020377 | Rouge-2:0.040273769621020486 | Rouge-l:0.1517245303879475\n",
            "Epoch: 2 | Step: 440 | Train loss: 1.2836567163467407 | lr: 0.0009516765285996055 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2367472298477304 | Rouge-2:0.1020784967191616 | Rouge-l:0.19875712891605343\n",
            "Epoch: 2 | Step: 450 | Train loss: 1.3057506084442139 | lr: 0.0009514299802761342 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.23240301431564248 | Rouge-2:0.07232350512992265 | Rouge-l:0.20936845878108695\n",
            "Epoch: 2 | Step: 460 | Train loss: 1.2480462789535522 | lr: 0.0009514299802761342 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.1611725582232074 | Rouge-2:0.0758255213202963 | Rouge-l:0.15022017727082643\n",
            "Epoch: 2 | Step: 470 | Train loss: 1.3043997287750244 | lr: 0.0009511834319526627 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.20869319334399722 | Rouge-2:0.0515542315660628 | Rouge-l:0.1837484288841219\n",
            "Epoch: 2 | Step: 480 | Train loss: 1.1740913391113281 | lr: 0.0009509368836291914 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.20360692249446646 | Rouge-2:0.043835468245992756 | Rouge-l:0.18369270680819197\n",
            "Epoch: 2 | Step: 490 | Train loss: 1.2360576391220093 | lr: 0.0009509368836291914 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.1737387476974284 | Rouge-2:0.02781198564148841 | Rouge-l:0.14885424971871378\n",
            "Epoch: 2 | Step: 500 | Train loss: 1.3420461416244507 | lr: 0.00095069033530572 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.23208115087820883 | Rouge-2:0.09045641280997958 | Rouge-l:0.19426668227426658\n",
            "Epoch: 2 | Step: 510 | Train loss: 1.2442066669464111 | lr: 0.00095069033530572 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.24423638008662046 | Rouge-2:0.10870744829011506 | Rouge-l:0.21941519934572157\n",
            "Epoch: 2 | Step: 520 | Train loss: 1.0958247184753418 | lr: 0.0009504437869822485 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.24144375879946 | Rouge-2:0.06671712348537422 | Rouge-l:0.18107244318076807\n",
            "Epoch: 2 | Step: 530 | Train loss: 1.1909449100494385 | lr: 0.0009501972386587772 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.23493519471320076 | Rouge-2:0.07756362432104685 | Rouge-l:0.2114572289654982\n",
            "Epoch: 2 | Step: 540 | Train loss: 1.1146905422210693 | lr: 0.0009501972386587772 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.29416413052909746 | Rouge-2:0.15986046718471625 | Rouge-l:0.26033955011209803\n",
            "Epoch: 2 | Step: 550 | Train loss: 0.9853808879852295 | lr: 0.0009499506903353058 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2605794593091101 | Rouge-2:0.1021474426005476 | Rouge-l:0.23412929591041726\n",
            "Epoch: 2 | Step: 560 | Train loss: 1.3215057849884033 | lr: 0.0009497041420118343 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.23252029185883527 | Rouge-2:0.11302282422092844 | Rouge-l:0.22789066222920565\n",
            "Epoch: 2 | Step: 570 | Train loss: 0.9514337182044983 | lr: 0.0009497041420118343 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.24594210357199642 | Rouge-2:0.06764265153521587 | Rouge-l:0.1992392050212718\n",
            "Epoch: 2 | Step: 580 | Train loss: 1.2000652551651 | lr: 0.0009494575936883629 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2650312149875169 | Rouge-2:0.10086059417173278 | Rouge-l:0.23939284564297647\n",
            "Epoch: 2 | Step: 590 | Train loss: 1.2271060943603516 | lr: 0.0009494575936883629 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2972960021450118 | Rouge-2:0.12304938595802976 | Rouge-l:0.23696578623797906\n",
            "Epoch: 2 | Step: 600 | Train loss: 1.1742534637451172 | lr: 0.0009492110453648916 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2553064360345984 | Rouge-2:0.1110283721745338 | Rouge-l:0.23351915533284406\n",
            "Epoch: 2 | Step: 610 | Train loss: 1.1312391757965088 | lr: 0.0009489644970414202 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2515135629109342 | Rouge-2:0.08934771615268633 | Rouge-l:0.19091128085391076\n",
            "Epoch: 2 | Step: 620 | Train loss: 1.2080339193344116 | lr: 0.0009489644970414202 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.23364704621095303 | Rouge-2:0.09597289580452736 | Rouge-l:0.22511116658132338\n",
            "Epoch: 2 | Step: 630 | Train loss: 1.3562729358673096 | lr: 0.0009487179487179487 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.25524054309527183 | Rouge-2:0.09051941223562493 | Rouge-l:0.21958180965428037\n",
            "Epoch: 2 | Step: 640 | Train loss: 1.312765121459961 | lr: 0.0009484714003944773 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.25153763537432444 | Rouge-2:0.09034130464570729 | Rouge-l:0.23534277950555557\n",
            "Epoch: 2 | Step: 650 | Train loss: 1.2173107862472534 | lr: 0.0009484714003944773 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2544207590134582 | Rouge-2:0.09886577788752039 | Rouge-l:0.24354112938382855\n",
            "Epoch: 2 | Step: 660 | Train loss: 1.1335375308990479 | lr: 0.000948224852071006 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.19710856388003947 | Rouge-2:0.07520179113153949 | Rouge-l:0.18811235175882735\n",
            "Epoch: 2 | Step: 670 | Train loss: 1.417627215385437 | lr: 0.000948224852071006 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.26963900570232335 | Rouge-2:0.12995672065865657 | Rouge-l:0.2414571875205051\n",
            "Epoch: 2 | Step: 680 | Train loss: 1.0648558139801025 | lr: 0.0009479783037475345 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2355707611943957 | Rouge-2:0.061237372226838435 | Rouge-l:0.20336662954173462\n",
            "Epoch: 2 | Step: 690 | Train loss: 1.0539271831512451 | lr: 0.0009477317554240631 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2853070769217217 | Rouge-2:0.12635906559312773 | Rouge-l:0.24009303170767654\n",
            "Epoch: 2 | Step: 700 | Train loss: 1.0492663383483887 | lr: 0.0009477317554240631 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.16716889167984283 | Rouge-2:0.058727901959714494 | Rouge-l:0.13901637898785651\n",
            "Epoch: 2 | Step: 710 | Train loss: 1.1421825885772705 | lr: 0.0009474852071005917 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2603316544616074 | Rouge-2:0.0838815475966117 | Rouge-l:0.23173600494204485\n",
            "Epoch: 2 | Step: 720 | Train loss: 1.2046290636062622 | lr: 0.0009472386587771203 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.22781563635306515 | Rouge-2:0.0724831965099218 | Rouge-l:0.19793036537404418\n",
            "Epoch: 2 | Step: 730 | Train loss: 1.0250502824783325 | lr: 0.0009472386587771203 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.21902702744457858 | Rouge-2:0.06428719810648037 | Rouge-l:0.18142122807153788\n",
            "Epoch: 2 | Step: 740 | Train loss: 1.1552174091339111 | lr: 0.000946992110453649 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.19634769492103388 | Rouge-2:0.056961930720498946 | Rouge-l:0.17650642507976408\n",
            "Epoch: 2 | Step: 750 | Train loss: 1.2062445878982544 | lr: 0.000946992110453649 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2378179244502151 | Rouge-2:0.06902301469169646 | Rouge-l:0.21894328057557122\n",
            "Epoch: 2 | Step: 760 | Train loss: 1.1134341955184937 | lr: 0.0009467455621301775 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.252035627104031 | Rouge-2:0.09586219524451042 | Rouge-l:0.21836494962663852\n",
            "Epoch: 2 | Step: 770 | Train loss: 1.18867027759552 | lr: 0.0009464990138067062 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2232700509463527 | Rouge-2:0.1072134338447387 | Rouge-l:0.2152343366606384\n",
            "Epoch: 2 | Step: 780 | Train loss: 1.0922828912734985 | lr: 0.0009464990138067062 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2553852822785652 | Rouge-2:0.08212401218770932 | Rouge-l:0.21963643325382942\n",
            "Epoch: 2 | Step: 790 | Train loss: 1.208401083946228 | lr: 0.0009462524654832347 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.19127473887710172 | Rouge-2:0.057328719890039015 | Rouge-l:0.17472335547789222\n",
            "Epoch: 2 | Step: 800 | Train loss: 0.8947966694831848 | lr: 0.0009460059171597634 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.2256631963058115 | Rouge-2:0.06093410051537532 | Rouge-l:0.18877722191160956\n",
            "Epoch: 2 | Step: 810 | Train loss: 1.2676606178283691 | lr: 0.0009460059171597634 | Min loss:0.8611001372337341\n",
            "Rouge-1:0.17388408951837953 | Rouge-2:0.0781012075922877 | Rouge-l:0.16581957338934727\n",
            "Epoch: 2 | Step: 820 | Train loss: 0.9871296286582947 | lr: 0.0009457593688362919 | Min loss:0.8611001372337341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2 | Step: 824 | Train loss: 0.799911379814148 | lr: 0.0009457593688362919 | Min loss:0.799911379814148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.1891295776098611 | Rouge-2:0.05589918491886546 | Rouge-l:0.16676122118978054\n",
            "Epoch: 2 | Step: 830 | Train loss: 1.1933518648147583 | lr: 0.0009457593688362919 | Min loss:0.799911379814148\n",
            "Rouge-1:0.26307130717084254 | Rouge-2:0.1051657571614962 | Rouge-l:0.24980020327473862\n",
            "Epoch: 2 | Step: 840 | Train loss: 1.104418396949768 | lr: 0.0009455128205128205 | Min loss:0.799911379814148\n",
            "Rouge-1:0.23248026874410832 | Rouge-2:0.09411324782348914 | Rouge-l:0.21420741928174272\n",
            "Epoch: 2 | Step: 850 | Train loss: 1.093281865119934 | lr: 0.0009452662721893491 | Min loss:0.799911379814148\n",
            "Rouge-1:0.22502566277586283 | Rouge-2:0.09315850881696824 | Rouge-l:0.2097306024440378\n",
            "Epoch: 2 | Step: 860 | Train loss: 1.150936245918274 | lr: 0.0009452662721893491 | Min loss:0.799911379814148\n",
            "Rouge-1:0.30150619598168815 | Rouge-2:0.10753507547659617 | Rouge-l:0.2580172346317355\n",
            "Epoch: 2 | Step: 870 | Train loss: 1.265974521636963 | lr: 0.0009450197238658778 | Min loss:0.799911379814148\n",
            "Rouge-1:0.20601605860202019 | Rouge-2:0.05892586859745585 | Rouge-l:0.18475335391540249\n",
            "Epoch: 2 | Step: 880 | Train loss: 1.3233530521392822 | lr: 0.0009447731755424063 | Min loss:0.799911379814148\n",
            "Rouge-1:0.2824960044115408 | Rouge-2:0.10192926503929499 | Rouge-l:0.23793581922635562\n",
            "Epoch: 2 | Step: 890 | Train loss: 1.1767245531082153 | lr: 0.0009447731755424063 | Min loss:0.799911379814148\n",
            "Rouge-1:0.25777748358683794 | Rouge-2:0.07725965455467285 | Rouge-l:0.23231452062387498\n",
            "Epoch: 2 | Step: 900 | Train loss: 1.2347605228424072 | lr: 0.0009445266272189349 | Min loss:0.799911379814148\n",
            "Rouge-1:0.25554232262467136 | Rouge-2:0.11363852399420699 | Rouge-l:0.23526454484689363\n",
            "Epoch: 2 | Step: 910 | Train loss: 0.9875673055648804 | lr: 0.0009445266272189349 | Min loss:0.799911379814148\n",
            "Rouge-1:0.3556716276903657 | Rouge-2:0.1659469272132993 | Rouge-l:0.3302820612947018\n",
            "Epoch: 2 | Step: 920 | Train loss: 1.099749207496643 | lr: 0.0009442800788954635 | Min loss:0.799911379814148\n",
            "Rouge-1:0.21002175392840666 | Rouge-2:0.06581576194863963 | Rouge-l:0.1921869324998352\n",
            "Epoch: 2 | Step: 930 | Train loss: 1.100653052330017 | lr: 0.0009440335305719922 | Min loss:0.799911379814148\n",
            "Rouge-1:0.2268642073626003 | Rouge-2:0.1176549482767294 | Rouge-l:0.20715744673192663\n",
            "Epoch: 2 | Step: 940 | Train loss: 1.054305076599121 | lr: 0.0009440335305719922 | Min loss:0.799911379814148\n",
            "Rouge-1:0.2528765629187661 | Rouge-2:0.11065149831587928 | Rouge-l:0.23001331505551825\n",
            "Epoch: 2 | Step: 950 | Train loss: 1.2175617218017578 | lr: 0.0009437869822485208 | Min loss:0.799911379814148\n",
            "Rouge-1:0.28763067288596245 | Rouge-2:0.13387210930498086 | Rouge-l:0.2673579273143038\n",
            "Epoch: 2 | Step: 960 | Train loss: 1.059910774230957 | lr: 0.0009435404339250493 | Min loss:0.799911379814148\n",
            "Rouge-1:0.2179830743380285 | Rouge-2:0.06903388103056304 | Rouge-l:0.19153040523988527\n",
            "Epoch: 2 | Step: 970 | Train loss: 1.0400725603103638 | lr: 0.0009435404339250493 | Min loss:0.799911379814148\n",
            "Rouge-1:0.36851022980751247 | Rouge-2:0.21805409272824455 | Rouge-l:0.35830189647417915\n",
            "Epoch: 2 | Step: 980 | Train loss: 1.1360217332839966 | lr: 0.000943293885601578 | Min loss:0.799911379814148\n",
            "Rouge-1:0.21990144873970707 | Rouge-2:0.06268781293349045 | Rouge-l:0.20348831100303996\n",
            "Epoch: 2 | Step: 990 | Train loss: 1.156580924987793 | lr: 0.000943293885601578 | Min loss:0.799911379814148\n",
            "Rouge-1:0.3050679371193596 | Rouge-2:0.13799957998335502 | Rouge-l:0.2818952799802339\n",
            "Epoch: 2 | Step: 1000 | Train loss: 0.9484034180641174 | lr: 0.0009430473372781065 | Min loss:0.799911379814148\n",
            "Rouge-1:0.3568320077735843 | Rouge-2:0.16164443011350915 | Rouge-l:0.31564256316022665\n",
            "Epoch: 2 | Step: 1010 | Train loss: 1.0283352136611938 | lr: 0.0009428007889546352 | Min loss:0.799911379814148\n",
            "Rouge-1:0.17501353741120282 | Rouge-2:0.03100350818402309 | Rouge-l:0.1466140562737186\n",
            "Epoch: 2 | Step: 1020 | Train loss: 1.1386299133300781 | lr: 0.0009428007889546352 | Min loss:0.799911379814148\n",
            "Rouge-1:0.1837617064689676 | Rouge-2:0.04678549822710596 | Rouge-l:0.16135194711067885\n",
            "Epoch: 2 | Step: 1030 | Train loss: 1.1378239393234253 | lr: 0.0009425542406311637 | Min loss:0.799911379814148\n",
            "Rouge-1:0.23627314364265395 | Rouge-2:0.09201927075380148 | Rouge-l:0.20704033940984973\n",
            "Epoch: 2 | Step: 1040 | Train loss: 1.419293761253357 | lr: 0.0009423076923076923 | Min loss:0.799911379814148\n",
            "Rouge-1:0.25118022441024085 | Rouge-2:0.08335358433754249 | Rouge-l:0.21569146585696622\n",
            "Epoch: 2 | Step: 1050 | Train loss: 1.1982015371322632 | lr: 0.0009423076923076923 | Min loss:0.799911379814148\n",
            "Rouge-1:0.23402682479370177 | Rouge-2:0.06987007082412712 | Rouge-l:0.20568352149422736\n",
            "Epoch: 2 | Step: 1060 | Train loss: 1.140816330909729 | lr: 0.0009420611439842209 | Min loss:0.799911379814148\n",
            "Rouge-1:0.16410906068530817 | Rouge-2:0.04395138517085819 | Rouge-l:0.13322133490534102\n",
            "Epoch: 2 | Step: 1070 | Train loss: 1.1696090698242188 | lr: 0.0009420611439842209 | Min loss:0.799911379814148\n",
            "Rouge-1:0.2286448640366881 | Rouge-2:0.07376858719295172 | Rouge-l:0.1891258689386489\n",
            "Epoch: 2 | Step: 1080 | Train loss: 1.161081314086914 | lr: 0.0009418145956607496 | Min loss:0.799911379814148\n",
            "Rouge-1:0.18872839174783573 | Rouge-2:0.04771062131022535 | Rouge-l:0.1560663985686012\n",
            "Epoch: 2 | Step: 1090 | Train loss: 1.4192185401916504 | lr: 0.000941568047337278 | Min loss:0.799911379814148\n",
            "Rouge-1:0.22074248058490153 | Rouge-2:0.07860724819395123 | Rouge-l:0.20641611011628969\n",
            "Epoch: 2 | Step: 1100 | Train loss: 1.0205503702163696 | lr: 0.000941568047337278 | Min loss:0.799911379814148\n",
            "Rouge-1:0.23880954065198998 | Rouge-2:0.027028866256611404 | Rouge-l:0.18733339152495415\n",
            "Epoch: 2 | Step: 1110 | Train loss: 0.9842822551727295 | lr: 0.0009413214990138067 | Min loss:0.799911379814148\n",
            "Rouge-1:0.23805360973447123 | Rouge-2:0.14585677998718824 | Rouge-l:0.23110916529002679\n",
            "Epoch: 2 | Step: 1120 | Train loss: 0.8971025347709656 | lr: 0.0009410749506903353 | Min loss:0.799911379814148\n",
            "Rouge-1:0.2970534726399354 | Rouge-2:0.12689460116229953 | Rouge-l:0.26379726806020143\n",
            "Epoch: 2 | Step: 1130 | Train loss: 1.2236905097961426 | lr: 0.0009410749506903353 | Min loss:0.799911379814148\n",
            "Rouge-1:0.09089252726402351 | Rouge-2:0.021618036264778897 | Rouge-l:0.08642824154973781\n",
            "Epoch: 2 | Step: 1140 | Train loss: 1.26218843460083 | lr: 0.000940828402366864 | Min loss:0.799911379814148\n",
            "Rouge-1:0.3081837406798834 | Rouge-2:0.10118722770147358 | Rouge-l:0.2454509515433965\n",
            "Epoch: 2 | Step: 1150 | Train loss: 1.2467767000198364 | lr: 0.000940828402366864 | Min loss:0.799911379814148\n",
            "Rouge-1:0.19281238147436486 | Rouge-2:0.08490385561056607 | Rouge-l:0.1792083928703763\n",
            "Epoch: 2 | Step: 1160 | Train loss: 1.0189785957336426 | lr: 0.0009405818540433924 | Min loss:0.799911379814148\n",
            "Rouge-1:0.2744303283542295 | Rouge-2:0.12138392621322144 | Rouge-l:0.25191430271320386\n",
            "Epoch: 2 | Step: 1170 | Train loss: 1.1888651847839355 | lr: 0.0009403353057199211 | Min loss:0.799911379814148\n",
            "Rouge-1:0.2582568417371436 | Rouge-2:0.09664351698337897 | Rouge-l:0.22511177499832685\n",
            "Epoch: 2 | Step: 1180 | Train loss: 1.154691457748413 | lr: 0.0009403353057199211 | Min loss:0.799911379814148\n",
            "Rouge-1:0.32764761293346606 | Rouge-2:0.16998131806706485 | Rouge-l:0.3085170039591071\n",
            "Epoch: 2 | Step: 1190 | Train loss: 1.3146053552627563 | lr: 0.0009400887573964498 | Min loss:0.799911379814148\n",
            "Rouge-1:0.23182000041287745 | Rouge-2:0.09810524847217751 | Rouge-l:0.21049063533351237\n",
            "Epoch: 2 | Step: 1200 | Train loss: 1.1835871934890747 | lr: 0.0009398422090729783 | Min loss:0.799911379814148\n",
            "Rouge-1:0.26700527130305035 | Rouge-2:0.1322027334815876 | Rouge-l:0.24669006019836554\n",
            "Epoch: 2 | Step: 1210 | Train loss: 1.2801204919815063 | lr: 0.0009398422090729783 | Min loss:0.799911379814148\n",
            "Rouge-1:0.26299201412860856 | Rouge-2:0.08364975274681001 | Rouge-l:0.22797533827874553\n",
            "Epoch: 2 | Step: 1220 | Train loss: 1.3591355085372925 | lr: 0.000939595660749507 | Min loss:0.799911379814148\n",
            "Rouge-1:0.23304012860759976 | Rouge-2:0.09636426807068538 | Rouge-l:0.21742892317466259\n",
            "Epoch: 2 | Step: 1230 | Train loss: 1.3633044958114624 | lr: 0.000939595660749507 | Min loss:0.799911379814148\n",
            "Rouge-1:0.3159131986957403 | Rouge-2:0.12121083381050783 | Rouge-l:0.2952067390600611\n",
            "Epoch: 2 | Step: 1240 | Train loss: 1.0418424606323242 | lr: 0.0009393491124260355 | Min loss:0.799911379814148\n",
            "Rouge-1:0.12359742906259386 | Rouge-2:0.03231126937695429 | Rouge-l:0.11980955027471507\n",
            "Epoch: 2 | Step: 1250 | Train loss: 1.217703938484192 | lr: 0.0009391025641025641 | Min loss:0.799911379814148\n",
            "Rouge-1:0.2639567500850424 | Rouge-2:0.09357345421728591 | Rouge-l:0.24851576186179608\n",
            "Epoch: 2 | Step: 1260 | Train loss: 1.0206676721572876 | lr: 0.0009391025641025641 | Min loss:0.799911379814148\n",
            "Rouge-1:0.2611668925645545 | Rouge-2:0.08982857002793404 | Rouge-l:0.21219218375145898\n",
            "Epoch: 2 | Step: 1270 | Train loss: 1.1517608165740967 | lr: 0.0009388560157790927 | Min loss:0.799911379814148\n",
            "Rouge-1:0.15846455848277358 | Rouge-2:0.06828529511822123 | Rouge-l:0.15013122514944024\n",
            "Epoch: 2 | Step: 1280 | Train loss: 1.1137908697128296 | lr: 0.0009386094674556214 | Min loss:0.799911379814148\n",
            "Rouge-1:0.3083724282174375 | Rouge-2:0.13883014870153176 | Rouge-l:0.2708046837283376\n",
            "Epoch: 2 | Step: 1290 | Train loss: 0.980346143245697 | lr: 0.0009386094674556214 | Min loss:0.799911379814148\n",
            "Rouge-1:0.24234859218005073 | Rouge-2:0.08037621492335649 | Rouge-l:0.22392266625412477\n",
            "Epoch: 2 | Step: 1300 | Train loss: 1.320143222808838 | lr: 0.0009383629191321499 | Min loss:0.799911379814148\n",
            "Rouge-1:0.12115260333752528 | Rouge-2:0.01988426857107874 | Rouge-l:0.108532411029833\n",
            "Epoch: 2 | Step: 1310 | Train loss: 1.0001283884048462 | lr: 0.0009383629191321499 | Min loss:0.799911379814148\n",
            "Rouge-1:0.25849735433576376 | Rouge-2:0.12076865721516791 | Rouge-l:0.21722642896956987\n",
            "Epoch: 2 | Step: 1320 | Train loss: 1.2724246978759766 | lr: 0.0009381163708086785 | Min loss:0.799911379814148\n",
            "Rouge-1:0.22034470474443177 | Rouge-2:0.058508010945629595 | Rouge-l:0.19453187612987902\n",
            "Epoch: 2 | Step: 1330 | Train loss: 1.1510660648345947 | lr: 0.0009378698224852071 | Min loss:0.799911379814148\n",
            "Rouge-1:0.3249084477354827 | Rouge-2:0.12619475543827366 | Rouge-l:0.2855293095396037\n",
            "Epoch: 2 | Step: 1340 | Train loss: 1.0698868036270142 | lr: 0.0009378698224852071 | Min loss:0.799911379814148\n",
            "Rouge-1:0.29950151348120363 | Rouge-2:0.13559410542204056 | Rouge-l:0.2657482110238571\n",
            "Epoch: 2 | Step: 1350 | Train loss: 1.0651267766952515 | lr: 0.0009376232741617358 | Min loss:0.799911379814148\n",
            "Rouge-1:0.20478850747499938 | Rouge-2:0.0643996000582459 | Rouge-l:0.19562184080833273\n",
            "Epoch: 3 | Step: 0 | Train loss: 1.1827126741409302 | lr: 0.0009376232741617358 | Min loss:0.799911379814148\n",
            "Rouge-1:0.3303033455895324 | Rouge-2:0.16153901537342738 | Rouge-l:0.2652021798202385\n",
            "Epoch: 3 | Step: 10 | Train loss: 0.8294489979743958 | lr: 0.0009373767258382642 | Min loss:0.799911379814148\n",
            "Rouge-1:0.24408865697139828 | Rouge-2:0.07419642643048309 | Rouge-l:0.2035798139625553\n",
            "Epoch: 3 | Step: 20 | Train loss: 1.0148258209228516 | lr: 0.0009373767258382642 | Min loss:0.799911379814148\n",
            "Rouge-1:0.186107585324503 | Rouge-2:0.039427210173007154 | Rouge-l:0.16253302392099428\n",
            "Epoch: 3 | Step: 30 | Train loss: 1.03330659866333 | lr: 0.0009371301775147929 | Min loss:0.799911379814148\n",
            "Rouge-1:0.27591893989038513 | Rouge-2:0.14413641717365575 | Rouge-l:0.24399549546694074\n",
            "Epoch: 3 | Step: 40 | Train loss: 0.8718999028205872 | lr: 0.0009368836291913216 | Min loss:0.799911379814148\n",
            "Rouge-1:0.2626423647885951 | Rouge-2:0.09130381679080267 | Rouge-l:0.22122205031777756\n",
            "Epoch: 3 | Step: 50 | Train loss: 1.0132582187652588 | lr: 0.0009368836291913216 | Min loss:0.799911379814148\n",
            "Rouge-1:0.1891097676729654 | Rouge-2:0.045552506609139336 | Rouge-l:0.14561139604959375\n",
            "Epoch: 3 | Step: 60 | Train loss: 1.1203887462615967 | lr: 0.0009366370808678501 | Min loss:0.799911379814148\n",
            "Rouge-1:0.20136388135680733 | Rouge-2:0.057224024804697814 | Rouge-l:0.17766596469014068\n",
            "Epoch: 3 | Step: 70 | Train loss: 1.1409852504730225 | lr: 0.0009366370808678501 | Min loss:0.799911379814148\n",
            "Rouge-1:0.2583656432039654 | Rouge-2:0.10048558781823215 | Rouge-l:0.23897461756293972\n",
            "Epoch: 3 | Step: 80 | Train loss: 1.0025278329849243 | lr: 0.0009363905325443787 | Min loss:0.799911379814148\n",
            "Rouge-1:0.23046306406844946 | Rouge-2:0.09297072513654962 | Rouge-l:0.19955381631137561\n",
            "Epoch: 3 | Step: 90 | Train loss: 1.2444177865982056 | lr: 0.0009361439842209073 | Min loss:0.799911379814148\n",
            "Rouge-1:0.23469763175305489 | Rouge-2:0.07970389451752838 | Rouge-l:0.18730203898019496\n",
            "Epoch: 3 | Step: 100 | Train loss: 1.1214536428451538 | lr: 0.0009361439842209073 | Min loss:0.799911379814148\n",
            "Rouge-1:0.2617457905126783 | Rouge-2:0.0834322231349652 | Rouge-l:0.2112474444098816\n",
            "Epoch: 3 | Step: 110 | Train loss: 1.2442381381988525 | lr: 0.000935897435897436 | Min loss:0.799911379814148\n",
            "Rouge-1:0.22616740449897116 | Rouge-2:0.06669642705874836 | Rouge-l:0.203184600266167\n",
            "Epoch: 3 | Step: 120 | Train loss: 1.2950899600982666 | lr: 0.0009356508875739645 | Min loss:0.799911379814148\n",
            "Rouge-1:0.22343253977478705 | Rouge-2:0.0598054513103267 | Rouge-l:0.1871247886729624\n",
            "Epoch: 3 | Step: 130 | Train loss: 1.1701360940933228 | lr: 0.0009356508875739645 | Min loss:0.799911379814148\n",
            "Rouge-1:0.20259517685173148 | Rouge-2:0.059809464474308294 | Rouge-l:0.17517858302888764\n",
            "Epoch: 3 | Step: 140 | Train loss: 1.0786749124526978 | lr: 0.0009354043392504931 | Min loss:0.799911379814148\n",
            "Rouge-1:0.28127646577664117 | Rouge-2:0.12070957566207467 | Rouge-l:0.2642651875811525\n",
            "Epoch: 3 | Step: 150 | Train loss: 1.066815972328186 | lr: 0.0009354043392504931 | Min loss:0.799911379814148\n",
            "Rouge-1:0.35564162556876616 | Rouge-2:0.1982346125262145 | Rouge-l:0.2990483029384253\n",
            "Epoch: 3 | Step: 160 | Train loss: 1.2155951261520386 | lr: 0.0009351577909270217 | Min loss:0.799911379814148\n",
            "Rouge-1:0.22181000509977217 | Rouge-2:0.08422554631926239 | Rouge-l:0.2168100050997722\n",
            "Epoch: 3 | Step: 170 | Train loss: 1.0919864177703857 | lr: 0.0009349112426035503 | Min loss:0.799911379814148\n",
            "Rouge-1:0.3264960395460464 | Rouge-2:0.11977671681401969 | Rouge-l:0.2868348673848742\n",
            "Epoch: 3 | Step: 180 | Train loss: 1.1378802061080933 | lr: 0.0009349112426035503 | Min loss:0.799911379814148\n",
            "Rouge-1:0.2782588022547191 | Rouge-2:0.10264392134968636 | Rouge-l:0.22761581778820525\n",
            "Epoch: 3 | Step: 190 | Train loss: 1.0478403568267822 | lr: 0.0009346646942800789 | Min loss:0.799911379814148\n",
            "Rouge-1:0.20940593602704183 | Rouge-2:0.07062499876961895 | Rouge-l:0.1956238847449905\n",
            "Epoch: 3 | Step: 200 | Train loss: 1.0725868940353394 | lr: 0.0009344181459566076 | Min loss:0.799911379814148\n",
            "Rouge-1:0.27612220431082674 | Rouge-2:0.11488334889084258 | Rouge-l:0.2525863246811971\n",
            "Epoch: 3 | Step: 210 | Train loss: 0.9696223139762878 | lr: 0.0009344181459566076 | Min loss:0.799911379814148\n",
            "Rouge-1:0.24842012017450835 | Rouge-2:0.12548052393098227 | Rouge-l:0.21807003547659756\n",
            "Epoch: 3 | Step: 220 | Train loss: 1.1488436460494995 | lr: 0.000934171597633136 | Min loss:0.799911379814148\n",
            "Rouge-1:0.21812939421272137 | Rouge-2:0.07295403676707002 | Rouge-l:0.18767239171992034\n",
            "Epoch: 3 | Step: 230 | Train loss: 1.2567763328552246 | lr: 0.000934171597633136 | Min loss:0.799911379814148\n",
            "Rouge-1:0.31632553663698426 | Rouge-2:0.17243622431791678 | Rouge-l:0.28869377025521786\n",
            "Epoch: 3 | Step: 240 | Train loss: 0.9524901509284973 | lr: 0.0009339250493096647 | Min loss:0.799911379814148\n",
            "Rouge-1:0.26833507378797994 | Rouge-2:0.0836984934381672 | Rouge-l:0.24767980313270932\n",
            "Epoch: 3 | Step: 250 | Train loss: 1.0147554874420166 | lr: 0.0009336785009861934 | Min loss:0.799911379814148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3 | Step: 256 | Train loss: 0.7978094220161438 | lr: 0.0009336785009861934 | Min loss:0.7978094220161438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.2106939077966481 | Rouge-2:0.06866672804695165 | Rouge-l:0.19348342171015395\n",
            "Epoch: 3 | Step: 260 | Train loss: 1.1242743730545044 | lr: 0.0009336785009861934 | Min loss:0.7978094220161438\n",
            "Rouge-1:0.20328615239732298 | Rouge-2:0.08807942711659059 | Rouge-l:0.193286152397323\n",
            "Epoch: 3 | Step: 270 | Train loss: 1.1427052021026611 | lr: 0.000933431952662722 | Min loss:0.7978094220161438\n",
            "Rouge-1:0.20324014582587951 | Rouge-2:0.04525462808661272 | Rouge-l:0.17880832764406135\n",
            "Epoch: 3 | Step: 280 | Train loss: 1.0214157104492188 | lr: 0.0009331854043392505 | Min loss:0.7978094220161438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3 | Step: 283 | Train loss: 0.7598298788070679 | lr: 0.0009331854043392505 | Min loss:0.7598298788070679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.20738196203214426 | Rouge-2:0.07083333184409965 | Rouge-l:0.186558000418709\n",
            "Epoch: 3 | Step: 290 | Train loss: 0.9624249935150146 | lr: 0.0009331854043392505 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2418443845645686 | Rouge-2:0.09048590119441355 | Rouge-l:0.20267960879416475\n",
            "Epoch: 3 | Step: 300 | Train loss: 1.0591833591461182 | lr: 0.0009329388560157791 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2207489962757261 | Rouge-2:0.09167802125458617 | Rouge-l:0.20669962652782695\n",
            "Epoch: 3 | Step: 310 | Train loss: 1.069069266319275 | lr: 0.0009329388560157791 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.26392687429116807 | Rouge-2:0.11160432607195792 | Rouge-l:0.2524685409578348\n",
            "Epoch: 3 | Step: 320 | Train loss: 1.0843786001205444 | lr: 0.0009326923076923078 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.22621422854016504 | Rouge-2:0.05357366720564244 | Rouge-l:0.18638172577161577\n",
            "Epoch: 3 | Step: 330 | Train loss: 0.9515143632888794 | lr: 0.0009324457593688363 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.23032660066094612 | Rouge-2:0.07078807479353173 | Rouge-l:0.19242656666716218\n",
            "Epoch: 3 | Step: 340 | Train loss: 1.1190599203109741 | lr: 0.0009324457593688363 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.1649040054777073 | Rouge-2:0.047549627342910086 | Rouge-l:0.14435008274987154\n",
            "Epoch: 3 | Step: 350 | Train loss: 1.126643180847168 | lr: 0.0009321992110453649 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.26784440217624 | Rouge-2:0.07840291662858899 | Rouge-l:0.23497585629045278\n",
            "Epoch: 3 | Step: 360 | Train loss: 1.2087963819503784 | lr: 0.0009319526627218935 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.23194111079809257 | Rouge-2:0.06214847319461043 | Rouge-l:0.2086810375380193\n",
            "Epoch: 3 | Step: 370 | Train loss: 1.197080373764038 | lr: 0.0009319526627218935 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.328673492487217 | Rouge-2:0.14762698441683267 | Rouge-l:0.30111121371876715\n",
            "Epoch: 3 | Step: 380 | Train loss: 0.959551990032196 | lr: 0.0009317061143984221 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.22900628676538612 | Rouge-2:0.06628382116450841 | Rouge-l:0.19843104301878692\n",
            "Epoch: 3 | Step: 390 | Train loss: 1.1217466592788696 | lr: 0.0009317061143984221 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2930122573182855 | Rouge-2:0.12389106345287787 | Rouge-l:0.2680364799987582\n",
            "Epoch: 3 | Step: 400 | Train loss: 0.9542372226715088 | lr: 0.0009314595660749507 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.38401553422072393 | Rouge-2:0.18399567689127835 | Rouge-l:0.335936987116983\n",
            "Epoch: 3 | Step: 410 | Train loss: 0.9963070750236511 | lr: 0.0009312130177514793 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.23108059336197323 | Rouge-2:0.1117400539551903 | Rouge-l:0.21823251801389787\n",
            "Epoch: 3 | Step: 420 | Train loss: 1.161717414855957 | lr: 0.0009312130177514793 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.22569913831764593 | Rouge-2:0.07931545444620483 | Rouge-l:0.20394589156439918\n",
            "Epoch: 3 | Step: 430 | Train loss: 1.3427221775054932 | lr: 0.0009309664694280078 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.18707693935482228 | Rouge-2:0.04539337322923492 | Rouge-l:0.15266334160325948\n",
            "Epoch: 3 | Step: 440 | Train loss: 1.1510258913040161 | lr: 0.0009307199211045365 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2564292930100386 | Rouge-2:0.06310019661365632 | Rouge-l:0.21241972540672105\n",
            "Epoch: 3 | Step: 450 | Train loss: 1.1416997909545898 | lr: 0.0009307199211045365 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.3226085053146173 | Rouge-2:0.16017755735006042 | Rouge-l:0.2852521398332518\n",
            "Epoch: 3 | Step: 460 | Train loss: 1.0599992275238037 | lr: 0.0009304733727810652 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.28261976047169646 | Rouge-2:0.1679984038533226 | Rouge-l:0.28261976047169646\n",
            "Epoch: 3 | Step: 470 | Train loss: 0.9691355228424072 | lr: 0.0009304733727810652 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2466852414752343 | Rouge-2:0.09904377186824995 | Rouge-l:0.22294237805845782\n",
            "Epoch: 3 | Step: 480 | Train loss: 1.1983084678649902 | lr: 0.0009302268244575937 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.3141812570634843 | Rouge-2:0.12839505239904903 | Rouge-l:0.2920160818810677\n",
            "Epoch: 3 | Step: 490 | Train loss: 0.8612377643585205 | lr: 0.0009299802761341223 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2641957341709711 | Rouge-2:0.10326970186399763 | Rouge-l:0.2422011225024464\n",
            "Epoch: 3 | Step: 500 | Train loss: 1.01572585105896 | lr: 0.0009299802761341223 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.23594939843020316 | Rouge-2:0.08518032031536377 | Rouge-l:0.19889465572797468\n",
            "Epoch: 3 | Step: 510 | Train loss: 1.087971806526184 | lr: 0.0009297337278106509 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2797705463763608 | Rouge-2:0.11910138439773868 | Rouge-l:0.25626020255351695\n",
            "Epoch: 3 | Step: 520 | Train loss: 0.9439021944999695 | lr: 0.0009294871794871796 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.30477463675718747 | Rouge-2:0.1537697825589629 | Rouge-l:0.25791059529637184\n",
            "Epoch: 3 | Step: 530 | Train loss: 1.0131944417953491 | lr: 0.0009294871794871796 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.21765083823673492 | Rouge-2:0.1176915874386405 | Rouge-l:0.20802120860710532\n",
            "Epoch: 3 | Step: 540 | Train loss: 1.0014877319335938 | lr: 0.0009292406311637081 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.25933060758607224 | Rouge-2:0.12439096794592583 | Rouge-l:0.23315927891474358\n",
            "Epoch: 3 | Step: 550 | Train loss: 0.8937872648239136 | lr: 0.0009292406311637081 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.16777328101102348 | Rouge-2:0.024142413498640852 | Rouge-l:0.14577766697593575\n",
            "Epoch: 3 | Step: 560 | Train loss: 1.079039216041565 | lr: 0.0009289940828402367 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.3370486572297732 | Rouge-2:0.15619832664809202 | Rouge-l:0.309616282801754\n",
            "Epoch: 3 | Step: 570 | Train loss: 1.0152528285980225 | lr: 0.0009287475345167653 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.34611245334388585 | Rouge-2:0.17025310973206575 | Rouge-l:0.3095625449189775\n",
            "Epoch: 3 | Step: 580 | Train loss: 1.048474907875061 | lr: 0.0009287475345167653 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.22958288877683614 | Rouge-2:0.09329505587451012 | Rouge-l:0.18702439654443087\n",
            "Epoch: 3 | Step: 590 | Train loss: 0.9839419722557068 | lr: 0.0009285009861932939 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.30477316577738456 | Rouge-2:0.16599437654641688 | Rouge-l:0.2835676240073267\n",
            "Epoch: 3 | Step: 600 | Train loss: 1.121787428855896 | lr: 0.0009282544378698225 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.23102830190579776 | Rouge-2:0.06620732394952629 | Rouge-l:0.20492107579857166\n",
            "Epoch: 3 | Step: 610 | Train loss: 1.1893749237060547 | lr: 0.0009282544378698225 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.20880158722325065 | Rouge-2:0.05416552621932702 | Rouge-l:0.17885632685306918\n",
            "Epoch: 3 | Step: 620 | Train loss: 1.0660715103149414 | lr: 0.0009280078895463511 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.1603333636864818 | Rouge-2:0.05059314243591211 | Rouge-l:0.14407857441445118\n",
            "Epoch: 3 | Step: 630 | Train loss: 1.0594861507415771 | lr: 0.0009280078895463511 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.22118426728726165 | Rouge-2:0.07997520264107452 | Rouge-l:0.21192500802800238\n",
            "Epoch: 3 | Step: 640 | Train loss: 1.0801655054092407 | lr: 0.0009277613412228797 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.32982816843266205 | Rouge-2:0.20662135875415993 | Rouge-l:0.32228312338761694\n",
            "Epoch: 3 | Step: 650 | Train loss: 0.9235742688179016 | lr: 0.0009275147928994083 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.22703084960623796 | Rouge-2:0.0801613830313877 | Rouge-l:0.2119845533099417\n",
            "Epoch: 3 | Step: 660 | Train loss: 1.2060117721557617 | lr: 0.0009275147928994083 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2487989048162633 | Rouge-2:0.07793678351520464 | Rouge-l:0.22307908405967786\n",
            "Epoch: 3 | Step: 670 | Train loss: 1.0096824169158936 | lr: 0.000927268244575937 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2777788247895995 | Rouge-2:0.10665745784263202 | Rouge-l:0.2355127864298111\n",
            "Epoch: 3 | Step: 680 | Train loss: 1.1225495338439941 | lr: 0.0009270216962524655 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2060099521382815 | Rouge-2:0.05729509924004133 | Rouge-l:0.17417614665878878\n",
            "Epoch: 3 | Step: 690 | Train loss: 1.2072256803512573 | lr: 0.0009270216962524655 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.3038938394357223 | Rouge-2:0.1619009929815193 | Rouge-l:0.2894629451267792\n",
            "Epoch: 3 | Step: 700 | Train loss: 1.0102699995040894 | lr: 0.000926775147928994 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.28178706111085516 | Rouge-2:0.13194090853742824 | Rouge-l:0.2538911666827027\n",
            "Epoch: 3 | Step: 710 | Train loss: 0.9870731234550476 | lr: 0.000926775147928994 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.25257499385219423 | Rouge-2:0.10818160390306272 | Rouge-l:0.21362306745131138\n",
            "Epoch: 3 | Step: 720 | Train loss: 0.9491862654685974 | lr: 0.0009265285996055227 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2082957896929996 | Rouge-2:0.07523375629125337 | Rouge-l:0.19717918890248579\n",
            "Epoch: 3 | Step: 730 | Train loss: 0.97670978307724 | lr: 0.0009262820512820514 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2606739697418977 | Rouge-2:0.11930589944000491 | Rouge-l:0.23693110632512124\n",
            "Epoch: 3 | Step: 740 | Train loss: 0.9122334122657776 | lr: 0.0009262820512820514 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2548527561468998 | Rouge-2:0.08634288686647694 | Rouge-l:0.22684104085070175\n",
            "Epoch: 3 | Step: 750 | Train loss: 1.0418086051940918 | lr: 0.0009260355029585798 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2242025024296359 | Rouge-2:0.08484246103800297 | Rouge-l:0.19812362878402145\n",
            "Epoch: 3 | Step: 760 | Train loss: 1.031164288520813 | lr: 0.0009257889546351085 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.23861579183569823 | Rouge-2:0.08004303604474416 | Rouge-l:0.2059063138137202\n",
            "Epoch: 3 | Step: 770 | Train loss: 1.046531319618225 | lr: 0.0009257889546351085 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.20815209605814913 | Rouge-2:0.08932940532424119 | Rouge-l:0.19495103785709095\n",
            "Epoch: 3 | Step: 780 | Train loss: 1.1629362106323242 | lr: 0.0009255424063116371 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.25822667230766266 | Rouge-2:0.09163748976750617 | Rouge-l:0.2193690673047965\n",
            "Epoch: 3 | Step: 790 | Train loss: 1.1946746110916138 | lr: 0.0009255424063116371 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2756155544762743 | Rouge-2:0.13398128799361 | Rouge-l:0.24976135024198592\n",
            "Epoch: 3 | Step: 800 | Train loss: 1.1362920999526978 | lr: 0.0009252958579881658 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.22929812144295347 | Rouge-2:0.0645614781740252 | Rouge-l:0.18797486136969338\n",
            "Epoch: 3 | Step: 810 | Train loss: 1.2844324111938477 | lr: 0.0009250493096646942 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.19404898557722536 | Rouge-2:0.0596201849829229 | Rouge-l:0.16567441049748724\n",
            "Epoch: 3 | Step: 820 | Train loss: 1.0440938472747803 | lr: 0.0009250493096646942 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.33444592553186475 | Rouge-2:0.14438406623066505 | Rouge-l:0.32257890963259084\n",
            "Epoch: 3 | Step: 830 | Train loss: 0.9868268966674805 | lr: 0.0009248027613412229 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.23781911656968874 | Rouge-2:0.08257425300447273 | Rouge-l:0.20963549835637002\n",
            "Epoch: 3 | Step: 840 | Train loss: 1.0875258445739746 | lr: 0.0009245562130177515 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.29677780080621885 | Rouge-2:0.13340496505280597 | Rouge-l:0.26451860167201974\n",
            "Epoch: 3 | Step: 850 | Train loss: 0.8703476786613464 | lr: 0.0009245562130177515 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.269627732260604 | Rouge-2:0.1247483968603887 | Rouge-l:0.25185921045982407\n",
            "Epoch: 3 | Step: 860 | Train loss: 0.9564455151557922 | lr: 0.0009243096646942801 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2878914395678297 | Rouge-2:0.09689419036982555 | Rouge-l:0.23739506637021815\n",
            "Epoch: 3 | Step: 870 | Train loss: 1.235327124595642 | lr: 0.0009243096646942801 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2244285280292796 | Rouge-2:0.06673811145230463 | Rouge-l:0.20259764152448004\n",
            "Epoch: 3 | Step: 880 | Train loss: 1.0906221866607666 | lr: 0.0009240631163708086 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.3271043500698086 | Rouge-2:0.16857118128332707 | Rouge-l:0.30172255593801445\n",
            "Epoch: 3 | Step: 890 | Train loss: 1.0491116046905518 | lr: 0.0009238165680473373 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2490939737331632 | Rouge-2:0.11343784601005787 | Rouge-l:0.21168656632575578\n",
            "Epoch: 3 | Step: 900 | Train loss: 0.9876141548156738 | lr: 0.0009238165680473373 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.28728030638958857 | Rouge-2:0.1351906104517313 | Rouge-l:0.24778346064274281\n",
            "Epoch: 3 | Step: 910 | Train loss: 1.2262097597122192 | lr: 0.0009235700197238658 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.15677151891484725 | Rouge-2:0.04649491284137594 | Rouge-l:0.14498423821309286\n",
            "Epoch: 3 | Step: 920 | Train loss: 1.2748661041259766 | lr: 0.0009233234714003945 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.21685463805319719 | Rouge-2:0.06820646105778796 | Rouge-l:0.19218984508418463\n",
            "Epoch: 3 | Step: 930 | Train loss: 1.0778383016586304 | lr: 0.0009233234714003945 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.1984593216341681 | Rouge-2:0.09269033443085506 | Rouge-l:0.18787731105215752\n",
            "Epoch: 3 | Step: 940 | Train loss: 1.0106134414672852 | lr: 0.0009230769230769232 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.314215679021698 | Rouge-2:0.17209559377904526 | Rouge-l:0.2923731465541656\n",
            "Epoch: 3 | Step: 950 | Train loss: 1.093991994857788 | lr: 0.0009230769230769232 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.20850254526883064 | Rouge-2:0.10988781902957402 | Rouge-l:0.20850254526883064\n",
            "Epoch: 3 | Step: 960 | Train loss: 1.0843703746795654 | lr: 0.0009228303747534517 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.3714808174537124 | Rouge-2:0.19710606450435847 | Rouge-l:0.33602462955850015\n",
            "Epoch: 3 | Step: 970 | Train loss: 0.9280712008476257 | lr: 0.0009225838264299803 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.22769589287969774 | Rouge-2:0.06896249814417449 | Rouge-l:0.20624431708029586\n",
            "Epoch: 3 | Step: 980 | Train loss: 1.2261829376220703 | lr: 0.0009225838264299803 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.26346948574564344 | Rouge-2:0.10715744192976158 | Rouge-l:0.2240184275445853\n",
            "Epoch: 3 | Step: 990 | Train loss: 1.0290285348892212 | lr: 0.0009223372781065089 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.28377943260782057 | Rouge-2:0.12641430511010315 | Rouge-l:0.2424904278549235\n",
            "Epoch: 3 | Step: 1000 | Train loss: 1.1888017654418945 | lr: 0.0009220907297830376 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.21649901654370757 | Rouge-2:0.07177178776994278 | Rouge-l:0.18641145615723415\n",
            "Epoch: 3 | Step: 1010 | Train loss: 0.8563727140426636 | lr: 0.0009220907297830376 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.28923355712108884 | Rouge-2:0.19286337425260197 | Rouge-l:0.260595786223256\n",
            "Epoch: 3 | Step: 1020 | Train loss: 0.9371896982192993 | lr: 0.000921844181459566 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.3283472425109247 | Rouge-2:0.1795617752541515 | Rouge-l:0.30615610031978246\n",
            "Epoch: 3 | Step: 1030 | Train loss: 1.1267225742340088 | lr: 0.000921844181459566 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2136978523404261 | Rouge-2:0.10676299252439184 | Rouge-l:0.20423356662614042\n",
            "Epoch: 3 | Step: 1040 | Train loss: 0.9635521769523621 | lr: 0.0009215976331360947 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.26909337720023896 | Rouge-2:0.11986039110097145 | Rouge-l:0.24235742500090007\n",
            "Epoch: 3 | Step: 1050 | Train loss: 1.0753824710845947 | lr: 0.0009213510848126233 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.26867042903665 | Rouge-2:0.13817840588290126 | Rouge-l:0.23996332119351274\n",
            "Epoch: 3 | Step: 1060 | Train loss: 0.9746502041816711 | lr: 0.0009213510848126233 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2189121506916658 | Rouge-2:0.09380120730425887 | Rouge-l:0.21041560691286396\n",
            "Epoch: 3 | Step: 1070 | Train loss: 1.2063740491867065 | lr: 0.0009211045364891519 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.35184170845618573 | Rouge-2:0.15545812706926793 | Rouge-l:0.31818036261811583\n",
            "Epoch: 3 | Step: 1080 | Train loss: 0.8759472370147705 | lr: 0.0009208579881656804 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.15804945740074425 | Rouge-2:0.05082624369780936 | Rouge-l:0.12283633479538028\n",
            "Epoch: 3 | Step: 1090 | Train loss: 0.9612191915512085 | lr: 0.0009208579881656804 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.19990266339470109 | Rouge-2:0.06063837633135377 | Rouge-l:0.1866420813841191\n",
            "Epoch: 3 | Step: 1100 | Train loss: 0.9256470203399658 | lr: 0.0009206114398422091 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2496357613587229 | Rouge-2:0.08540292956588526 | Rouge-l:0.212084905996335\n",
            "Epoch: 3 | Step: 1110 | Train loss: 1.02253258228302 | lr: 0.0009206114398422091 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.22478614018529394 | Rouge-2:0.0564064442668544 | Rouge-l:0.16023238053070432\n",
            "Epoch: 3 | Step: 1120 | Train loss: 1.2573434114456177 | lr: 0.0009203648915187378 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.24599491397611814 | Rouge-2:0.12239041967070026 | Rouge-l:0.2163207210666311\n",
            "Epoch: 3 | Step: 1130 | Train loss: 1.0103768110275269 | lr: 0.0009201183431952663 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.22357224883249777 | Rouge-2:0.08311909653760649 | Rouge-l:0.1990624449109291\n",
            "Epoch: 3 | Step: 1140 | Train loss: 1.2422794103622437 | lr: 0.0009201183431952663 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2183983674746344 | Rouge-2:0.09784496298298014 | Rouge-l:0.20496998551176968\n",
            "Epoch: 3 | Step: 1150 | Train loss: 1.1170953512191772 | lr: 0.0009198717948717949 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.38286885435298074 | Rouge-2:0.22496041565886815 | Rouge-l:0.32754721343351373\n",
            "Epoch: 3 | Step: 1160 | Train loss: 0.9357066750526428 | lr: 0.0009196252465483235 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.28676144847864987 | Rouge-2:0.11601478688796027 | Rouge-l:0.22674159784927755\n",
            "Epoch: 3 | Step: 1170 | Train loss: 0.9886659383773804 | lr: 0.0009196252465483235 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.25460058206381625 | Rouge-2:0.11320542173542837 | Rouge-l:0.2193260558653771\n",
            "Epoch: 3 | Step: 1180 | Train loss: 1.0863640308380127 | lr: 0.0009193786982248521 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.1644684824987254 | Rouge-2:0.047080042347820636 | Rouge-l:0.1503811809114238\n",
            "Epoch: 3 | Step: 1190 | Train loss: 1.1683783531188965 | lr: 0.0009193786982248521 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.20572365305149184 | Rouge-2:0.069716359403208 | Rouge-l:0.19710296339631944\n",
            "Epoch: 3 | Step: 1200 | Train loss: 1.0741970539093018 | lr: 0.0009191321499013807 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.27603997074128034 | Rouge-2:0.150090525033805 | Rouge-l:0.26844015222948364\n",
            "Epoch: 3 | Step: 1210 | Train loss: 1.005911946296692 | lr: 0.0009188856015779093 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.3133084822518446 | Rouge-2:0.15533272678622698 | Rouge-l:0.28941006924244017\n",
            "Epoch: 3 | Step: 1220 | Train loss: 1.21611750125885 | lr: 0.0009188856015779093 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.32247644265139835 | Rouge-2:0.15007770891313651 | Rouge-l:0.2996238356995267\n",
            "Epoch: 3 | Step: 1230 | Train loss: 0.8958066701889038 | lr: 0.0009186390532544378 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.29555946660548765 | Rouge-2:0.12286648997328782 | Rouge-l:0.282017799938821\n",
            "Epoch: 3 | Step: 1240 | Train loss: 1.1189922094345093 | lr: 0.0009183925049309665 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.291234436049358 | Rouge-2:0.058754787206310104 | Rouge-l:0.23136919236058498\n",
            "Epoch: 3 | Step: 1250 | Train loss: 0.9346016645431519 | lr: 0.0009183925049309665 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.17970979514145521 | Rouge-2:0.033555790391444476 | Rouge-l:0.1445465846959867\n",
            "Epoch: 3 | Step: 1260 | Train loss: 1.3424991369247437 | lr: 0.0009181459566074951 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.21490512871568687 | Rouge-2:0.08492895189804084 | Rouge-l:0.18330790649346468\n",
            "Epoch: 3 | Step: 1270 | Train loss: 1.3432912826538086 | lr: 0.0009181459566074951 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2814837117080969 | Rouge-2:0.12216299607182293 | Rouge-l:0.23241533217096738\n",
            "Epoch: 3 | Step: 1280 | Train loss: 1.1397807598114014 | lr: 0.0009178994082840238 | Min loss:0.7598298788070679\n",
            "Rouge-1:0.2823080436718669 | Rouge-2:0.0927107418007077 | Rouge-l:0.25828498293541946\n",
            "Epoch: 3 | Step: 1290 | Train loss: 1.1240534782409668 | lr: 0.0009176528599605522 | Min loss:0.7598298788070679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3 | Step: 1293 | Train loss: 0.7009577751159668 | lr: 0.0009176528599605522 | Min loss:0.7009577751159668\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.29468335951334174 | Rouge-2:0.13171885455795496 | Rouge-l:0.24701852434850652\n",
            "Epoch: 3 | Step: 1300 | Train loss: 1.150193691253662 | lr: 0.0009176528599605522 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2074492287403008 | Rouge-2:0.07152435098067908 | Rouge-l:0.18962537039920108\n",
            "Epoch: 3 | Step: 1310 | Train loss: 1.1138503551483154 | lr: 0.0009174063116370809 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2861184584467916 | Rouge-2:0.13779527035999758 | Rouge-l:0.25728330618486595\n",
            "Epoch: 3 | Step: 1320 | Train loss: 0.9464351534843445 | lr: 0.0009171597633136096 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.31645576649888413 | Rouge-2:0.19374348838157446 | Rouge-l:0.2805807116020901\n",
            "Epoch: 3 | Step: 1330 | Train loss: 1.0774109363555908 | lr: 0.0009171597633136096 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.30709935622768586 | Rouge-2:0.17058766671693712 | Rouge-l:0.2927804707787695\n",
            "Epoch: 3 | Step: 1340 | Train loss: 1.234509825706482 | lr: 0.0009169132149901381 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.19167150250149423 | Rouge-2:0.034262421135033416 | Rouge-l:0.16407890990890167\n",
            "Epoch: 3 | Step: 1350 | Train loss: 1.0832903385162354 | lr: 0.0009169132149901381 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2636861728036224 | Rouge-2:0.10815002147520131 | Rouge-l:0.22097197843022087\n",
            "Epoch: 4 | Step: 0 | Train loss: 0.950681746006012 | lr: 0.0009166666666666666 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.19037053918996377 | Rouge-2:0.06805521161828039 | Rouge-l:0.14723826888378042\n",
            "Epoch: 4 | Step: 10 | Train loss: 0.9054622650146484 | lr: 0.0009166666666666666 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2813369575171793 | Rouge-2:0.09346880568802249 | Rouge-l:0.25706839980459883\n",
            "Epoch: 4 | Step: 20 | Train loss: 0.9053412079811096 | lr: 0.0009164201183431953 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.24189233688062317 | Rouge-2:0.10758234622081878 | Rouge-l:0.2180426044371408\n",
            "Epoch: 4 | Step: 30 | Train loss: 1.0931367874145508 | lr: 0.0009164201183431953 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2752759929509413 | Rouge-2:0.09677492411090624 | Rouge-l:0.2355101453725938\n",
            "Epoch: 4 | Step: 40 | Train loss: 0.8952506184577942 | lr: 0.0009161735700197239 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.28153084240881393 | Rouge-2:0.1414188661110332 | Rouge-l:0.24066545779342927\n",
            "Epoch: 4 | Step: 50 | Train loss: 0.9132460951805115 | lr: 0.0009159270216962525 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2921738311471515 | Rouge-2:0.15239249994265855 | Rouge-l:0.26794124853448475\n",
            "Epoch: 4 | Step: 60 | Train loss: 0.9996731877326965 | lr: 0.0009159270216962525 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.35266455076117953 | Rouge-2:0.15300526800539604 | Rouge-l:0.3106973986196088\n",
            "Epoch: 4 | Step: 70 | Train loss: 1.010107398033142 | lr: 0.0009156804733727811 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.3049007318132768 | Rouge-2:0.12688911646763276 | Rouge-l:0.2454455063235686\n",
            "Epoch: 4 | Step: 80 | Train loss: 0.9778333902359009 | lr: 0.0009154339250493096 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2642760667585036 | Rouge-2:0.08531719153200565 | Rouge-l:0.23739743388242832\n",
            "Epoch: 4 | Step: 90 | Train loss: 0.9402592778205872 | lr: 0.0009154339250493096 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.29759516407360376 | Rouge-2:0.14569649395524145 | Rouge-l:0.25801668699512664\n",
            "Epoch: 4 | Step: 100 | Train loss: 0.9352666139602661 | lr: 0.0009151873767258383 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.20749760742174234 | Rouge-2:0.07096059982126113 | Rouge-l:0.17150545142958634\n",
            "Epoch: 4 | Step: 110 | Train loss: 1.1417300701141357 | lr: 0.0009151873767258383 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.34864263980714116 | Rouge-2:0.17116944707094797 | Rouge-l:0.28638538078264075\n",
            "Epoch: 4 | Step: 120 | Train loss: 1.129970669746399 | lr: 0.0009149408284023669 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.24142476866841098 | Rouge-2:0.09355677662924744 | Rouge-l:0.20228710058614266\n",
            "Epoch: 4 | Step: 130 | Train loss: 1.0716040134429932 | lr: 0.0009146942800788955 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2612431691138526 | Rouge-2:0.11260923235028153 | Rouge-l:0.23392269546984953\n",
            "Epoch: 4 | Step: 140 | Train loss: 1.0854088068008423 | lr: 0.0009146942800788955 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.267970723152276 | Rouge-2:0.12538144652091904 | Rouge-l:0.24857137250292535\n",
            "Epoch: 4 | Step: 150 | Train loss: 1.0194048881530762 | lr: 0.000914447731755424 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.3484890172081459 | Rouge-2:0.19187105207465086 | Rouge-l:0.3316905982358139\n",
            "Epoch: 4 | Step: 160 | Train loss: 0.9570755958557129 | lr: 0.0009142011834319527 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2568221090951716 | Rouge-2:0.13003517696370057 | Rouge-l:0.24217024506008386\n",
            "Epoch: 4 | Step: 170 | Train loss: 0.9036964774131775 | lr: 0.0009142011834319527 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.22882418832473167 | Rouge-2:0.08191808014124168 | Rouge-l:0.1979125074130508\n",
            "Epoch: 4 | Step: 180 | Train loss: 1.173356533050537 | lr: 0.0009139546351084813 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.27986386921503725 | Rouge-2:0.14611960997478096 | Rouge-l:0.25381439395266847\n",
            "Epoch: 4 | Step: 190 | Train loss: 1.1506775617599487 | lr: 0.0009139546351084813 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.21185476522821248 | Rouge-2:0.10904493154458975 | Rouge-l:0.1945753534635066\n",
            "Epoch: 4 | Step: 200 | Train loss: 0.9746484756469727 | lr: 0.0009137080867850098 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.3101450054464212 | Rouge-2:0.130341457804807 | Rouge-l:0.2830929581931357\n",
            "Epoch: 4 | Step: 210 | Train loss: 0.9774467945098877 | lr: 0.0009134615384615384 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.18007694232698163 | Rouge-2:0.07640701273543532 | Rouge-l:0.17026925001928933\n",
            "Epoch: 4 | Step: 220 | Train loss: 1.0730832815170288 | lr: 0.0009134615384615384 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2919566316659144 | Rouge-2:0.14428460644969743 | Rouge-l:0.258576820756403\n",
            "Epoch: 4 | Step: 230 | Train loss: 0.8481199145317078 | lr: 0.0009132149901380671 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.23686731817675732 | Rouge-2:0.10176641228450843 | Rouge-l:0.190048858858298\n",
            "Epoch: 4 | Step: 240 | Train loss: 1.0971107482910156 | lr: 0.0009129684418145957 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.27744797173129365 | Rouge-2:0.11007901530499938 | Rouge-l:0.2533924994674255\n",
            "Epoch: 4 | Step: 250 | Train loss: 0.9794721007347107 | lr: 0.0009129684418145957 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.28547940877846023 | Rouge-2:0.11324088871404812 | Rouge-l:0.2619133914624429\n",
            "Epoch: 4 | Step: 260 | Train loss: 0.9118392467498779 | lr: 0.0009127218934911243 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.25388475327470883 | Rouge-2:0.08600357770229514 | Rouge-l:0.2341097978379887\n",
            "Epoch: 4 | Step: 270 | Train loss: 0.976611852645874 | lr: 0.0009127218934911243 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2603846638780335 | Rouge-2:0.10786942674217082 | Rouge-l:0.2063427346063248\n",
            "Epoch: 4 | Step: 280 | Train loss: 1.018611192703247 | lr: 0.0009124753451676529 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.29352042448773186 | Rouge-2:0.15020655369887295 | Rouge-l:0.26054558682539414\n",
            "Epoch: 4 | Step: 290 | Train loss: 1.0764124393463135 | lr: 0.0009122287968441815 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.22326582981597518 | Rouge-2:0.09416678693251376 | Rouge-l:0.2004025819527273\n",
            "Epoch: 4 | Step: 300 | Train loss: 0.9706512689590454 | lr: 0.0009122287968441815 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.31597137363123784 | Rouge-2:0.13647055100297065 | Rouge-l:0.27564258796677443\n",
            "Epoch: 4 | Step: 310 | Train loss: 1.0323559045791626 | lr: 0.0009119822485207101 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.19132353561069917 | Rouge-2:0.06910715108433443 | Rouge-l:0.1815394600371499\n",
            "Epoch: 4 | Step: 320 | Train loss: 1.0528508424758911 | lr: 0.0009117357001972387 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2557820427213772 | Rouge-2:0.12026480506423223 | Rouge-l:0.24814315383248833\n",
            "Epoch: 4 | Step: 330 | Train loss: 0.938248872756958 | lr: 0.0009117357001972387 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2835255685450011 | Rouge-2:0.1158584872608566 | Rouge-l:0.2453486562570974\n",
            "Epoch: 4 | Step: 340 | Train loss: 1.1730918884277344 | lr: 0.0009114891518737673 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.28182559088583786 | Rouge-2:0.12878151049383205 | Rouge-l:0.25800466404766975\n",
            "Epoch: 4 | Step: 350 | Train loss: 1.0721255540847778 | lr: 0.0009114891518737673 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2641334201110194 | Rouge-2:0.1080286163500172 | Rouge-l:0.24841637943780767\n",
            "Epoch: 4 | Step: 360 | Train loss: 0.7606952786445618 | lr: 0.0009112426035502958 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.18887236271608668 | Rouge-2:0.0846549341418901 | Rouge-l:0.1804932418369658\n",
            "Epoch: 4 | Step: 370 | Train loss: 1.0869284868240356 | lr: 0.0009109960552268245 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.20712160390036063 | Rouge-2:0.04809337780286352 | Rouge-l:0.1845258633412334\n",
            "Epoch: 4 | Step: 380 | Train loss: 1.161861538887024 | lr: 0.0009109960552268245 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2819794749069764 | Rouge-2:0.10688694016268147 | Rouge-l:0.23793456148706302\n",
            "Epoch: 4 | Step: 390 | Train loss: 1.0078322887420654 | lr: 0.0009107495069033531 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.33069774049017125 | Rouge-2:0.19744709976168467 | Rouge-l:0.31876592230835304\n",
            "Epoch: 4 | Step: 400 | Train loss: 0.8912002444267273 | lr: 0.0009105029585798816 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.312178244033006 | Rouge-2:0.1318739412577667 | Rouge-l:0.2960231411409036\n",
            "Epoch: 4 | Step: 410 | Train loss: 0.9417750835418701 | lr: 0.0009105029585798816 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.33266484674962044 | Rouge-2:0.15169997519792053 | Rouge-l:0.284691937779269\n",
            "Epoch: 4 | Step: 420 | Train loss: 0.8451948761940002 | lr: 0.0009102564102564102 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.16394379299303943 | Rouge-2:0.02920634776425332 | Rouge-l:0.12401714447519317\n",
            "Epoch: 4 | Step: 430 | Train loss: 1.1858255863189697 | lr: 0.0009102564102564102 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2452055564374532 | Rouge-2:0.07974568628487312 | Rouge-l:0.2235596620093007\n",
            "Epoch: 4 | Step: 440 | Train loss: 0.9510304927825928 | lr: 0.0009100098619329389 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.3086759812369244 | Rouge-2:0.08870938022745109 | Rouge-l:0.24091198978740413\n",
            "Epoch: 4 | Step: 450 | Train loss: 1.094030499458313 | lr: 0.0009097633136094676 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.30866486256606324 | Rouge-2:0.18989251464368934 | Rouge-l:0.30241486256606326\n",
            "Epoch: 4 | Step: 460 | Train loss: 0.7934296727180481 | lr: 0.0009097633136094676 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2509676248935653 | Rouge-2:0.10740121155241035 | Rouge-l:0.23559958775828677\n",
            "Epoch: 4 | Step: 470 | Train loss: 0.8769298791885376 | lr: 0.000909516765285996 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.27373449349603074 | Rouge-2:0.1390269129694658 | Rouge-l:0.24823529864900987\n",
            "Epoch: 4 | Step: 480 | Train loss: 0.964335024356842 | lr: 0.0009092702169625247 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.21659014217057582 | Rouge-2:0.09901444938697217 | Rouge-l:0.20227737160780532\n",
            "Epoch: 4 | Step: 490 | Train loss: 1.1273846626281738 | lr: 0.0009092702169625247 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2443224232685187 | Rouge-2:0.09339759165804204 | Rouge-l:0.20877348146957686\n",
            "Epoch: 4 | Step: 500 | Train loss: 0.8509958982467651 | lr: 0.0009090236686390533 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2398923064475914 | Rouge-2:0.11534618367787305 | Rouge-l:0.20133711164239662\n",
            "Epoch: 4 | Step: 510 | Train loss: 0.9410492777824402 | lr: 0.0009090236686390533 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2230592115277715 | Rouge-2:0.11522611269612736 | Rouge-l:0.2103026971703492\n",
            "Epoch: 4 | Step: 520 | Train loss: 1.2914150953292847 | lr: 0.0009087771203155819 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.22257367203440853 | Rouge-2:0.07979436614427449 | Rouge-l:0.2177659797267162\n",
            "Epoch: 4 | Step: 530 | Train loss: 0.9193957448005676 | lr: 0.0009085305719921104 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.20021643758992236 | Rouge-2:0.029389880057010466 | Rouge-l:0.15908893586459455\n",
            "Epoch: 4 | Step: 540 | Train loss: 1.1847360134124756 | lr: 0.0009085305719921104 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.1878043462804892 | Rouge-2:0.06572321445344861 | Rouge-l:0.16507956557873482\n",
            "Epoch: 4 | Step: 550 | Train loss: 1.2006964683532715 | lr: 0.0009082840236686391 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2807697506767747 | Rouge-2:0.1124534697250023 | Rouge-l:0.2285856294437404\n",
            "Epoch: 4 | Step: 560 | Train loss: 1.085756540298462 | lr: 0.0009080374753451676 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.3450352618441085 | Rouge-2:0.20987716038409274 | Rouge-l:0.3317019285107752\n",
            "Epoch: 4 | Step: 570 | Train loss: 0.8968380093574524 | lr: 0.0009080374753451676 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.26753835639588613 | Rouge-2:0.14981384103281123 | Rouge-l:0.25265740401493375\n",
            "Epoch: 4 | Step: 580 | Train loss: 1.0344847440719604 | lr: 0.0009077909270216963 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2697409330768893 | Rouge-2:0.11211243579294478 | Rouge-l:0.2547487700674849\n",
            "Epoch: 4 | Step: 590 | Train loss: 1.0414609909057617 | lr: 0.0009077909270216963 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.31510300554904463 | Rouge-2:0.15932127607621388 | Rouge-l:0.28438137039887784\n",
            "Epoch: 4 | Step: 600 | Train loss: 0.7801644802093506 | lr: 0.0009075443786982249 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.20986820690310692 | Rouge-2:0.06768304241688425 | Rouge-l:0.1928905608932029\n",
            "Epoch: 4 | Step: 610 | Train loss: 1.0645486116409302 | lr: 0.0009072978303747535 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.19875406534929838 | Rouge-2:0.04992209447661185 | Rouge-l:0.17296684087786338\n",
            "Epoch: 4 | Step: 620 | Train loss: 1.2949835062026978 | lr: 0.0009072978303747535 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2776890035886886 | Rouge-2:0.11910794689510701 | Rouge-l:0.25110939156234485\n",
            "Epoch: 4 | Step: 630 | Train loss: 0.9575520157814026 | lr: 0.000907051282051282 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.36181049191505193 | Rouge-2:0.15505336240743764 | Rouge-l:0.3099810550120856\n",
            "Epoch: 4 | Step: 640 | Train loss: 0.8304342031478882 | lr: 0.0009068047337278107 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.27002677811395115 | Rouge-2:0.08634393064729791 | Rouge-l:0.20597333427602452\n",
            "Epoch: 4 | Step: 650 | Train loss: 0.9928385019302368 | lr: 0.0009068047337278107 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.3592420580223252 | Rouge-2:0.20780868135099273 | Rouge-l:0.3210038197840868\n",
            "Epoch: 4 | Step: 660 | Train loss: 1.191208004951477 | lr: 0.0009065581854043394 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2649314335081865 | Rouge-2:0.10423960635644189 | Rouge-l:0.23606451935901432\n",
            "Epoch: 4 | Step: 670 | Train loss: 1.155155062675476 | lr: 0.0009065581854043394 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.21422411578809122 | Rouge-2:0.10103920556876443 | Rouge-l:0.2095944861584616\n",
            "Epoch: 4 | Step: 680 | Train loss: 1.047303318977356 | lr: 0.0009063116370808678 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2465141788659906 | Rouge-2:0.11741227639229368 | Rouge-l:0.22233136057738487\n",
            "Epoch: 4 | Step: 690 | Train loss: 1.162477731704712 | lr: 0.0009060650887573965 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.28658941168987634 | Rouge-2:0.09604320500133774 | Rouge-l:0.2528681999514232\n",
            "Epoch: 4 | Step: 700 | Train loss: 1.2706291675567627 | lr: 0.0009060650887573965 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2045917706682599 | Rouge-2:0.1001645937964451 | Rouge-l:0.1920141309167071\n",
            "Epoch: 4 | Step: 710 | Train loss: 0.9931164979934692 | lr: 0.0009058185404339251 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.28935217388932954 | Rouge-2:0.17364776622687134 | Rouge-l:0.26377809618701903\n",
            "Epoch: 4 | Step: 720 | Train loss: 1.0250332355499268 | lr: 0.0009055719921104537 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.32196128327372864 | Rouge-2:0.16958837844358188 | Rouge-l:0.30807239438483974\n",
            "Epoch: 4 | Step: 730 | Train loss: 0.9223688244819641 | lr: 0.0009055719921104537 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2641004675458325 | Rouge-2:0.12714736460918066 | Rouge-l:0.25002079721616216\n",
            "Epoch: 4 | Step: 740 | Train loss: 0.920967161655426 | lr: 0.0009053254437869822 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2892954159009162 | Rouge-2:0.12170785623077658 | Rouge-l:0.2590908981963986\n",
            "Epoch: 4 | Step: 750 | Train loss: 0.8728530406951904 | lr: 0.0009053254437869822 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2795574400771623 | Rouge-2:0.13041726555838506 | Rouge-l:0.24895058441408477\n",
            "Epoch: 4 | Step: 760 | Train loss: 0.9232936501502991 | lr: 0.0009050788954635109 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.22472750781817394 | Rouge-2:0.1058065105462571 | Rouge-l:0.20775918202631877\n",
            "Epoch: 4 | Step: 770 | Train loss: 1.1405118703842163 | lr: 0.0009048323471400395 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.3320008780309752 | Rouge-2:0.09815016493149109 | Rouge-l:0.3097470901521874\n",
            "Epoch: 4 | Step: 780 | Train loss: 0.9317381381988525 | lr: 0.0009048323471400395 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2989297074534412 | Rouge-2:0.10666948655350136 | Rouge-l:0.25951760065505813\n",
            "Epoch: 4 | Step: 790 | Train loss: 0.8784601092338562 | lr: 0.0009045857988165681 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.22439172870106083 | Rouge-2:0.13033841495960313 | Rouge-l:0.22439172870106083\n",
            "Epoch: 4 | Step: 800 | Train loss: 0.8309531211853027 | lr: 0.0009043392504930966 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.24108258513498923 | Rouge-2:0.05797445698185743 | Rouge-l:0.2216543571130112\n",
            "Epoch: 4 | Step: 810 | Train loss: 0.9615392684936523 | lr: 0.0009043392504930966 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.3204197589633471 | Rouge-2:0.12674835862428185 | Rouge-l:0.26286295366853873\n",
            "Epoch: 4 | Step: 820 | Train loss: 0.8278291821479797 | lr: 0.0009040927021696253 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.19153513621259458 | Rouge-2:0.03793408207867071 | Rouge-l:0.18068444176815016\n",
            "Epoch: 4 | Step: 830 | Train loss: 1.2156312465667725 | lr: 0.0009040927021696253 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2816208351334883 | Rouge-2:0.1012525663744543 | Rouge-l:0.2650488654365186\n",
            "Epoch: 4 | Step: 840 | Train loss: 0.9599127173423767 | lr: 0.0009038461538461538 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.32674342256364847 | Rouge-2:0.13970632047418782 | Rouge-l:0.28788845152117726\n",
            "Epoch: 4 | Step: 850 | Train loss: 0.9038942456245422 | lr: 0.0009035996055226825 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.17934107856827555 | Rouge-2:0.04566473212635869 | Rouge-l:0.16148393571113276\n",
            "Epoch: 4 | Step: 860 | Train loss: 0.8837316632270813 | lr: 0.0009035996055226825 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.34236765645229456 | Rouge-2:0.18929757380299916 | Rouge-l:0.29486130376502084\n",
            "Epoch: 4 | Step: 870 | Train loss: 1.0767574310302734 | lr: 0.000903353057199211 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.3430115002798946 | Rouge-2:0.1677367130530968 | Rouge-l:0.30470034248344263\n",
            "Epoch: 4 | Step: 880 | Train loss: 1.1754177808761597 | lr: 0.0009031065088757396 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.2784864736818972 | Rouge-2:0.09351832390410085 | Rouge-l:0.2303089111128873\n",
            "Epoch: 4 | Step: 890 | Train loss: 1.0394067764282227 | lr: 0.0009031065088757396 | Min loss:0.7009577751159668\n",
            "Rouge-1:0.3242607380191049 | Rouge-2:0.12181679923703692 | Rouge-l:0.266237459891837\n",
            "Epoch: 4 | Step: 900 | Train loss: 1.0143752098083496 | lr: 0.0009028599605522683 | Min loss:0.7009577751159668\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 4 | Step: 901 | Train loss: 0.6856606602668762 | lr: 0.0009028599605522683 | Min loss:0.6856606602668762\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.2116685947408833 | Rouge-2:0.1049099188305584 | Rouge-l:0.19772862028366747\n",
            "Epoch: 4 | Step: 910 | Train loss: 0.9722038507461548 | lr: 0.0009028599605522683 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.19344302630705093 | Rouge-2:0.07561853507345159 | Rouge-l:0.17651594297371767\n",
            "Epoch: 4 | Step: 920 | Train loss: 1.0516022443771362 | lr: 0.0009026134122287969 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.19072984603700577 | Rouge-2:0.07505952206939497 | Rouge-l:0.1819335497407095\n",
            "Epoch: 4 | Step: 930 | Train loss: 0.9320814609527588 | lr: 0.0009023668639053254 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.25583295335876893 | Rouge-2:0.08564103979604891 | Rouge-l:0.21331235915365399\n",
            "Epoch: 4 | Step: 940 | Train loss: 1.0551904439926147 | lr: 0.0009023668639053254 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.2895418499465123 | Rouge-2:0.08146448441289615 | Rouge-l:0.24422436939060252\n",
            "Epoch: 4 | Step: 950 | Train loss: 1.017584204673767 | lr: 0.000902120315581854 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.28885893863878165 | Rouge-2:0.09661596686405646 | Rouge-l:0.24482606104166257\n",
            "Epoch: 4 | Step: 960 | Train loss: 1.0673805475234985 | lr: 0.0009018737672583827 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.3561913701927473 | Rouge-2:0.18568851252181354 | Rouge-l:0.3098269687586864\n",
            "Epoch: 4 | Step: 970 | Train loss: 0.9864258766174316 | lr: 0.0009018737672583827 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.3120982410792098 | Rouge-2:0.15364344190881626 | Rouge-l:0.2824783154858743\n",
            "Epoch: 4 | Step: 980 | Train loss: 0.982977569103241 | lr: 0.0009016272189349113 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.31195337226158903 | Rouge-2:0.1625839493208459 | Rouge-l:0.2683085911168079\n",
            "Epoch: 4 | Step: 990 | Train loss: 1.0109318494796753 | lr: 0.0009016272189349113 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.24671094074052113 | Rouge-2:0.0732763535728885 | Rouge-l:0.21124498512750675\n",
            "Epoch: 4 | Step: 1000 | Train loss: 1.1983928680419922 | lr: 0.0009013806706114399 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.16194881391702437 | Rouge-2:0.05714424741125574 | Rouge-l:0.1375440520122625\n",
            "Epoch: 4 | Step: 1010 | Train loss: 1.2337656021118164 | lr: 0.0009011341222879684 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.2762290637957897 | Rouge-2:0.11254836154793943 | Rouge-l:0.26500308217507124\n",
            "Epoch: 4 | Step: 1020 | Train loss: 1.1706798076629639 | lr: 0.0009011341222879684 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.26687400889913737 | Rouge-2:0.09352446230892378 | Rouge-l:0.2377767679611256\n",
            "Epoch: 4 | Step: 1030 | Train loss: 1.0898975133895874 | lr: 0.0009008875739644971 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.2562384249497826 | Rouge-2:0.09902085573147669 | Rouge-l:0.2302448352061929\n",
            "Epoch: 4 | Step: 1040 | Train loss: 0.9899930953979492 | lr: 0.0009006410256410256 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.338368839910356 | Rouge-2:0.19522917568934808 | Rouge-l:0.2929146204330696\n",
            "Epoch: 4 | Step: 1050 | Train loss: 0.8676749467849731 | lr: 0.0009006410256410256 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.23757190282935534 | Rouge-2:0.10769739279116397 | Rouge-l:0.21806132081877336\n",
            "Epoch: 4 | Step: 1060 | Train loss: 1.105622410774231 | lr: 0.0009003944773175543 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.28582865509252914 | Rouge-2:0.10849081720423964 | Rouge-l:0.25884260021173744\n",
            "Epoch: 4 | Step: 1070 | Train loss: 1.0291101932525635 | lr: 0.0009003944773175543 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.29059782533355616 | Rouge-2:0.15365832433240767 | Rouge-l:0.25627312420485787\n",
            "Epoch: 4 | Step: 1080 | Train loss: 1.0715805292129517 | lr: 0.0009001479289940828 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.2940835688827256 | Rouge-2:0.08950175158914536 | Rouge-l:0.24700085753277284\n",
            "Epoch: 4 | Step: 1090 | Train loss: 0.8693756461143494 | lr: 0.0008999013806706114 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.3071302732523324 | Rouge-2:0.1390462377810825 | Rouge-l:0.2782614024716969\n",
            "Epoch: 4 | Step: 1100 | Train loss: 1.0274561643600464 | lr: 0.0008999013806706114 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.27160737390358974 | Rouge-2:0.10698458080300205 | Rouge-l:0.2452791329014357\n",
            "Epoch: 4 | Step: 1110 | Train loss: 0.9906375408172607 | lr: 0.00089965483234714 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.22325203460348583 | Rouge-2:0.09423676808037132 | Rouge-l:0.20658536793681923\n",
            "Epoch: 4 | Step: 1120 | Train loss: 0.9452123045921326 | lr: 0.0008994082840236687 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.2363358214138016 | Rouge-2:0.055453945715077856 | Rouge-l:0.19513813021611046\n",
            "Epoch: 4 | Step: 1130 | Train loss: 1.1749043464660645 | lr: 0.0008994082840236687 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.3307417261204254 | Rouge-2:0.13389509550450504 | Rouge-l:0.29795456469266146\n",
            "Epoch: 4 | Step: 1140 | Train loss: 1.102066993713379 | lr: 0.0008991617357001973 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.2808220414833288 | Rouge-2:0.06660363483279405 | Rouge-l:0.22667998734127467\n",
            "Epoch: 4 | Step: 1150 | Train loss: 1.2143571376800537 | lr: 0.0008991617357001973 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.2632153328878149 | Rouge-2:0.11253821461166638 | Rouge-l:0.24642506977402237\n",
            "Epoch: 4 | Step: 1160 | Train loss: 1.0458471775054932 | lr: 0.0008989151873767258 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.25310528403100613 | Rouge-2:0.10005739787401867 | Rouge-l:0.22810528403100613\n",
            "Epoch: 4 | Step: 1170 | Train loss: 1.1160863637924194 | lr: 0.0008986686390532545 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.2207797482025738 | Rouge-2:0.07999331626272936 | Rouge-l:0.1754984289121082\n",
            "Epoch: 4 | Step: 1180 | Train loss: 1.1101405620574951 | lr: 0.0008986686390532545 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.1919250600568825 | Rouge-2:0.05205513631458551 | Rouge-l:0.1872954304272529\n",
            "Epoch: 4 | Step: 1190 | Train loss: 0.8341315984725952 | lr: 0.0008984220907297831 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.32513777805090555 | Rouge-2:0.127013777624698 | Rouge-l:0.2778283294458998\n",
            "Epoch: 4 | Step: 1200 | Train loss: 0.8682506084442139 | lr: 0.0008981755424063116 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.26314537709138686 | Rouge-2:0.0774352472483064 | Rouge-l:0.21806129702089375\n",
            "Epoch: 4 | Step: 1210 | Train loss: 1.083134651184082 | lr: 0.0008981755424063116 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.17186604155072688 | Rouge-2:0.06441765589240868 | Rouge-l:0.16071885540354075\n",
            "Epoch: 4 | Step: 1220 | Train loss: 1.3340065479278564 | lr: 0.0008979289940828402 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.2667403012198837 | Rouge-2:0.1539620289601881 | Rouge-l:0.2433394076816904\n",
            "Epoch: 4 | Step: 1230 | Train loss: 1.0174150466918945 | lr: 0.0008979289940828402 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.2487911924159697 | Rouge-2:0.09362430063082545 | Rouge-l:0.20617959649555032\n",
            "Epoch: 4 | Step: 1240 | Train loss: 1.1663352251052856 | lr: 0.0008976824457593689 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.2743562326538724 | Rouge-2:0.10637307744525065 | Rouge-l:0.23194601077166777\n",
            "Epoch: 4 | Step: 1250 | Train loss: 1.0861316919326782 | lr: 0.0008974358974358974 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.2974273974312497 | Rouge-2:0.17413735815180775 | Rouge-l:0.2835289844218453\n",
            "Epoch: 4 | Step: 1260 | Train loss: 1.0194084644317627 | lr: 0.0008974358974358974 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.2675572339662504 | Rouge-2:0.12265952591925937 | Rouge-l:0.23152665214694504\n",
            "Epoch: 4 | Step: 1270 | Train loss: 0.9186057448387146 | lr: 0.000897189349112426 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.16722117095286854 | Rouge-2:0.07225694262480077 | Rouge-l:0.16241347864517625\n",
            "Epoch: 4 | Step: 1280 | Train loss: 0.8775039911270142 | lr: 0.0008969428007889546 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.2818817158267471 | Rouge-2:0.11559830920744493 | Rouge-l:0.24060339401415115\n",
            "Epoch: 4 | Step: 1290 | Train loss: 0.9712583422660828 | lr: 0.0008969428007889546 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.1799895068896219 | Rouge-2:0.059953702179955465 | Rouge-l:0.15199709684464444\n",
            "Epoch: 4 | Step: 1300 | Train loss: 1.1458063125610352 | lr: 0.0008966962524654833 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.20677073211005995 | Rouge-2:0.07134647219916011 | Rouge-l:0.18909055192987978\n",
            "Epoch: 4 | Step: 1310 | Train loss: 1.148541808128357 | lr: 0.0008966962524654833 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.24144127402775178 | Rouge-2:0.06781284683960778 | Rouge-l:0.21771130607903383\n",
            "Epoch: 4 | Step: 1320 | Train loss: 1.1221692562103271 | lr: 0.0008964497041420119 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.2440027782984424 | Rouge-2:0.08203977473968903 | Rouge-l:0.2218284852002363\n",
            "Epoch: 4 | Step: 1330 | Train loss: 1.0681564807891846 | lr: 0.0008962031558185405 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.2595809093355215 | Rouge-2:0.08024751526680333 | Rouge-l:0.2272385768730286\n",
            "Epoch: 4 | Step: 1340 | Train loss: 1.0457020998001099 | lr: 0.0008962031558185405 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.286016574818573 | Rouge-2:0.10044578213335333 | Rouge-l:0.23548334539777244\n",
            "Epoch: 4 | Step: 1350 | Train loss: 1.0924471616744995 | lr: 0.0008959566074950691 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.24730743433052665 | Rouge-2:0.08394878692211981 | Rouge-l:0.24267780470089703\n",
            "Epoch: 5 | Step: 0 | Train loss: 0.8363795876502991 | lr: 0.0008959566074950691 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.262064436637374 | Rouge-2:0.12129055935472562 | Rouge-l:0.23432323788514584\n",
            "Epoch: 5 | Step: 10 | Train loss: 0.842644989490509 | lr: 0.0008957100591715976 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.20224109771235985 | Rouge-2:0.06701468557916705 | Rouge-l:0.1722940575908203\n",
            "Epoch: 5 | Step: 20 | Train loss: 1.1151843070983887 | lr: 0.0008957100591715976 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.34211541407104024 | Rouge-2:0.19260775502236283 | Rouge-l:0.29978331457224183\n",
            "Epoch: 5 | Step: 30 | Train loss: 1.0178524255752563 | lr: 0.0008954635108481263 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.28120363327698417 | Rouge-2:0.14635407569165854 | Rouge-l:0.2720495928729438\n",
            "Epoch: 5 | Step: 40 | Train loss: 0.9634264707565308 | lr: 0.0008952169625246549 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.29739252440376845 | Rouge-2:0.1227179872883729 | Rouge-l:0.2622521258530438\n",
            "Epoch: 5 | Step: 50 | Train loss: 0.7895870208740234 | lr: 0.0008952169625246549 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.45904369435484127 | Rouge-2:0.2633709703685563 | Rouge-l:0.41752821361594805\n",
            "Epoch: 5 | Step: 60 | Train loss: 0.7656130790710449 | lr: 0.0008949704142011834 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.3215509519445712 | Rouge-2:0.1645615497579402 | Rouge-l:0.30763915784162266\n",
            "Epoch: 5 | Step: 70 | Train loss: 0.7747620344161987 | lr: 0.0008949704142011834 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.24400935755576908 | Rouge-2:0.08256884787813618 | Rouge-l:0.2088876743613461\n",
            "Epoch: 5 | Step: 80 | Train loss: 0.9993268251419067 | lr: 0.000894723865877712 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.21951483546092723 | Rouge-2:0.07217036771527005 | Rouge-l:0.199482784178876\n",
            "Epoch: 5 | Step: 90 | Train loss: 0.9606943130493164 | lr: 0.0008944773175542407 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.32360158628660884 | Rouge-2:0.12407106509780888 | Rouge-l:0.2972027274315789\n",
            "Epoch: 5 | Step: 100 | Train loss: 1.033006191253662 | lr: 0.0008944773175542407 | Min loss:0.6856606602668762\n",
            "Rouge-1:0.3033196311833846 | Rouge-2:0.12031692240892031 | Rouge-l:0.26886361905467515\n",
            "Epoch: 5 | Step: 110 | Train loss: 0.8988988399505615 | lr: 0.0008942307692307693 | Min loss:0.6856606602668762\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.32413146507477797 | Rouge-2:0.19857614265010903 | Rouge-l:0.28961036989914163\n",
            "Epoch: 5 | Step: 120 | Train loss: 0.6618687510490417 | lr: 0.0008939842209072978 | Min loss:0.6856606602668762\n",
            "Epoch: 5 | Step: 120 | Train loss: 0.6618687510490417 | lr: 0.0008939842209072978 | Min loss:0.6618687510490417\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.20925740862292422 | Rouge-2:0.07098010122098178 | Rouge-l:0.17529670449774645\n",
            "Epoch: 5 | Step: 130 | Train loss: 0.9560802578926086 | lr: 0.0008939842209072978 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2771690095463415 | Rouge-2:0.1229431448167439 | Rouge-l:0.2532926875721934\n",
            "Epoch: 5 | Step: 140 | Train loss: 0.9295961260795593 | lr: 0.0008937376725838264 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2909499143666741 | Rouge-2:0.11838278184883363 | Rouge-l:0.25145392185344023\n",
            "Epoch: 5 | Step: 150 | Train loss: 0.9588344097137451 | lr: 0.0008937376725838264 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.28973812179816566 | Rouge-2:0.08533048036935141 | Rouge-l:0.20958210791016246\n",
            "Epoch: 5 | Step: 160 | Train loss: 1.0127679109573364 | lr: 0.0008934911242603551 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.3549586866460613 | Rouge-2:0.21058781326577086 | Rouge-l:0.3100012544578416\n",
            "Epoch: 5 | Step: 170 | Train loss: 0.922279953956604 | lr: 0.0008932445759368836 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.28924819105534855 | Rouge-2:0.09545797315695759 | Rouge-l:0.2569015079511346\n",
            "Epoch: 5 | Step: 180 | Train loss: 1.1587425470352173 | lr: 0.0008932445759368836 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.35659286108621324 | Rouge-2:0.19044080289081763 | Rouge-l:0.32012570670141016\n",
            "Epoch: 5 | Step: 190 | Train loss: 0.9257837533950806 | lr: 0.0008929980276134122 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.19993592222384898 | Rouge-2:0.06947581286134373 | Rouge-l:0.17462355310476482\n",
            "Epoch: 5 | Step: 200 | Train loss: 0.9964950680732727 | lr: 0.0008927514792899409 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.20649257112328503 | Rouge-2:0.06372031374694596 | Rouge-l:0.1776828391885531\n",
            "Epoch: 5 | Step: 210 | Train loss: 1.2989561557769775 | lr: 0.0008927514792899409 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.28545004281107467 | Rouge-2:0.11178068964904363 | Rouge-l:0.2538710954426536\n",
            "Epoch: 5 | Step: 220 | Train loss: 0.8708711862564087 | lr: 0.0008925049309664694 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.32939450138743775 | Rouge-2:0.1384248781723959 | Rouge-l:0.3081698987483614\n",
            "Epoch: 5 | Step: 230 | Train loss: 0.9186016917228699 | lr: 0.0008925049309664694 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2658132020866996 | Rouge-2:0.11863950477323615 | Rouge-l:0.24158742786092538\n",
            "Epoch: 5 | Step: 240 | Train loss: 0.8311848640441895 | lr: 0.0008922583826429981 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2330457966420154 | Rouge-2:0.0876368355186895 | Rouge-l:0.2110760996723184\n",
            "Epoch: 5 | Step: 250 | Train loss: 0.9738643169403076 | lr: 0.0008920118343195266 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.26380188946164135 | Rouge-2:0.10158162718216698 | Rouge-l:0.24131511697486885\n",
            "Epoch: 5 | Step: 260 | Train loss: 0.9705942273139954 | lr: 0.0008920118343195266 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2381785289871868 | Rouge-2:0.08882753555371406 | Rouge-l:0.19263257055556596\n",
            "Epoch: 5 | Step: 270 | Train loss: 1.0368506908416748 | lr: 0.0008917652859960553 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.3069989705437419 | Rouge-2:0.165165347286394 | Rouge-l:0.28402808178337946\n",
            "Epoch: 5 | Step: 280 | Train loss: 0.8707793354988098 | lr: 0.0008915187376725838 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2926408070403809 | Rouge-2:0.1551768305967774 | Rouge-l:0.2818951930052932\n",
            "Epoch: 5 | Step: 290 | Train loss: 0.935301661491394 | lr: 0.0008915187376725838 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2548272460554211 | Rouge-2:0.13258876831305885 | Rouge-l:0.2471578321360072\n",
            "Epoch: 5 | Step: 300 | Train loss: 0.9930424690246582 | lr: 0.0008912721893491125 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.3136682908863712 | Rouge-2:0.17007991299654698 | Rouge-l:0.294305545788332\n",
            "Epoch: 5 | Step: 310 | Train loss: 0.7887473702430725 | lr: 0.0008912721893491125 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.26146483186756203 | Rouge-2:0.10787556013210617 | Rouge-l:0.2244310509638962\n",
            "Epoch: 5 | Step: 320 | Train loss: 1.106966495513916 | lr: 0.0008910256410256411 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2762516787250433 | Rouge-2:0.12319501162598638 | Rouge-l:0.2511543801902448\n",
            "Epoch: 5 | Step: 330 | Train loss: 0.8728143572807312 | lr: 0.0008907790927021696 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.3255224054239574 | Rouge-2:0.14232530961089046 | Rouge-l:0.27550951134910473\n",
            "Epoch: 5 | Step: 340 | Train loss: 0.8716092109680176 | lr: 0.0008907790927021696 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.29790212813359157 | Rouge-2:0.1220427612450859 | Rouge-l:0.2513639440954075\n",
            "Epoch: 5 | Step: 350 | Train loss: 0.9367982745170593 | lr: 0.0008905325443786982 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2721307859836034 | Rouge-2:0.12011469656395891 | Rouge-l:0.2547200716978891\n",
            "Epoch: 5 | Step: 360 | Train loss: 0.9386865496635437 | lr: 0.0008902859960552269 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.22828016647058252 | Rouge-2:0.08529666433105546 | Rouge-l:0.21829552745368547\n",
            "Epoch: 5 | Step: 370 | Train loss: 1.0816937685012817 | lr: 0.0008902859960552269 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2744940218930604 | Rouge-2:0.12296751617316681 | Rouge-l:0.24287389445677854\n",
            "Epoch: 5 | Step: 380 | Train loss: 0.9275730848312378 | lr: 0.0008900394477317554 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2995798922532182 | Rouge-2:0.10002429025038503 | Rouge-l:0.23468304949793628\n",
            "Epoch: 5 | Step: 390 | Train loss: 0.9727901220321655 | lr: 0.0008900394477317554 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2094978129041017 | Rouge-2:0.07622481562533885 | Rouge-l:0.18210395563219567\n",
            "Epoch: 5 | Step: 400 | Train loss: 1.0288970470428467 | lr: 0.000889792899408284 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.30480556729216085 | Rouge-2:0.12767308689460938 | Rouge-l:0.2620739551304858\n",
            "Epoch: 5 | Step: 410 | Train loss: 0.9639040231704712 | lr: 0.0008895463510848127 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2603558904287408 | Rouge-2:0.11544464833764953 | Rouge-l:0.23205404432798168\n",
            "Epoch: 5 | Step: 420 | Train loss: 0.9227562546730042 | lr: 0.0008895463510848127 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.25607727706182015 | Rouge-2:0.10384915087398952 | Rouge-l:0.2162759455169665\n",
            "Epoch: 5 | Step: 430 | Train loss: 0.9158892631530762 | lr: 0.0008892998027613413 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.3160179106452054 | Rouge-2:0.14786692692837278 | Rouge-l:0.2535525875820563\n",
            "Epoch: 5 | Step: 440 | Train loss: 1.0051231384277344 | lr: 0.0008890532544378699 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.34577107869440316 | Rouge-2:0.13982030188126524 | Rouge-l:0.3097163781173771\n",
            "Epoch: 5 | Step: 450 | Train loss: 0.7372937798500061 | lr: 0.0008890532544378699 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.27385882875199336 | Rouge-2:0.1377986496290406 | Rouge-l:0.2540179716685733\n",
            "Epoch: 5 | Step: 460 | Train loss: 1.0542340278625488 | lr: 0.0008888067061143984 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.19985992118683626 | Rouge-2:0.0650615367562449 | Rouge-l:0.19071357972342162\n",
            "Epoch: 5 | Step: 470 | Train loss: 1.056679368019104 | lr: 0.0008888067061143984 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.33976644644577114 | Rouge-2:0.1717550771991061 | Rouge-l:0.31015907465089937\n",
            "Epoch: 5 | Step: 480 | Train loss: 0.9836994409561157 | lr: 0.0008885601577909271 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2673671766409953 | Rouge-2:0.11512127278157834 | Rouge-l:0.21538832966214833\n",
            "Epoch: 5 | Step: 490 | Train loss: 1.031822681427002 | lr: 0.0008883136094674556 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.27943163774080637 | Rouge-2:0.11087065407330018 | Rouge-l:0.2511086210543606\n",
            "Epoch: 5 | Step: 500 | Train loss: 0.9645401835441589 | lr: 0.0008883136094674556 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.27202374079480174 | Rouge-2:0.13571031040175557 | Rouge-l:0.25192005415885693\n",
            "Epoch: 5 | Step: 510 | Train loss: 1.1523078680038452 | lr: 0.0008880670611439843 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2587046954309185 | Rouge-2:0.12027491627912215 | Rouge-l:0.2524546954309185\n",
            "Epoch: 5 | Step: 520 | Train loss: 0.9027237296104431 | lr: 0.0008878205128205128 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.20186411770196916 | Rouge-2:0.07795056217993114 | Rouge-l:0.18119203307864618\n",
            "Epoch: 5 | Step: 530 | Train loss: 1.0280323028564453 | lr: 0.0008878205128205128 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.3231652908921736 | Rouge-2:0.12045696662832342 | Rouge-l:0.25082018807832074\n",
            "Epoch: 5 | Step: 540 | Train loss: 1.0643517971038818 | lr: 0.0008875739644970414 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.21643298167215866 | Rouge-2:0.11040640210051986 | Rouge-l:0.2038648439780129\n",
            "Epoch: 5 | Step: 550 | Train loss: 0.9086147546768188 | lr: 0.0008875739644970414 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.23155896844658153 | Rouge-2:0.09458127328788557 | Rouge-l:0.2168522078159078\n",
            "Epoch: 5 | Step: 560 | Train loss: 1.1155883073806763 | lr: 0.00088732741617357 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.36548763809738855 | Rouge-2:0.1845867938764965 | Rouge-l:0.31808967793627047\n",
            "Epoch: 5 | Step: 570 | Train loss: 0.8096936345100403 | lr: 0.0008870808678500987 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2150949363777908 | Rouge-2:0.10333251832247353 | Rouge-l:0.21063065066350511\n",
            "Epoch: 5 | Step: 580 | Train loss: 0.8474356532096863 | lr: 0.0008870808678500987 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.26825855303681606 | Rouge-2:0.10154220509411299 | Rouge-l:0.24623928860027225\n",
            "Epoch: 5 | Step: 590 | Train loss: 0.8573711514472961 | lr: 0.0008868343195266271 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.29775622599031204 | Rouge-2:0.15210671161170294 | Rouge-l:0.2810863302881582\n",
            "Epoch: 5 | Step: 600 | Train loss: 0.88924640417099 | lr: 0.0008865877712031558 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.29029735924194494 | Rouge-2:0.10401191063727983 | Rouge-l:0.25809288251158147\n",
            "Epoch: 5 | Step: 610 | Train loss: 0.9447903037071228 | lr: 0.0008865877712031558 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.23379267051997737 | Rouge-2:0.08194509501318216 | Rouge-l:0.19477375465323546\n",
            "Epoch: 5 | Step: 620 | Train loss: 0.9596112370491028 | lr: 0.0008863412228796845 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.33445171643846466 | Rouge-2:0.2040161291670613 | Rouge-l:0.29665591289165305\n",
            "Epoch: 5 | Step: 630 | Train loss: 1.0373164415359497 | lr: 0.0008863412228796845 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.291065650841837 | Rouge-2:0.1389621928450013 | Rouge-l:0.27378886512755124\n",
            "Epoch: 5 | Step: 640 | Train loss: 0.8745617866516113 | lr: 0.0008860946745562131 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.12048086096161051 | Rouge-2:0.03825571766705151 | Rouge-l:0.10794953264080852\n",
            "Epoch: 5 | Step: 650 | Train loss: 1.2366838455200195 | lr: 0.0008858481262327417 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.21153710701838968 | Rouge-2:0.09724510929846 | Rouge-l:0.19695377368505637\n",
            "Epoch: 5 | Step: 660 | Train loss: 0.9096209406852722 | lr: 0.0008858481262327417 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.26470001105241103 | Rouge-2:0.11525948978797484 | Rouge-l:0.24862858248098244\n",
            "Epoch: 5 | Step: 670 | Train loss: 1.074222207069397 | lr: 0.0008856015779092702 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2996149051478093 | Rouge-2:0.142341093468559 | Rouge-l:0.2735732384811426\n",
            "Epoch: 5 | Step: 680 | Train loss: 0.8623358011245728 | lr: 0.0008853550295857989 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.17869013938983488 | Rouge-2:0.028615644654907083 | Rouge-l:0.15904728224697778\n",
            "Epoch: 5 | Step: 690 | Train loss: 0.9043622612953186 | lr: 0.0008853550295857989 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.1877505858577602 | Rouge-2:0.08664012226084175 | Rouge-l:0.17750811094137223\n",
            "Epoch: 5 | Step: 700 | Train loss: 0.9215633273124695 | lr: 0.0008851084812623274 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.31608642574879525 | Rouge-2:0.17471327656525296 | Rouge-l:0.26836901508980854\n",
            "Epoch: 5 | Step: 710 | Train loss: 1.0720716714859009 | lr: 0.0008851084812623274 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.24157405421872688 | Rouge-2:0.07736353888124715 | Rouge-l:0.20996615842631033\n",
            "Epoch: 5 | Step: 720 | Train loss: 0.9830789566040039 | lr: 0.0008848619329388561 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2624641093012365 | Rouge-2:0.098550568878737 | Rouge-l:0.24310359724957004\n",
            "Epoch: 5 | Step: 730 | Train loss: 1.1148008108139038 | lr: 0.0008846153846153846 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.31178277248748326 | Rouge-2:0.18975249797657584 | Rouge-l:0.29640578836049913\n",
            "Epoch: 5 | Step: 740 | Train loss: 0.7718936800956726 | lr: 0.0008846153846153846 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.28076213637786074 | Rouge-2:0.12440584919518961 | Rouge-l:0.2557880863470957\n",
            "Epoch: 5 | Step: 750 | Train loss: 1.1172370910644531 | lr: 0.0008843688362919132 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.3088007946963604 | Rouge-2:0.13326226051896087 | Rouge-l:0.27477030312910417\n",
            "Epoch: 5 | Step: 760 | Train loss: 0.908465564250946 | lr: 0.0008841222879684418 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2961956066431334 | Rouge-2:0.13771864253258845 | Rouge-l:0.26736311313672684\n",
            "Epoch: 5 | Step: 770 | Train loss: 0.9685752391815186 | lr: 0.0008841222879684418 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.29461561918226215 | Rouge-2:0.1436931417094808 | Rouge-l:0.2670400697317127\n",
            "Epoch: 5 | Step: 780 | Train loss: 0.8677014112472534 | lr: 0.0008838757396449705 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.23725590181181186 | Rouge-2:0.10684836859219309 | Rouge-l:0.2144213058522159\n",
            "Epoch: 5 | Step: 790 | Train loss: 0.9179092645645142 | lr: 0.0008838757396449705 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.31120509157746196 | Rouge-2:0.16220585474298224 | Rouge-l:0.29795780896876634\n",
            "Epoch: 5 | Step: 800 | Train loss: 0.9814977049827576 | lr: 0.000883629191321499 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.32370928727468745 | Rouge-2:0.13356264991895656 | Rouge-l:0.27091319447859463\n",
            "Epoch: 5 | Step: 810 | Train loss: 0.8471915125846863 | lr: 0.0008833826429980276 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2539528446561623 | Rouge-2:0.13651982998472073 | Rouge-l:0.24001886197217961\n",
            "Epoch: 5 | Step: 820 | Train loss: 0.9345134496688843 | lr: 0.0008833826429980276 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.29428032929039 | Rouge-2:0.12770640781892822 | Rouge-l:0.2666116531242714\n",
            "Epoch: 5 | Step: 830 | Train loss: 0.9079350233078003 | lr: 0.0008831360946745562 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.3589220357071502 | Rouge-2:0.17622911998559396 | Rouge-l:0.3332698763759848\n",
            "Epoch: 5 | Step: 840 | Train loss: 0.924835205078125 | lr: 0.0008828895463510849 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.23560237406362342 | Rouge-2:0.10275369398610969 | Rouge-l:0.2211932324805688\n",
            "Epoch: 5 | Step: 850 | Train loss: 1.0554944276809692 | lr: 0.0008828895463510849 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2759950036112504 | Rouge-2:0.12747242843401088 | Rouge-l:0.2429751970940014\n",
            "Epoch: 5 | Step: 860 | Train loss: 0.7802656292915344 | lr: 0.0008826429980276133 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.28803538413743346 | Rouge-2:0.1595795135967279 | Rouge-l:0.2729722231503594\n",
            "Epoch: 5 | Step: 870 | Train loss: 0.8914330005645752 | lr: 0.0008826429980276133 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2695514594639384 | Rouge-2:0.1286449909092428 | Rouge-l:0.2457845022730682\n",
            "Epoch: 5 | Step: 880 | Train loss: 0.8546797633171082 | lr: 0.000882396449704142 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.276302337533401 | Rouge-2:0.10346650759510792 | Rouge-l:0.2523936073746708\n",
            "Epoch: 5 | Step: 890 | Train loss: 1.0064144134521484 | lr: 0.0008821499013806707 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.32043210347591894 | Rouge-2:0.11683253306446265 | Rouge-l:0.27906659782349724\n",
            "Epoch: 5 | Step: 900 | Train loss: 1.1493521928787231 | lr: 0.0008821499013806707 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.25349199889395824 | Rouge-2:0.123014440984427 | Rouge-l:0.23378687811710572\n",
            "Epoch: 5 | Step: 910 | Train loss: 0.8704183101654053 | lr: 0.0008819033530571992 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.3446521360384956 | Rouge-2:0.1850726996293044 | Rouge-l:0.3009857118890593\n",
            "Epoch: 5 | Step: 920 | Train loss: 0.9388214945793152 | lr: 0.0008816568047337278 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2256866971882527 | Rouge-2:0.08978020766912671 | Rouge-l:0.19969235352452058\n",
            "Epoch: 5 | Step: 930 | Train loss: 1.1622925996780396 | lr: 0.0008816568047337278 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.24894975565419275 | Rouge-2:0.09836117953103794 | Rouge-l:0.20601820803514515\n",
            "Epoch: 5 | Step: 940 | Train loss: 1.133934497833252 | lr: 0.0008814102564102564 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2636057152326906 | Rouge-2:0.12104693900544013 | Rouge-l:0.24366463779161318\n",
            "Epoch: 5 | Step: 950 | Train loss: 0.9931425452232361 | lr: 0.0008814102564102564 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.33321069429280725 | Rouge-2:0.1589024434569727 | Rouge-l:0.2818992052293021\n",
            "Epoch: 5 | Step: 960 | Train loss: 0.8461870551109314 | lr: 0.0008811637080867851 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.25596424863235107 | Rouge-2:0.09322524847259546 | Rouge-l:0.23735891996028152\n",
            "Epoch: 5 | Step: 970 | Train loss: 1.0023531913757324 | lr: 0.0008809171597633136 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2847836032557676 | Rouge-2:0.10920403836210536 | Rouge-l:0.24558001511862176\n",
            "Epoch: 5 | Step: 980 | Train loss: 1.0476913452148438 | lr: 0.0008809171597633136 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2713677054309999 | Rouge-2:0.1291333778946179 | Rouge-l:0.2532724673357618\n",
            "Epoch: 5 | Step: 990 | Train loss: 0.8451738953590393 | lr: 0.0008806706114398422 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.21173085018690424 | Rouge-2:0.09487949106149143 | Rouge-l:0.21173085018690424\n",
            "Epoch: 5 | Step: 1000 | Train loss: 0.9256848692893982 | lr: 0.0008804240631163708 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.3360102304706973 | Rouge-2:0.188059051508379 | Rouge-l:0.3055967039634207\n",
            "Epoch: 5 | Step: 1010 | Train loss: 0.9964656233787537 | lr: 0.0008804240631163708 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.24538978460265826 | Rouge-2:0.08819802938031748 | Rouge-l:0.2121925432371295\n",
            "Epoch: 5 | Step: 1020 | Train loss: 1.137947678565979 | lr: 0.0008801775147928994 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.295597867030189 | Rouge-2:0.11181975638106795 | Rouge-l:0.25734214807594064\n",
            "Epoch: 5 | Step: 1030 | Train loss: 0.9513614773750305 | lr: 0.0008801775147928994 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2385377189112905 | Rouge-2:0.10157971462520762 | Rouge-l:0.1997482074170376\n",
            "Epoch: 5 | Step: 1040 | Train loss: 0.9347299933433533 | lr: 0.000879930966469428 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2492527262080388 | Rouge-2:0.11522603021778827 | Rouge-l:0.2267636069044034\n",
            "Epoch: 5 | Step: 1050 | Train loss: 1.0814672708511353 | lr: 0.0008796844181459567 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.3025634961816541 | Rouge-2:0.09265350784035087 | Rouge-l:0.25950898968005687\n",
            "Epoch: 5 | Step: 1060 | Train loss: 1.0020325183868408 | lr: 0.0008796844181459567 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2680027056937341 | Rouge-2:0.10319021706365217 | Rouge-l:0.22574557876269408\n",
            "Epoch: 5 | Step: 1070 | Train loss: 1.0162420272827148 | lr: 0.0008794378698224851 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2516452353298841 | Rouge-2:0.08167315864362337 | Rouge-l:0.2206619107043181\n",
            "Epoch: 5 | Step: 1080 | Train loss: 0.8507465720176697 | lr: 0.0008791913214990138 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.34360525359109884 | Rouge-2:0.15630538761307297 | Rouge-l:0.2900255578239031\n",
            "Epoch: 5 | Step: 1090 | Train loss: 0.8814828991889954 | lr: 0.0008791913214990138 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2589413080211068 | Rouge-2:0.10803126559303838 | Rouge-l:0.22046932873297315\n",
            "Epoch: 5 | Step: 1100 | Train loss: 0.9839497208595276 | lr: 0.0008789447731755425 | Min loss:0.6618687510490417\n",
            "Rouge-1:0.2604492886876889 | Rouge-2:0.12853920761318 | Rouge-l:0.2423616818500821\n",
            "Epoch: 5 | Step: 1110 | Train loss: 0.9002676010131836 | lr: 0.0008789447731755425 | Min loss:0.6618687510490417\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/model/config.json\n",
            "Configuration saved in /content/model/generation_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 5 | Step: 1118 | Train loss: 0.6537072062492371 | lr: 0.0008786982248520711 | Min loss:0.6537072062492371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/model/special_tokens_map.json\n",
            "Copy vocab file to /content/model/spiece.model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rouge-1:0.29490939555348694 | Rouge-2:0.1265237434626759 | Rouge-l:0.256650803478154\n",
            "Epoch: 5 | Step: 1120 | Train loss: 1.0699220895767212 | lr: 0.0008786982248520711 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.2676747331319166 | Rouge-2:0.09193076417604311 | Rouge-l:0.23138443065586686\n",
            "Epoch: 5 | Step: 1130 | Train loss: 1.1069016456604004 | lr: 0.0008784516765285996 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.33820332895235844 | Rouge-2:0.16155769111394494 | Rouge-l:0.3087448302751098\n",
            "Epoch: 5 | Step: 1140 | Train loss: 0.8905775547027588 | lr: 0.0008784516765285996 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.28432321683866346 | Rouge-2:0.12509336859189282 | Rouge-l:0.26283198876848807\n",
            "Epoch: 5 | Step: 1150 | Train loss: 0.8918335437774658 | lr: 0.0008782051282051282 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.3460324936357968 | Rouge-2:0.17381021340443878 | Rouge-l:0.299350132051612\n",
            "Epoch: 5 | Step: 1160 | Train loss: 0.8343853950500488 | lr: 0.0008779585798816569 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.21689646006725943 | Rouge-2:0.08086450034677399 | Rouge-l:0.18550102623280124\n",
            "Epoch: 5 | Step: 1170 | Train loss: 1.1747938394546509 | lr: 0.0008779585798816569 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.35286731164118307 | Rouge-2:0.19301826555131635 | Rouge-l:0.30157226659613806\n",
            "Epoch: 5 | Step: 1180 | Train loss: 0.9131072759628296 | lr: 0.0008777120315581854 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.289168862938182 | Rouge-2:0.115831504708754 | Rouge-l:0.27703838125820085\n",
            "Epoch: 5 | Step: 1190 | Train loss: 1.0142830610275269 | lr: 0.0008777120315581854 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.28515266797954775 | Rouge-2:0.1302732540864199 | Rouge-l:0.23153628594286213\n",
            "Epoch: 5 | Step: 1200 | Train loss: 0.8052698969841003 | lr: 0.000877465483234714 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.20276709569070936 | Rouge-2:0.10768703104521135 | Rouge-l:0.19755876235737602\n",
            "Epoch: 5 | Step: 1210 | Train loss: 0.9097154140472412 | lr: 0.0008772189349112426 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.3008996948185803 | Rouge-2:0.16184039837777045 | Rouge-l:0.27649433166321713\n",
            "Epoch: 5 | Step: 1220 | Train loss: 0.7344142198562622 | lr: 0.0008772189349112426 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.268189520362393 | Rouge-2:0.08939587172989787 | Rouge-l:0.23446109361672487\n",
            "Epoch: 5 | Step: 1230 | Train loss: 0.8818263411521912 | lr: 0.0008769723865877712 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.2652360402783198 | Rouge-2:0.11692369756395474 | Rouge-l:0.2571867978540774\n",
            "Epoch: 5 | Step: 1240 | Train loss: 0.869234025478363 | lr: 0.0008767258382642998 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.21319049003352544 | Rouge-2:0.07300984843023178 | Rouge-l:0.1894743369056076\n",
            "Epoch: 5 | Step: 1250 | Train loss: 1.0250037908554077 | lr: 0.0008767258382642998 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.2524828239341425 | Rouge-2:0.11880087273030879 | Rouge-l:0.22966712361844224\n",
            "Epoch: 5 | Step: 1260 | Train loss: 0.8992885947227478 | lr: 0.0008764792899408284 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.32720402075374555 | Rouge-2:0.1302155909321684 | Rouge-l:0.31757439112411595\n",
            "Epoch: 5 | Step: 1270 | Train loss: 0.8384133577346802 | lr: 0.0008764792899408284 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.20560511097075523 | Rouge-2:0.0875971229389078 | Rouge-l:0.17841066289807442\n",
            "Epoch: 5 | Step: 1280 | Train loss: 1.1378949880599976 | lr: 0.000876232741617357 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.2620442925845158 | Rouge-2:0.12270488528522208 | Rouge-l:0.24371095925118247\n",
            "Epoch: 5 | Step: 1290 | Train loss: 0.9651681184768677 | lr: 0.0008759861932938856 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.244654595272555 | Rouge-2:0.0970918238297987 | Rouge-l:0.2193687169144206\n",
            "Epoch: 5 | Step: 1300 | Train loss: 1.1162139177322388 | lr: 0.0008759861932938856 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.2742902352771502 | Rouge-2:0.14144382212111495 | Rouge-l:0.2526235686104836\n",
            "Epoch: 5 | Step: 1310 | Train loss: 0.8392321467399597 | lr: 0.0008757396449704143 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.2866485897001771 | Rouge-2:0.1162000332024552 | Rouge-l:0.2435163483002727\n",
            "Epoch: 5 | Step: 1320 | Train loss: 0.9140818119049072 | lr: 0.0008754930966469428 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.25731306225677664 | Rouge-2:0.11396915344808121 | Rouge-l:0.23749345816993117\n",
            "Epoch: 5 | Step: 1330 | Train loss: 0.9764737486839294 | lr: 0.0008754930966469428 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.29786593512303056 | Rouge-2:0.12422712000553723 | Rouge-l:0.27157756831742236\n",
            "Epoch: 5 | Step: 1340 | Train loss: 1.099941611289978 | lr: 0.0008752465483234714 | Min loss:0.6537072062492371\n",
            "Rouge-1:0.26439150213232065 | Rouge-2:0.1434672248426313 | Rouge-l:0.2516074112232297\n",
            "Epoch: 5 | Step: 1350 | Train loss: 0.8956472277641296 | lr: 0.0008752465483234714 | Min loss:0.6537072062492371\n"
          ]
        }
      ],
      "source": [
        "# Train!\n",
        "progress_bar = tqdm(range(total_train_steps), disable=not accelerator.is_local_main_process)\n",
        "\n",
        "print(\"***** Running training *****\")\n",
        "print(f\"  Num examples = {len(train_df)}\")\n",
        "print(f\"  Num Epochs = {args.num_train_epochs}\")\n",
        "print(f\"  Instantaneous batch size per device = {args.per_device_train_batch_size}\")\n",
        "print(f\"  Total train batch size (w. parallel, distributed & accumulation) = {args.per_device_train_batch_size * accelerator.num_processes * args.gradient_accumulation_steps}\")\n",
        "print(f\"  Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
        "\n",
        "train_gen_config = GenerationConfig(max_length=args.max_output_length,\n",
        "                                    num_beams=10,\n",
        "                                    length_penalty=1,\n",
        "                                    no_repeat_ngram_size=2,\n",
        "                                    early_stopping=True)\n",
        "train_gen = lambda input_tokens: model.generate(input_tokens, generation_config=train_gen_config)\n",
        "\n",
        "loss_plt_list = []\n",
        "rouge_plt_list = {\"rouge-1\":[], \"rouge-2\":[], \"rouge-l\":[]}\n",
        "\n",
        "min_lost = 100\n",
        "for epoch in range(args.num_train_epochs):\n",
        "    train_dataset = encode_dataset(train_df, train_batch_size)\n",
        "\n",
        "    for idx, (input_batch, label_batch) in enumerate(train_dataset):\n",
        "        with accelerator.accumulate(model):\n",
        "            outputs = model.forward(input_ids=input_batch, labels=label_batch)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            accelerator.backward(loss)\n",
        "\n",
        "            loss_plt_list.append(loss.item())\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        progress_bar.update(1)\n",
        "\n",
        "        # Evaluate the rouge score every 10 steps\n",
        "        if idx % 10 == 0:\n",
        "            pdt_lst = []\n",
        "            lb_lst = []\n",
        "            output_tokens = train_gen(input_batch)\n",
        "            for t, l in zip(output_tokens, label_batch):\n",
        "                pdt_lst.append(tokenizer.decode(t, skip_special_tokens=True))\n",
        "                lb_lst.append(tokenizer.decode(l, skip_special_tokens=True))\n",
        "            rouge = get_rouge(pdt_lst, lb_lst)\n",
        "            rouge_plt_list[\"rouge-1\"].append(rouge[\"rouge-1\"][\"f\"])\n",
        "            rouge_plt_list[\"rouge-2\"].append(rouge[\"rouge-2\"][\"f\"])\n",
        "            rouge_plt_list[\"rouge-l\"].append(rouge[\"rouge-l\"][\"f\"])\n",
        "\n",
        "            print(\"Rouge-1:{} | Rouge-2:{} | Rouge-l:{}\".format(rouge[\"rouge-1\"][\"f\"], rouge[\"rouge-2\"][\"f\"], rouge[\"rouge-l\"][\"f\"]))\n",
        "            del pdt_lst, lb_lst\n",
        "\n",
        "        # show the information\n",
        "        if idx % 10 == 0:\n",
        "            print(f\"Epoch: {epoch} | Step: {idx} | Train loss: {loss.item()} | lr: {lr_scheduler.get_last_lr()[0]} | Min loss:{min_lost}\")\n",
        "\n",
        "        if (idx > 1000 or epoch > 0) and loss.item() < min_lost:\n",
        "            min_lost = loss.item()\n",
        "            print(f\"Epoch: {epoch} | Step: {idx} | Train loss: {loss.item()} | lr: {lr_scheduler.get_last_lr()[0]} | Min loss:{min_lost}\")\n",
        "\n",
        "            # Save the model\n",
        "            accelerator.wait_for_everyone()\n",
        "            unwrapped_model = accelerator.unwrap_model(model)\n",
        "            unwrapped_model.save_pretrained(\n",
        "                args.output_dir, is_main_process=accelerator.is_main_process, save_function=accelerator.save\n",
        "            )\n",
        "            if accelerator.is_main_process:\n",
        "                tokenizer.save_pretrained(args.output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hOuwY4FChCh"
      },
      "source": [
        "### Different Generation Strategies\n",
        "It defines different generation configurations such as greedy search, beam search, and various sampling strategies with tempurature, top-K, and top-P. The code iterates through each strategy, generating text for a subset of evaluation data, and computes Rouge scores for comparison. The generated text and ground truth labels are stored for evaluation. The best strategy is determined based on the combined Rouge scores for unigram, bigram, and longest common subsequence metrics. This code snippet enables the selection of the most effective text generation approach for the given task. Note that we only compare these strategies on the first 100 featrues of validation datas, which is already sufficient to differentiate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698,
          "referenced_widgets": [
            "782e8172ce4d47f3a133ce5818b92918",
            "51d7cfc5c3c04dde8fcfb90e760ef146",
            "a910fed0794b4ca78b3c50d3cb28766d",
            "0ed72d5d2cdd4692bfe0778d2ca3c656",
            "c7403d8c7fb84b729eb5bb640aef58af",
            "4cdc17008fbd465db3157382809be672",
            "8e7b229bf7cb4d70a0f2afd524d3965a",
            "85de2167b7ee44dfac731928c138abf6",
            "b7e9e0b4a3894caebcda823c6ad06ada",
            "811bdadc3e234e25b19d4becb2c7aead",
            "336a471685e54a0aa39c40647e88cfb5",
            "7663ef13d7f143f8921150118b844bb9",
            "be61dd76047445e88d49c943697249a9",
            "bd14eab05e214f7f835a4defef236ee2",
            "f2ffc7fe78bc4b858e5d53cd7b3093ee",
            "db73f42384fa49338921c1fd9debd325",
            "a5953fbfbebd46c38c15231647133067",
            "5fca4468bea64eb1b40f473371fa89e0",
            "814271fef05841c49da12b2c1346f8b1",
            "9a99a08f54be475aa511f505ce0098d6",
            "9031c4b4f4e14878ab041a486bb8499f",
            "dae56ab60e54476bbf967f5f2fc658cb",
            "2ab9289870624962ba33a70be5a5ba95",
            "74d378ecee31410f8d08e45d6eb01116",
            "631005fd3dff496396b36a24ebe27dd3",
            "568a7d06e44a40a784b63ed62ad2d01f",
            "32469c80a42b45bfa90531924dca5b48",
            "aea8bf1553ba4646907e331566cd012d",
            "e3d9bc23fb614702a29fbf4c0186f10e",
            "ce289cdbe05e41478cf4dda1ef83c524",
            "3fb82b13e01b46d9ac42e3e29bae4cc4",
            "e132e58264bd4c87a94bfc502c7621b2",
            "27b4a28aa04d41dabd90170cabc72c55",
            "7b2db2f8700b4575b1492c8bf19af1ec",
            "670438621d9c4fbea8f02d8a5fa69a1f",
            "fc0afe1eda254ec58577079f7bdb52ef",
            "7016a49c87ab4a4092c08a87011b9381",
            "3b42208c51874d5587ea2e5023749f0d",
            "2a8a4755d5f744688ab6598bf4da2b15",
            "730099960d344b339a21697750153d62",
            "b8afa57de3ba4fde8655b52acca7ea64",
            "1647bc42d1e04c84a6fee751bc81dbf8",
            "014b467dffd3418fa6219c0c59dc1931",
            "3dd98d0159504cc5af4f96c98cc143a3",
            "425991a88c554be5b879db74556e66ae",
            "05aa6f14b1da4191bb3c16584fc5836f",
            "56b7063c93d3499482a38366a180982e",
            "af331e3766b44fe7995f17e4b12601b0",
            "219ca377a32047cdb76d6c952aaaeff2",
            "ff4b0aec799d40e3a3eff4e10c45aa5a",
            "6a0d7e4a845448ce83e6fef4542271a0",
            "0bdcde1ccf7a44518fcda01a07f19a37",
            "4bff4dc4d79c42fc9dcceb51b8c46278",
            "1a1de90ad5aa41d2bf3dbb156261b1bf",
            "a5d571b8de5d4194aefff5b5758659f3"
          ]
        },
        "id": "j6rhbSMwmTUp",
        "outputId": "7ff44282-46ee-4631-c179-1a6509f63e9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using generation strategy : greedy\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "782e8172ce4d47f3a133ce5818b92918",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "greedy :\n",
            "rouge-1: 20.40792833902558\n",
            "rouge-2: 7.236797986414389\n",
            "rouge-l: 18.42256309905828\n",
            "\n",
            "using generation strategy : beam\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7663ef13d7f143f8921150118b844bb9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "beam :\n",
            "rouge-1: 24.3631487179364\n",
            "rouge-2: 10.309077519928305\n",
            "rouge-l: 22.436342505238038\n",
            "\n",
            "using generation strategy : sampling_temp\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ab9289870624962ba33a70be5a5ba95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sampling_temp :\n",
            "rouge-1: 18.40069198195147\n",
            "rouge-2: 5.184157273858043\n",
            "rouge-l: 16.713770074517704\n",
            "\n",
            "using generation strategy : topK\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b2db2f8700b4575b1492c8bf19af1ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "topK :\n",
            "rouge-1: 10.780672671962291\n",
            "rouge-2: 1.918568360183683\n",
            "rouge-l: 9.843856822193116\n",
            "\n",
            "using generation strategy : topP\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "425991a88c554be5b879db74556e66ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "topP :\n",
            "rouge-1: 12.373567040062678\n",
            "rouge-2: 3.61369356590339\n",
            "rouge-l: 11.752682100349887\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "# pure greedy\n",
        "greedy_config = GenerationConfig(max_length=args.max_output_length)\n",
        "greedy = lambda input_tokens: model.generate(input_tokens, generation_config=greedy_config)\n",
        "# pure beam search\n",
        "beam_config = GenerationConfig(max_length=args.max_output_length,\n",
        "                               num_beams=10,\n",
        "                               length_penalty=1,\n",
        "                               no_repeat_ngram_size=2,\n",
        "                               early_stopping=True)\n",
        "beam = lambda input_tokens: model.generate(input_tokens, generation_config=beam_config)\n",
        "# sampling with temperature\n",
        "sampling_temp_config = GenerationConfig(max_length=args.max_output_length,\n",
        "                                        do_sample=True,\n",
        "                                        top_k=0,\n",
        "                                        temperature=0.7)\n",
        "sampling_temp = lambda input_tokens: model.generate(input_tokens,generation_config=sampling_temp_config)\n",
        "# topK_sampling\n",
        "topK_sampling_config = GenerationConfig(max_length=args.max_output_length,\n",
        "                                        do_sample=True,\n",
        "                                        top_k=model.config.vocab_size//5)\n",
        "topK_sampling = lambda input_tokens: model.generate(input_tokens, generation_config=topK_sampling_config)\n",
        "# topP with topK sampling\n",
        "topP_sampling_config = GenerationConfig(max_length=args.max_output_length,\n",
        "                                        do_sample=True,\n",
        "                                        top_p=0.95,\n",
        "                                        top_k=model.config.vocab_size//5)\n",
        "topP_sampling = lambda input_tokens: model.generate(input_tokens, generation_config=topP_sampling_config)\n",
        "\n",
        "generation_strategy = {\"greedy\":greedy, \"beam\":beam, \"sampling_temp\":sampling_temp, \"topK\":topK_sampling, \"topP\":topP_sampling}\n",
        "\n",
        "best_name = None\n",
        "best_score = 0\n",
        "for gen_name, gen in generation_strategy.items():\n",
        "    print(f\"using generation strategy : {gen_name}\")\n",
        "    progress_bar = tqdm(range(100), disable=not accelerator.is_local_main_process)\n",
        "    pdt_lst, lb_lst = [], []\n",
        "    for idx, feature in enumerate(eval_df.iloc):\n",
        "        input_tokens = encode_main_text(feature[\"maintext\"], args.max_input_length)\n",
        "        input_tokens = input_tokens.unsqueeze(0).cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = gen(input_tokens)\n",
        "            for output_tokens in outputs:\n",
        "                prediction = tokenizer.decode(output_tokens, skip_special_tokens=True)\n",
        "                if len(prediction) == 0:\n",
        "                    prediction = \" \"\n",
        "                pdt_lst.append(prediction)\n",
        "                lb_lst.append(feature[\"title\"])\n",
        "        progress_bar.update(1)\n",
        "\n",
        "        if idx == 100: break\n",
        "        # We first compare the result of first 100 set of datas\n",
        "        # And chose the one with the highest rouge_score sum and choose it to generate the rest of the datas\n",
        "\n",
        "    print(gen_name, \":\")\n",
        "    final_rouge = get_rouge(pdt_lst, lb_lst)\n",
        "    score = [final_rouge[\"rouge-1\"][\"f\"]*100, final_rouge[\"rouge-2\"][\"f\"]*100, final_rouge[\"rouge-l\"][\"f\"]*100]\n",
        "    print(f\"rouge-1: {score[0]}\")\n",
        "    print(f\"rouge-2: {score[1]}\")\n",
        "    print(f\"rouge-l: {score[2]}\\n\")\n",
        "\n",
        "    if best_score < score[0] + score [1] + score[2]:\n",
        "        best_score = score[0] + score[1] + score[2];\n",
        "        best_name = gen_name\n",
        "\n",
        "    del pdt_lst, lb_lst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation Loop\n",
        "First, choose the best text generation strategy determined in the previous section. It then iterates through the dataset, encoding the main text and generating predictions using the selected strategy. The generated predictions and ground truth labels are stored for later evaluation. Rouge scores are calculated based on unigram, bigram, and longest common subsequence metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "e43008bbedd54eac8cf96305dcf4699b",
            "0fabe99192b14a6786dcef2243c163f6",
            "bc9387c8bd30420d943f6e5d54d0471a",
            "8ea3724fe79144ae92bf7b9748175375",
            "df3ea88e964c4d02b671ba04b5c9f4f0",
            "4c64fad3e97c4365a50fd7442a9f74e9",
            "2044357c26644273940e8f47dadcd33e",
            "60d1c3383c9d4d3fbd1c387c0b550ca2",
            "58305194235b4aa880be7ce0425e4cc6",
            "df5d9d42b3b34073a0feeaaa86e2bfdf",
            "fc58e12530a746798b8f50c8b6724983"
          ]
        },
        "id": "YxEwXj-oLerF",
        "outputId": "884cd876-8076-4394-c8a2-0b661b157cce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using generation strategy : beam\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e43008bbedd54eac8cf96305dcf4699b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5467 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rouge-1: 23.634813237719708\n",
            "rouge-2: 8.790286963149608\n",
            "rouge-l: 20.970440407326272\n"
          ]
        }
      ],
      "source": [
        "print(f\"using generation strategy : {best_name}\")\n",
        "total_eval_steps = math.ceil(eval_df.shape[0])\n",
        "progress_bar = tqdm(range(total_eval_steps), disable=not accelerator.is_local_main_process)\n",
        "\n",
        "pdt_lst, lb_lst = [], []\n",
        "for idx, feature in enumerate(eval_df.iloc):\n",
        "    input_tokens = encode_main_text(feature[\"maintext\"], args.max_input_length)\n",
        "    input_tokens = input_tokens.unsqueeze(0).cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = generation_strategy[best_name](input_tokens)\n",
        "        for output_tokens in outputs:\n",
        "            prediction = tokenizer.decode(output_tokens, skip_special_tokens=True)\n",
        "            pdt_lst.append(prediction)\n",
        "            lb_lst.append(feature[\"title\"])\n",
        "    progress_bar.update(1)\n",
        "\n",
        "final_rouge = get_rouge(pdt_lst, lb_lst)\n",
        "score = [final_rouge[\"rouge-1\"][\"f\"]*100, final_rouge[\"rouge-2\"][\"f\"]*100, final_rouge[\"rouge-l\"][\"f\"]*100]\n",
        "print(f\"rouge-1: {score[0]}\")\n",
        "print(f\"rouge-2: {score[1]}\")\n",
        "print(f\"rouge-l: {score[2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot the Loss and Rouge Score\n",
        "This generates two plots. The first plot diplay the loss over the training iterations. The second plot shows Rouge scores for different n-gram orders (unigram, bigram, and longest common subsequence) throughout the training iterations. The Rouge metric is assessed at intervals of every 10 training steps. As a result, the x-axis of the second figure corresponds to these intervals. The observed fluctuations in the Rouge score may be attributed to the inherent diversity within the dataset. Tasks with larger, more complex input paragraphs might yield comparatively lower performance, while tasks with smaller, less intricate inputs may lead to better results. This variance in input complexity likely contributes to the observed fluctuations in Rouge scores during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "id": "gDgaB6TBpaS4",
        "outputId": "62f1cd58-ec31-4d75-a06b-2ccc7edc0ab1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(loss_plt_list, label=\"loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(rouge_plt_list[\"rouge-1\"], label=\"rouge-1\")\n",
        "plt.plot(rouge_plt_list[\"rouge-2\"], label=\"rouge-2\")\n",
        "plt.plot(rouge_plt_list[\"rouge-l\"], label=\"rouge-l\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AA1Qj67mALKj"
      },
      "outputs": [],
      "source": [
        "result_dict = [{\"title\": title_, \"id\": str(feature_[\"id\"])} for feature_, title_ in zip(eval_df.iloc, pdt_lst)]\n",
        "\n",
        "with open(args.result_file, \"w\") as f:\n",
        "    for result_pair in result_dict:\n",
        "        json.dump(result_pair, f)\n",
        "        f.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mount Google Drive and Save the Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV0E7VQWQlnO",
        "outputId": "e1334d0d-2f41-4ffb-f2f2-58e169f8c2a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mUeTTOqCSEDa"
      },
      "outputs": [],
      "source": [
        "! cp -r /content/model \"/content/gdrive/My Drive/ADL/Hw2/model\"\n",
        "! cp /content/result.jsonl \"/content/gdrive/My Drive/ADL/Hw2/result.jsonl\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "014b467dffd3418fa6219c0c59dc1931": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05530eb983ae4d7a85626ece9e22ec97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05aa6f14b1da4191bb3c16584fc5836f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff4b0aec799d40e3a3eff4e10c45aa5a",
            "placeholder": "​",
            "style": "IPY_MODEL_6a0d7e4a845448ce83e6fef4542271a0",
            "value": ""
          }
        },
        "0bdcde1ccf7a44518fcda01a07f19a37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ed72d5d2cdd4692bfe0778d2ca3c656": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_811bdadc3e234e25b19d4becb2c7aead",
            "placeholder": "​",
            "style": "IPY_MODEL_336a471685e54a0aa39c40647e88cfb5",
            "value": " 101/? [00:30&lt;00:00,  2.21it/s]"
          }
        },
        "0fabe99192b14a6786dcef2243c163f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c64fad3e97c4365a50fd7442a9f74e9",
            "placeholder": "​",
            "style": "IPY_MODEL_2044357c26644273940e8f47dadcd33e",
            "value": "100%"
          }
        },
        "1647bc42d1e04c84a6fee751bc81dbf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a1de90ad5aa41d2bf3dbb156261b1bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2044357c26644273940e8f47dadcd33e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "219ca377a32047cdb76d6c952aaaeff2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "246c552040d8445fa8ae23767d9e4a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8149004acb904688ba4343d494ee58ac",
            "max": 8112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c93f4fa85c7e4e4eae1d0ecbc51976c8",
            "value": 8112
          }
        },
        "275bba471d824aa29776cfabb2a76919": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05530eb983ae4d7a85626ece9e22ec97",
            "placeholder": "​",
            "style": "IPY_MODEL_c76c77a9d820458d880a0e6c76848157",
            "value": "100%"
          }
        },
        "27b4a28aa04d41dabd90170cabc72c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a8a4755d5f744688ab6598bf4da2b15": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ab9289870624962ba33a70be5a5ba95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74d378ecee31410f8d08e45d6eb01116",
              "IPY_MODEL_631005fd3dff496396b36a24ebe27dd3",
              "IPY_MODEL_568a7d06e44a40a784b63ed62ad2d01f"
            ],
            "layout": "IPY_MODEL_32469c80a42b45bfa90531924dca5b48"
          }
        },
        "32469c80a42b45bfa90531924dca5b48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "336a471685e54a0aa39c40647e88cfb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b42208c51874d5587ea2e5023749f0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dd98d0159504cc5af4f96c98cc143a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fb82b13e01b46d9ac42e3e29bae4cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "404b323293d94968bebd6e0eccec98cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_275bba471d824aa29776cfabb2a76919",
              "IPY_MODEL_246c552040d8445fa8ae23767d9e4a69",
              "IPY_MODEL_492d5cb8d8054676a085a1ed087ab969"
            ],
            "layout": "IPY_MODEL_d47b0dd51dc3438d89864314f0d3e9c6"
          }
        },
        "425991a88c554be5b879db74556e66ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05aa6f14b1da4191bb3c16584fc5836f",
              "IPY_MODEL_56b7063c93d3499482a38366a180982e",
              "IPY_MODEL_af331e3766b44fe7995f17e4b12601b0"
            ],
            "layout": "IPY_MODEL_219ca377a32047cdb76d6c952aaaeff2"
          }
        },
        "492d5cb8d8054676a085a1ed087ab969": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80a0fbd4c1f6471e886a7ed79a34bf26",
            "placeholder": "​",
            "style": "IPY_MODEL_cc3e1b376e664f0b9a1575bbb91081da",
            "value": " 8112/8112 [1:57:00&lt;00:00,  1.30s/it]"
          }
        },
        "4bff4dc4d79c42fc9dcceb51b8c46278": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c64fad3e97c4365a50fd7442a9f74e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cdc17008fbd465db3157382809be672": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51d7cfc5c3c04dde8fcfb90e760ef146": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cdc17008fbd465db3157382809be672",
            "placeholder": "​",
            "style": "IPY_MODEL_8e7b229bf7cb4d70a0f2afd524d3965a",
            "value": ""
          }
        },
        "568a7d06e44a40a784b63ed62ad2d01f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e132e58264bd4c87a94bfc502c7621b2",
            "placeholder": "​",
            "style": "IPY_MODEL_27b4a28aa04d41dabd90170cabc72c55",
            "value": " 101/? [01:09&lt;00:00,  2.98it/s]"
          }
        },
        "56b7063c93d3499482a38366a180982e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bdcde1ccf7a44518fcda01a07f19a37",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bff4dc4d79c42fc9dcceb51b8c46278",
            "value": 100
          }
        },
        "58305194235b4aa880be7ce0425e4cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5fca4468bea64eb1b40f473371fa89e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60d1c3383c9d4d3fbd1c387c0b550ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "631005fd3dff496396b36a24ebe27dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce289cdbe05e41478cf4dda1ef83c524",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fb82b13e01b46d9ac42e3e29bae4cc4",
            "value": 100
          }
        },
        "670438621d9c4fbea8f02d8a5fa69a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a8a4755d5f744688ab6598bf4da2b15",
            "placeholder": "​",
            "style": "IPY_MODEL_730099960d344b339a21697750153d62",
            "value": ""
          }
        },
        "6a0d7e4a845448ce83e6fef4542271a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7016a49c87ab4a4092c08a87011b9381": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_014b467dffd3418fa6219c0c59dc1931",
            "placeholder": "​",
            "style": "IPY_MODEL_3dd98d0159504cc5af4f96c98cc143a3",
            "value": " 101/? [00:36&lt;00:00,  3.53it/s]"
          }
        },
        "730099960d344b339a21697750153d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74d378ecee31410f8d08e45d6eb01116": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aea8bf1553ba4646907e331566cd012d",
            "placeholder": "​",
            "style": "IPY_MODEL_e3d9bc23fb614702a29fbf4c0186f10e",
            "value": ""
          }
        },
        "7663ef13d7f143f8921150118b844bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be61dd76047445e88d49c943697249a9",
              "IPY_MODEL_bd14eab05e214f7f835a4defef236ee2",
              "IPY_MODEL_f2ffc7fe78bc4b858e5d53cd7b3093ee"
            ],
            "layout": "IPY_MODEL_db73f42384fa49338921c1fd9debd325"
          }
        },
        "782e8172ce4d47f3a133ce5818b92918": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51d7cfc5c3c04dde8fcfb90e760ef146",
              "IPY_MODEL_a910fed0794b4ca78b3c50d3cb28766d",
              "IPY_MODEL_0ed72d5d2cdd4692bfe0778d2ca3c656"
            ],
            "layout": "IPY_MODEL_c7403d8c7fb84b729eb5bb640aef58af"
          }
        },
        "7b2db2f8700b4575b1492c8bf19af1ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_670438621d9c4fbea8f02d8a5fa69a1f",
              "IPY_MODEL_fc0afe1eda254ec58577079f7bdb52ef",
              "IPY_MODEL_7016a49c87ab4a4092c08a87011b9381"
            ],
            "layout": "IPY_MODEL_3b42208c51874d5587ea2e5023749f0d"
          }
        },
        "80a0fbd4c1f6471e886a7ed79a34bf26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "811bdadc3e234e25b19d4becb2c7aead": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "814271fef05841c49da12b2c1346f8b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8149004acb904688ba4343d494ee58ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85de2167b7ee44dfac731928c138abf6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e7b229bf7cb4d70a0f2afd524d3965a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ea3724fe79144ae92bf7b9748175375": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df5d9d42b3b34073a0feeaaa86e2bfdf",
            "placeholder": "​",
            "style": "IPY_MODEL_fc58e12530a746798b8f50c8b6724983",
            "value": " 5467/5467 [39:50&lt;00:00,  2.47it/s]"
          }
        },
        "9031c4b4f4e14878ab041a486bb8499f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a99a08f54be475aa511f505ce0098d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5953fbfbebd46c38c15231647133067": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5d571b8de5d4194aefff5b5758659f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a910fed0794b4ca78b3c50d3cb28766d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85de2167b7ee44dfac731928c138abf6",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7e9e0b4a3894caebcda823c6ad06ada",
            "value": 100
          }
        },
        "aea8bf1553ba4646907e331566cd012d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af331e3766b44fe7995f17e4b12601b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a1de90ad5aa41d2bf3dbb156261b1bf",
            "placeholder": "​",
            "style": "IPY_MODEL_a5d571b8de5d4194aefff5b5758659f3",
            "value": " 101/? [00:38&lt;00:00,  2.61it/s]"
          }
        },
        "b7e9e0b4a3894caebcda823c6ad06ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8afa57de3ba4fde8655b52acca7ea64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc9387c8bd30420d943f6e5d54d0471a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60d1c3383c9d4d3fbd1c387c0b550ca2",
            "max": 5467,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58305194235b4aa880be7ce0425e4cc6",
            "value": 5467
          }
        },
        "bd14eab05e214f7f835a4defef236ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_814271fef05841c49da12b2c1346f8b1",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a99a08f54be475aa511f505ce0098d6",
            "value": 100
          }
        },
        "be61dd76047445e88d49c943697249a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5953fbfbebd46c38c15231647133067",
            "placeholder": "​",
            "style": "IPY_MODEL_5fca4468bea64eb1b40f473371fa89e0",
            "value": ""
          }
        },
        "c7403d8c7fb84b729eb5bb640aef58af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c76c77a9d820458d880a0e6c76848157": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c93f4fa85c7e4e4eae1d0ecbc51976c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc3e1b376e664f0b9a1575bbb91081da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce289cdbe05e41478cf4dda1ef83c524": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d47b0dd51dc3438d89864314f0d3e9c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dae56ab60e54476bbf967f5f2fc658cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db73f42384fa49338921c1fd9debd325": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df3ea88e964c4d02b671ba04b5c9f4f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df5d9d42b3b34073a0feeaaa86e2bfdf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e132e58264bd4c87a94bfc502c7621b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3d9bc23fb614702a29fbf4c0186f10e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e43008bbedd54eac8cf96305dcf4699b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fabe99192b14a6786dcef2243c163f6",
              "IPY_MODEL_bc9387c8bd30420d943f6e5d54d0471a",
              "IPY_MODEL_8ea3724fe79144ae92bf7b9748175375"
            ],
            "layout": "IPY_MODEL_df3ea88e964c4d02b671ba04b5c9f4f0"
          }
        },
        "f2ffc7fe78bc4b858e5d53cd7b3093ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9031c4b4f4e14878ab041a486bb8499f",
            "placeholder": "​",
            "style": "IPY_MODEL_dae56ab60e54476bbf967f5f2fc658cb",
            "value": " 101/? [00:43&lt;00:00,  2.10it/s]"
          }
        },
        "fc0afe1eda254ec58577079f7bdb52ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8afa57de3ba4fde8655b52acca7ea64",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1647bc42d1e04c84a6fee751bc81dbf8",
            "value": 100
          }
        },
        "fc58e12530a746798b8f50c8b6724983": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff4b0aec799d40e3a3eff4e10c45aa5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
